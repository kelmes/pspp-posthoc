This is pspp.info, produced by makeinfo version 5.2 from pspp.texi.

This manual is for GNU PSPP version 0.10.2, software for statistical
analysis.

   Copyright (C) 1997, 1998, 2004, 2005, 2009, 2012, 2013, 2014, 2016
Free Software Foundation, Inc.

     Permission is granted to copy, distribute and/or modify this
     document under the terms of the GNU Free Documentation License,
     Version 1.3 or any later version published by the Free Software
     Foundation; with no Invariant Sections, no Front-Cover Texts, and
     no Back-Cover Texts.  A copy of the license is included in the
     section entitled "GNU Free Documentation License".
INFO-DIR-SECTION Math
START-INFO-DIR-ENTRY
* PSPP: (pspp).             Statistical analysis package.
* PSPPIRE: (pspp).          Graphical user interface to PSPP.
END-INFO-DIR-ENTRY

   The authors wish to thank Network Theory Ltd
<http://www.network-theory.co.uk> for their financial support in the
production of this manual.


File: pspp.info,  Node: COUNT,  Next: FLIP,  Prev: COMPUTE,  Up: Data Manipulation

12.4 COUNT
==========

     COUNT VAR_NAME = VAR... (VALUE...).

     Each VALUE takes one of the following forms:
             NUMBER
             STRING
             NUM1 THRU NUM2
             MISSING
             SYSMIS
     where NUM1 is a numeric expression or the words 'LO'  or 'LOWEST'
           and NUM2 is a numeric expression  or 'HI' or 'HIGHEST'.

   'COUNT' creates or replaces a numeric "target" variable that counts
the occurrence of a "criterion" value or set of values over one or more
"test" variables for each case.

   The target variable values are always nonnegative integers.  They are
never missing.  The target variable is assigned an F8.2 output format.
*Note Input and Output Formats::.  Any variables, including string
variables, may be test variables.

   User-missing values of test variables are treated just like any other
values.  They are *not* treated as system-missing values.  User-missing
values that are criterion values or inside ranges of criterion values
are counted as any other values.  However (for numeric variables),
keyword 'MISSING' may be used to refer to all system- and user-missing
values.

   'COUNT' target variables are assigned values in the order specified.
In the command 'COUNT A=A B(1) /B=A B(2).', the following actions occur:

   - The number of occurrences of 1 between A and B is counted.

   - A is assigned this value.

   - The number of occurrences of 1 between B and the *new* value of A
     is counted.

   - B is assigned this value.

   Despite this ordering, all 'COUNT' criterion variables must exist
before the procedure is executed--they may not be created as target
variables earlier in the command!  Break such a command into two
separate commands.

   The examples below may help to clarify.

  A. Assuming 'Q0', 'Q2', ..., 'Q9' are numeric variables, the following
     commands:

       1. Count the number of times the value 1 occurs through these
          variables for each case and assigns the count to variable
          'QCOUNT'.

       2. Print out the total number of times the value 1 occurs
          throughout _all_ cases using 'DESCRIPTIVES'.  *Note
          DESCRIPTIVES::, for details.

          COUNT QCOUNT=Q0 TO Q9(1).
          DESCRIPTIVES QCOUNT /STATISTICS=SUM.

  B. Given these same variables, the following commands:

       1. Count the number of valid values of these variables for each
          case and assigns the count to variable 'QVALID'.

       2. Multiplies each value of 'QVALID' by 10 to obtain a percentage
          of valid values, using 'COMPUTE'.  *Note COMPUTE::, for
          details.

       3. Print out the percentage of valid values across all cases,
          using 'DESCRIPTIVES'.  *Note DESCRIPTIVES::, for details.

          COUNT QVALID=Q0 TO Q9 (LO THRU HI).
          COMPUTE QVALID=QVALID*10.
          DESCRIPTIVES QVALID /STATISTICS=MEAN.


File: pspp.info,  Node: FLIP,  Next: IF,  Prev: COUNT,  Up: Data Manipulation

12.5 FLIP
=========

     FLIP /VARIABLES=VAR_LIST /NEWNAMES=VAR_NAME.

   'FLIP' transposes rows and columns in the active dataset.  It causes
cases to be swapped with variables, and vice versa.

   All variables in the transposed active dataset are numeric.  String
variables take on the system-missing value in the transposed file.

   'N' subcommands are required.  If specified, the 'VARIABLES'
subcommand selects variables to be transformed into cases, and variables
not specified are discarded.  If the 'VARIABLES' subcommand is omitted,
all variables are selected for transposition.

   The variables specified by 'NEWNAMES', which must be a string
variable, is used to give names to the variables created by 'FLIP'.
Only the first 8 characters of the variable are used.  If 'NEWNAMES' is
not specified then the default is a variable named CASE_LBL, if it
exists.  If it does not then the variables created by 'FLIP' are named
VAR000 through VAR999, then VAR1000, VAR1001, and so on.

   When a 'NEWNAMES' variable is available, the names must be
canonicalized before becoming variable names.  Invalid characters are
replaced by letter 'V' in the first position, or by '_' in subsequent
positions.  If the name thus generated is not unique, then numeric
extensions are added, starting with 1, until a unique name is found or
there are no remaining possibilities.  If the latter occurs then the
'FLIP' operation aborts.

   The resultant dictionary contains a CASE_LBL variable, a string
variable of width 8, which stores the names of the variables in the
dictionary before the transposition.  Variables names longer than 8
characters are truncated.  If the active dataset is subsequently
transposed using 'FLIP', this variable can be used to recreate the
original variable names.

   'FLIP' honors 'N OF CASES' (*note N OF CASES::).  It ignores
'TEMPORARY' (*note TEMPORARY::), so that "temporary" transformations
become permanent.


File: pspp.info,  Node: IF,  Next: RECODE,  Prev: FLIP,  Up: Data Manipulation

12.6 IF
=======

     IF CONDITION VARIABLE=EXPRESSION.
   or
     IF CONDITION vector(INDEX)=EXPRESSION.

   The 'IF' transformation conditionally assigns the value of a target
expression to a target variable, based on the truth of a test
expression.

   Specify a boolean-valued expression (*note Expressions::) to be
tested following the 'IF' keyword.  This expression is evaluated for
each case.  If the value is true, then the value of the expression is
computed and assigned to the specified variable.  If the value is false
or missing, nothing is done.  Numeric and string variables may be
assigned.  When a string expression's width differs from the target
variable's width, the string result of the expression is truncated or
padded with spaces on the right as necessary.  The expression and
variable types must match.

   The target variable may be specified as an element of a vector (*note
VECTOR::).  In this case, a vector index expression must be specified in
parentheses following the vector name.  The index expression must
evaluate to a numeric value that, after rounding down to the nearest
integer, is a valid index for the named vector.

   Using 'IF' to assign to a variable specified on 'LEAVE' (*note
LEAVE::) resets the variable's left state.  Therefore, 'LEAVE' should be
specified following 'IF', not before.

   When 'IF' is specified following 'TEMPORARY' (*note TEMPORARY::), the
'LAG' function may not be used (*note LAG::).


File: pspp.info,  Node: RECODE,  Next: SORT CASES,  Prev: IF,  Up: Data Manipulation

12.7 RECODE
===========

The 'RECODE' command is used to transform existing values into other,
user specified values.  The general form is:

     RECODE SRC_VARS
             (SRC_VALUE SRC_VALUE ... = DEST_VALUE)
             (SRC_VALUE SRC_VALUE ... = DEST_VALUE)
             (SRC_VALUE SRC_VALUE ... = DEST_VALUE) ...
              [INTO DEST_VARS].

   Following the 'RECODE' keyword itself comes SRC_VARS which is a list
of variables whose values are to be transformed.  These variables may be
string variables or they may be numeric.  However the list must be
homogeneous; you may not mix string variables and numeric variables in
the same recoding.

   After the list of source variables, there should be one or more
"mappings".  Each mapping is enclosed in parentheses, and contains the
source values and a destination value separated by a single '='.  The
source values are used to specify the values in the dataset which need
to change, and the destination value specifies the new value to which
they should be changed.  Each SRC_VALUE may take one of the following
forms:
NUMBER
     If the source variables are numeric then SRC_VALUE may be a literal
     number.
STRING
     If the source variables are string variables then SRC_VALUE may be
     a literal string (like all strings, enclosed in single or double
     quotes).
NUM1 THRU NUM2
     This form is valid only when the source variables are numeric.  It
     specifies all values in the range between NUM1 and NUM2, including
     both endpoints of the range.  By convention, NUM1 should be less
     than NUM2.  Open-ended ranges may be specified using 'LO' or
     'LOWEST' for NUM1 or 'HI' or 'HIGHEST' for NUM2.
'MISSING'
     The literal keyword 'MISSING' matches both system missing and user
     missing values.  It is valid for both numeric and string variables.
'SYSMIS'
     The literal keyword 'SYSMIS' matches system missing values.  It is
     valid for both numeric variables only.
'ELSE'
     The 'ELSE' keyword may be used to match any values which are not
     matched by any other SRC_VALUE appearing in the command.  If this
     keyword appears, it should be used in the last mapping of the
     command.

   After the source variables comes an '=' and then the DEST_VALUE.  The
DEST_VALUE may take any of the following forms:
NUMBER
     A literal numeric value to which the source values should be
     changed.  This implies the destination variable must be numeric.
STRING
     A literal string value (enclosed in quotation marks) to which the
     source values should be changed.  This implies the destination
     variable must be a string variable.
'SYSMIS'
     The keyword 'SYSMIS' changes the value to the system missing value.
     This implies the destination variable must be numeric.
'COPY'
     The special keyword 'COPY' means that the source value should not
     be modified, but copied directly to the destination value.  This is
     meaningful only if 'INTO DEST_VARS' is specified.

   Mappings are considered from left to right.  Therefore, if a value is
matched by a SRC_VALUE from more than one mapping, the first (leftmost)
mapping which matches will be considered.  Any subsequent matches will
be ignored.

   The clause 'INTO DEST_VARS' is optional.  The behaviour of the
command is slightly different depending on whether it appears or not.

   If 'INTO DEST_VARS' does not appear, then values will be recoded "in
place".  This means that the recoded values are written back to the
source variables from whence the original values came.  In this case,
the DEST_VALUE for every mapping must imply a value which has the same
type as the SRC_VALUE.  For example, if the source value is a string
value, it is not permissible for DEST_VALUE to be 'SYSMIS' or another
forms which implies a numeric result.  It is also not permissible for
DEST_VALUE to be longer than the width of the source variable.

   The following example two numeric variables X and Y are recoded in
place.  Zero is recoded to 99, the values 1 to 10 inclusive are
unchanged, values 1000 and higher are recoded to the system-missing
value and all other values are changed to 999:
     recode X Y
             (0 = 99)
             (1 THRU 10 = COPY)
             (1000 THRU HIGHEST = SYSMIS)
             (ELSE = 999).

   If 'INTO DEST_VARS' is given, then recoded values are written into
the variables specified in DEST_VARS, which must therefore contain a
list of valid variable names.  The number of variables in DEST_VARS must
be the same as the number of variables in SRC_VARS and the respective
order of the variables in DEST_VARS corresponds to the order of
SRC_VARS.  That is to say, recoded values whose original value came from
the Nth variable in SRC_VARS will be placed into the Nth variable in
DEST_VARS.  The source variables will be unchanged.  If any mapping
implies a string as its destination value, then the respective
destination variable must already exist, or have been declared using
'STRING' or another transformation.  Numeric variables however will be
automatically created if they don't already exist.  The following
example deals with two source variables, A and B which contain string
values.  Hence there are two destination variables V1 and V2.  Any cases
where A or B contain the values 'apple', 'pear' or 'pomegranate' will
result in V1 or V2 being filled with the string 'fruit' whilst cases
with 'tomato', 'lettuce' or 'carrot' will result in 'vegetable'.  Any
other values will produce the result 'unknown':
     string V1 (a20).
     string V2 (a20).

     recode A B
             ("apple" "pear" "pomegranate" = "fruit")
             ("tomato" "lettuce" "carrot" = "vegetable")
             (ELSE = "unknown")
             into V1 V2.

   There is one very special mapping, not mentioned above.  If the
source variable is a string variable then a mapping may be specified as
'(CONVERT)'.  This mapping, if it appears must be the last mapping given
and the 'INTO DEST_VARS' clause must also be given and must not refer to
a string variable.  'CONVERT' causes a number specified as a string to
be converted to a numeric value.  For example it will convert the string
'"3"' into the numeric value 3 (note that it will not convert 'three'
into 3).  If the string cannot be parsed as a number, then the
system-missing value is assigned instead.  In the following example,
cases where the value of X (a string variable) is the empty string, are
recoded to 999 and all others are converted to the numeric equivalent of
the input value.  The results are placed into the numeric variable Y:
     recode X
            ("" = 999)
             (convert)
             into Y.

   It is possible to specify multiple recodings on a single command.
Introduce additional recodings with a slash ('/') to separate them from
the previous recodings:
     recode
             A  (2 = 22) (else = 99)
             /B (1 = 3) into Z
             .
Here we have two recodings.  The first affects the source variable A and
recodes in-place the value 2 into 22 and all other values to 99.  The
second recoding copies the values of B into the variable Z, changing any
instances of 1 into 3.


File: pspp.info,  Node: SORT CASES,  Prev: RECODE,  Up: Data Manipulation

12.8 SORT CASES
===============

     SORT CASES BY VAR_LIST[({D|A}] [ VAR_LIST[({D|A}] ] ...

   'SORT CASES' sorts the active dataset by the values of one or more
variables.

   Specify 'BY' and a list of variables to sort by.  By default,
variables are sorted in ascending order.  To override sort order,
specify '(D)' or '(DOWN)' after a list of variables to get descending
order, or '(A)' or '(UP)' for ascending order.  These apply to all the
listed variables up until the preceding '(A)', '(D)', '(UP)' or
'(DOWN)'.

   The sort algorithms used by 'SORT CASES' are stable.  That is,
records that have equal values of the sort variables will have the same
relative order before and after sorting.  As a special case, re-sorting
an already sorted file will not affect the ordering of cases.

   'SORT CASES' is a procedure.  It causes the data to be read.

   'SORT CASES' attempts to sort the entire active dataset in main
memory.  If workspace is exhausted, it falls back to a merge sort
algorithm that involves creates numerous temporary files.

   'SORT CASES' may not be specified following 'TEMPORARY'.


File: pspp.info,  Node: Data Selection,  Next: Conditionals and Looping,  Prev: Data Manipulation,  Up: Top

13 Selecting data for analysis
******************************

This chapter documents PSPP commands that temporarily or permanently
select data records from the active dataset for analysis.

* Menu:

* FILTER::                      Exclude cases based on a variable.
* N OF CASES::                  Limit the size of the active dataset.
* SAMPLE::                      Select a specified proportion of cases.
* SELECT IF::                   Permanently delete selected cases.
* SPLIT FILE::                  Do multiple analyses with one command.
* TEMPORARY::                   Make transformations' effects temporary.
* WEIGHT::                      Weight cases by a variable.


File: pspp.info,  Node: FILTER,  Next: N OF CASES,  Up: Data Selection

13.1 FILTER
===========

     FILTER BY VAR_NAME.
     FILTER OFF.

   'FILTER' allows a boolean-valued variable to be used to select cases
from the data stream for processing.

   To set up filtering, specify 'BY' and a variable name.  Keyword BY is
optional but recommended.  Cases which have a zero or system- or
user-missing value are excluded from analysis, but not deleted from the
data stream.  Cases with other values are analyzed.  To filter based on
a different condition, use transformations such as 'COMPUTE' or 'RECODE'
to compute a filter variable of the required form, then specify that
variable on 'FILTER'.

   'FILTER OFF' turns off case filtering.

   Filtering takes place immediately before cases pass to a procedure
for analysis.  Only one filter variable may be active at a time.
Normally, case filtering continues until it is explicitly turned off
with 'FILTER OFF'.  However, if 'FILTER' is placed after 'TEMPORARY', it
filters only the next procedure or procedure-like command.


File: pspp.info,  Node: N OF CASES,  Next: SAMPLE,  Prev: FILTER,  Up: Data Selection

13.2 N OF CASES
===============

     N [OF CASES] NUM_OF_CASES [ESTIMATED].

   'N OF CASES' limits the number of cases processed by any procedures
that follow it in the command stream.  'N OF CASES 100', for example,
tells PSPP to disregard all cases after the first 100.

   When 'N OF CASES' is specified after 'TEMPORARY', it affects only the
next procedure (*note TEMPORARY::).  Otherwise, cases beyond the limit
specified are not processed by any later procedure.

   If the limit specified on 'N OF CASES' is greater than the number of
cases in the active dataset, it has no effect.

   When 'N OF CASES' is used along with 'SAMPLE' or 'SELECT IF', the
case limit is applied to the cases obtained after sampling or case
selection, regardless of how 'N OF CASES' is placed relative to 'SAMPLE'
or 'SELECT IF' in the command file.  Thus, the commands 'N OF CASES 100'
and 'SAMPLE .5' will both randomly sample approximately half of the
active dataset's cases, then select the first 100 of those sampled,
regardless of their order in the command file.

   'N OF CASES' with the 'ESTIMATED' keyword gives an estimated number
of cases before 'DATA LIST' or another command to read in data.
'ESTIMATED' never limits the number of cases processed by procedures.
PSPP currently does not make use of case count estimates.


File: pspp.info,  Node: SAMPLE,  Next: SELECT IF,  Prev: N OF CASES,  Up: Data Selection

13.3 SAMPLE
===========

     SAMPLE NUM1 [FROM NUM2].

   'SAMPLE' randomly samples a proportion of the cases in the active
file.  Unless it follows 'TEMPORARY', it operates as a transformation,
permanently removing cases from the active dataset.

   The proportion to sample can be expressed as a single number between
0 and 1.  If K is the number specified, and N is the number of
currently-selected cases in the active dataset, then after 'SAMPLE K.',
approximately K*N cases will be selected.

   The proportion to sample can also be specified in the style 'SAMPLE M
FROM N'.  With this style, cases are selected as follows:

  1. If N is equal to the number of currently-selected cases in the
     active dataset, exactly M cases will be selected.

  2. If N is greater than the number of currently-selected cases in the
     active dataset, an equivalent proportion of cases will be selected.

  3. If N is less than the number of currently-selected cases in the
     active, exactly M cases will be selected _from the first N cases in
     the active dataset._

   'SAMPLE' and 'SELECT IF' are performed in the order specified by the
syntax file.

   'SAMPLE' is always performed before 'N OF CASES', regardless of
ordering in the syntax file (*note N OF CASES::).

   The same values for 'SAMPLE' may result in different samples.  To
obtain the same sample, use the 'SET' command to set the random number
seed to the same value before each 'SAMPLE'.  Different samples may
still result when the file is processed on systems with differing
endianness or floating-point formats.  By default, the random number
seed is based on the system time.


File: pspp.info,  Node: SELECT IF,  Next: SPLIT FILE,  Prev: SAMPLE,  Up: Data Selection

13.4 SELECT IF
==============

     SELECT IF EXPRESSION.

   'SELECT IF' selects cases for analysis based on the value of
EXPRESSION.  Cases not selected are permanently eliminated from the
active dataset, unless 'TEMPORARY' is in effect (*note TEMPORARY::).

   Specify a boolean expression (*note Expressions::).  If the value of
the expression is true for a particular case, the case will be analyzed.
If the expression has a false or missing value, then the case will be
deleted from the data stream.

   Place 'SELECT IF' as early in the command file as possible.  Cases
that are deleted early can be processed more efficiently in time and
space.

   When 'SELECT IF' is specified following 'TEMPORARY' (*note
TEMPORARY::), the 'LAG' function may not be used (*note LAG::).


File: pspp.info,  Node: SPLIT FILE,  Next: TEMPORARY,  Prev: SELECT IF,  Up: Data Selection

13.5 SPLIT FILE
===============

     SPLIT FILE [{LAYERED, SEPARATE}] BY VAR_LIST.
     SPLIT FILE OFF.

   'SPLIT FILE' allows multiple sets of data present in one data file to
be analyzed separately using single statistical procedure commands.

   Specify a list of variable names to analyze multiple sets of data
separately.  Groups of adjacent cases having the same values for these
variables are analyzed by statistical procedure commands as one group.
An independent analysis is carried out for each group of cases, and the
variable values for the group are printed along with the analysis.

   When a list of variable names is specified, one of the keywords
'LAYERED' or 'SEPARATE' may also be specified.  If provided, either
keyword are ignored.

   Groups are formed only by _adjacent_ cases.  To create a split using
a variable where like values are not adjacent in the working file, you
should first sort the data by that variable (*note SORT CASES::).

   Specify 'OFF' to disable 'SPLIT FILE' and resume analysis of the
entire active dataset as a single group of data.

   When 'SPLIT FILE' is specified after 'TEMPORARY', it affects only the
next procedure (*note TEMPORARY::).


File: pspp.info,  Node: TEMPORARY,  Next: WEIGHT,  Prev: SPLIT FILE,  Up: Data Selection

13.6 TEMPORARY
==============

     TEMPORARY.

   'TEMPORARY' is used to make the effects of transformations following
its execution temporary.  These transformations will affect only the
execution of the next procedure or procedure-like command.  Their
effects will not be saved to the active dataset.

   The only specification on 'TEMPORARY' is the command name.

   'TEMPORARY' may not appear within a 'DO IF' or 'LOOP' construct.  It
may appear only once between procedures and procedure-like commands.

   Scratch variables cannot be used following 'TEMPORARY'.

   An example may help to clarify:

     DATA LIST /X 1-2.
     BEGIN DATA.
      2
      4
     10
     15
     20
     24
     END DATA.

     COMPUTE X=X/2.

     TEMPORARY.
     COMPUTE X=X+3.

     DESCRIPTIVES X.
     DESCRIPTIVES X.

   The data read by the first 'DESCRIPTIVES' are 4, 5, 8, 10.5, 13, 15.
The data read by the first 'DESCRIPTIVES' are 1, 2, 5, 7.5, 10, 12.


File: pspp.info,  Node: WEIGHT,  Prev: TEMPORARY,  Up: Data Selection

13.7 WEIGHT
===========

     WEIGHT BY VAR_NAME.
     WEIGHT OFF.

   'WEIGHT' assigns cases varying weights, changing the frequency
distribution of the active dataset.  Execution of 'WEIGHT' is delayed
until data have been read.

   If a variable name is specified, 'WEIGHT' causes the values of that
variable to be used as weighting factors for subsequent statistical
procedures.  Use of keyword 'BY' is optional but recommended.  Weighting
variables must be numeric.  Scratch variables may not be used for
weighting (*note Scratch Variables::).

   When 'OFF' is specified, subsequent statistical procedures will
weight all cases equally.

   A positive integer weighting factor W on a case will yield the same
statistical output as would replicating the case W times.  A weighting
factor of 0 is treated for statistical purposes as if the case did not
exist in the input.  Weighting values need not be integers, but negative
and system-missing values for the weighting variable are interpreted as
weighting factors of 0.  User-missing values are not treated specially.

   When 'WEIGHT' is specified after 'TEMPORARY', it affects only the
next procedure (*note TEMPORARY::).

   'WEIGHT' does not cause cases in the active dataset to be replicated
in memory.


File: pspp.info,  Node: Conditionals and Looping,  Next: Statistics,  Prev: Data Selection,  Up: Top

14 Conditional and Looping Constructs
*************************************

This chapter documents PSPP commands used for conditional execution,
looping, and flow of control.

* Menu:

* BREAK::                       Exit a loop.
* DO IF::                       Conditionally execute a block of code.
* DO REPEAT::                   Textually repeat a code block.
* LOOP::                        Repeat a block of code.


File: pspp.info,  Node: BREAK,  Next: DO IF,  Up: Conditionals and Looping

14.1 BREAK
==========

     BREAK.

   'BREAK' terminates execution of the innermost currently executing
'LOOP' construct.

   'BREAK' is allowed only inside 'LOOP'...'END LOOP'.  *Note LOOP::,
for more details.


File: pspp.info,  Node: DO IF,  Next: DO REPEAT,  Prev: BREAK,  Up: Conditionals and Looping

14.2 DO IF
==========

     DO IF condition.
             ...
     [ELSE IF condition.
             ...
     ]...
     [ELSE.
             ...]
     END IF.

   'DO IF' allows one of several sets of transformations to be executed,
depending on user-specified conditions.

   If the specified boolean expression evaluates as true, then the block
of code following 'DO IF' is executed.  If it evaluates as missing, then
none of the code blocks is executed.  If it is false, then the boolean
expression on the first 'ELSE IF', if present, is tested in turn, with
the same rules applied.  If all expressions evaluate to false, then the
'ELSE' code block is executed, if it is present.

   When 'DO IF' or 'ELSE IF' is specified following 'TEMPORARY' (*note
TEMPORARY::), the 'LAG' function may not be used (*note LAG::).


File: pspp.info,  Node: DO REPEAT,  Next: LOOP,  Prev: DO IF,  Up: Conditionals and Looping

14.3 DO REPEAT
==============

     DO REPEAT dummy_name=expansion....
             ...
     END REPEAT [PRINT].

     expansion takes one of the following forms:
             var_list
             num_or_range...
             'string'...
             ALL

     num_or_range takes one of the following forms:
             number
             num1 TO num2

   'DO REPEAT' repeats a block of code, textually substituting different
variables, numbers, or strings into the block with each repetition.

   Specify a dummy variable name followed by an equals sign ('=') and
the list of replacements.  Replacements can be a list of existing or new
variables, numbers, strings, or 'ALL' to specify all existing variables.
When numbers are specified, runs of increasing integers may be indicated
as 'NUM1 TO NUM2', so that '1 TO 5' is short for '1 2 3 4 5'.

   Multiple dummy variables can be specified.  Each variable must have
the same number of replacements.

   The code within 'DO REPEAT' is repeated as many times as there are
replacements for each variable.  The first time, the first value for
each dummy variable is substituted; the second time, the second value
for each dummy variable is substituted; and so on.

   Dummy variable substitutions work like macros.  They take place
anywhere in a line that the dummy variable name occurs.  This includes
command and subcommand names, so command and subcommand names that
appear in the code block should not be used as dummy variable
identifiers.  Dummy variable substitutions do not occur inside quoted
strings, comments, unquoted strings (such as the text on the 'TITLE' or
'DOCUMENT' command), or inside 'BEGIN DATA'...'END DATA'.

   Substitution occurs only on whole words, so that, for example, a
dummy variable PRINT would not be substituted into the word PRINTOUT.

   New variable names used as replacements are not automatically created
as variables, but only if used in the code block in a context that would
create them, e.g. on a 'NUMERIC' or 'STRING' command or on the left side
of a 'COMPUTE' assignment.

   Any command may appear within 'DO REPEAT', including nested 'DO
REPEAT' commands.  If 'INCLUDE' or 'INSERT' appears within 'DO REPEAT',
the substitutions do not apply to the included file.

   If 'PRINT' is specified on 'END REPEAT', the commands after
substitutions are made are printed to the listing file, prefixed by a
plus sign ('+').


File: pspp.info,  Node: LOOP,  Prev: DO REPEAT,  Up: Conditionals and Looping

14.4 LOOP
=========

     LOOP [INDEX_VAR=START TO END [BY INCR]] [IF CONDITION].
             ...
     END LOOP [IF CONDITION].

   'LOOP' iterates a group of commands.  A number of termination options
are offered.

   Specify index_var to make that variable count from one value to
another by a particular increment.  INDEX_VAR must be a pre-existing
numeric variable.  START, END, and INCR are numeric expressions (*note
Expressions::.)

   During the first iteration, INDEX_VAR is set to the value of START.
During each successive iteration, INDEX_VAR is increased by the value of
INCR.  If END > START, then the loop terminates when INDEX_VAR > END;
otherwise it terminates when INDEX_VAR < END.  If INCR is not specified
then it defaults to +1 or -1 as appropriate.

   If END > START and INCR < 0, or if END < START and INCR > 0, then the
loop is never executed.  INDEX_VAR is nevertheless set to the value of
start.

   Modifying INDEX_VAR within the loop is allowed, but it has no effect
on the value of INDEX_VAR in the next iteration.

   Specify a boolean expression for the condition on 'LOOP' to cause the
loop to be executed only if the condition is true.  If the condition is
false or missing before the loop contents are executed the first time,
the loop contents are not executed at all.

   If index and condition clauses are both present on 'LOOP', the index
variable is always set before the condition is evaluated.  Thus, a
condition that makes use of the index variable will always see the index
value to be used in the next execution of the body.

   Specify a boolean expression for the condition on 'END LOOP' to cause
the loop to terminate if the condition is true after the enclosed code
block is executed.  The condition is evaluated at the end of the loop,
not at the beginning, so that the body of a loop with only a condition
on 'END LOOP' will always execute at least once.

   If neither the index clause nor either condition clause is present,
then the loop is executed MAX_LOOPS (*note SET::) times.  The default
value of MAX_LOOPS is 40.

   'BREAK' also terminates 'LOOP' execution (*note BREAK::).

   Loop index variables are by default reset to system-missing from one
case to another, not left, unless a scratch variable is used as index.
When loops are nested, this is usually undesired behavior, which can be
corrected with 'LEAVE' (*note LEAVE::) or by using a scratch variable as
the loop index.

   When 'LOOP' or 'END LOOP' is specified following 'TEMPORARY' (*note
TEMPORARY::), the 'LAG' function may not be used (*note LAG::).


File: pspp.info,  Node: Statistics,  Next: Utilities,  Prev: Conditionals and Looping,  Up: Top

15 Statistics
*************

This chapter documents the statistical procedures that PSPP supports so
far.

* Menu:

* DESCRIPTIVES::                Descriptive statistics.
* FREQUENCIES::                 Frequency tables.
* EXAMINE::                     Testing data for normality.
* GRAPH::                       Plot data.
* CORRELATIONS::                Correlation tables.
* CROSSTABS::                   Crosstabulation tables.
* FACTOR::                      Factor analysis and Principal Components analysis.
* GLM::                         Univariate Linear Models.
* LOGISTIC REGRESSION::         Bivariate Logistic Regression.
* MEANS::                       Average values and other statistics.
* NPAR TESTS::                  Nonparametric tests.
* T-TEST::                      Test hypotheses about means.
* ONEWAY::                      One way analysis of variance.
* QUICK CLUSTER::               K-Means clustering.
* RANK::                        Compute rank scores.
* REGRESSION::                  Linear regression.
* RELIABILITY::                 Reliability analysis.
* ROC::                         Receiver Operating Characteristic.


File: pspp.info,  Node: DESCRIPTIVES,  Next: FREQUENCIES,  Up: Statistics

15.1 DESCRIPTIVES
=================

     DESCRIPTIVES
             /VARIABLES=VAR_LIST
             /MISSING={VARIABLE,LISTWISE} {INCLUDE,NOINCLUDE}
             /FORMAT={LABELS,NOLABELS} {NOINDEX,INDEX} {LINE,SERIAL}
             /SAVE
             /STATISTICS={ALL,MEAN,SEMEAN,STDDEV,VARIANCE,KURTOSIS,
                          SKEWNESS,RANGE,MINIMUM,MAXIMUM,SUM,DEFAULT,
                          SESKEWNESS,SEKURTOSIS}
             /SORT={NONE,MEAN,SEMEAN,STDDEV,VARIANCE,KURTOSIS,SKEWNESS,
                    RANGE,MINIMUM,MAXIMUM,SUM,SESKEWNESS,SEKURTOSIS,NAME}
                   {A,D}

   The 'DESCRIPTIVES' procedure reads the active dataset and outputs
descriptive statistics requested by the user.  In addition, it can
optionally compute Z-scores.

   The 'VARIABLES' subcommand, which is required, specifies the list of
variables to be analyzed.  Keyword 'VARIABLES' is optional.

   All other subcommands are optional:

   The 'MISSING' subcommand determines the handling of missing
variables.  If 'INCLUDE' is set, then user-missing values are included
in the calculations.  If 'NOINCLUDE' is set, which is the default,
user-missing values are excluded.  If 'VARIABLE' is set, then missing
values are excluded on a variable by variable basis; if 'LISTWISE' is
set, then the entire case is excluded whenever any value in that case
has a system-missing or, if 'INCLUDE' is set, user-missing value.

   The 'FORMAT' subcommand affects the output format.  Currently the
'LABELS/NOLABELS' and 'NOINDEX/INDEX' settings are not used.  When
'SERIAL' is set, both valid and missing number of cases are listed in
the output; when 'NOSERIAL' is set, only valid cases are listed.

   The 'SAVE' subcommand causes 'DESCRIPTIVES' to calculate Z scores for
all the specified variables.  The Z scores are saved to new variables.
Variable names are generated by trying first the original variable name
with Z prepended and truncated to a maximum of 8 characters, then the
names ZSC000 through ZSC999, STDZ00 through STDZ09, ZZZZ00 through
ZZZZ09, ZQZQ00 through ZQZQ09, in that sequence.  In addition, Z score
variable names can be specified explicitly on 'VARIABLES' in the
variable list by enclosing them in parentheses after each variable.
When Z scores are calculated, PSPP ignores 'TEMPORARY', treating
temporary transformations as permanent.

   The 'STATISTICS' subcommand specifies the statistics to be displayed:

'ALL'
     All of the statistics below.
'MEAN'
     Arithmetic mean.
'SEMEAN'
     Standard error of the mean.
'STDDEV'
     Standard deviation.
'VARIANCE'
     Variance.
'KURTOSIS'
     Kurtosis and standard error of the kurtosis.
'SKEWNESS'
     Skewness and standard error of the skewness.
'RANGE'
     Range.
'MINIMUM'
     Minimum value.
'MAXIMUM'
     Maximum value.
'SUM'
     Sum.
'DEFAULT'
     Mean, standard deviation of the mean, minimum, maximum.
'SEKURTOSIS'
     Standard error of the kurtosis.
'SESKEWNESS'
     Standard error of the skewness.

   The 'SORT' subcommand specifies how the statistics should be sorted.
Most of the possible values should be self-explanatory.  'NAME' causes
the statistics to be sorted by name.  By default, the statistics are
listed in the order that they are specified on the 'VARIABLES'
subcommand.  The 'A' and 'D' settings request an ascending or descending
sort order, respectively.


File: pspp.info,  Node: FREQUENCIES,  Next: EXAMINE,  Prev: DESCRIPTIVES,  Up: Statistics

15.2 FREQUENCIES
================

     FREQUENCIES
             /VARIABLES=VAR_LIST
             /FORMAT={TABLE,NOTABLE,LIMIT(LIMIT)}
                     {AVALUE,DVALUE,AFREQ,DFREQ}
             /MISSING={EXCLUDE,INCLUDE}
             /STATISTICS={DEFAULT,MEAN,SEMEAN,MEDIAN,MODE,STDDEV,VARIANCE,
                          KURTOSIS,SKEWNESS,RANGE,MINIMUM,MAXIMUM,SUM,
                          SESKEWNESS,SEKURTOSIS,ALL,NONE}
             /NTILES=NTILES
             /PERCENTILES=percent...
             /HISTOGRAM=[MINIMUM(X_MIN)] [MAXIMUM(X_MAX)]
                        [{FREQ[(Y_MAX)],PERCENT[(Y_MAX)]}] [{NONORMAL,NORMAL}]
             /PIECHART=[MINIMUM(X_MIN)] [MAXIMUM(X_MAX)]
                       [{FREQ,PERCENT}] [{NOMISSING,MISSING}]
             /BARCHART=[MINIMUM(X_MIN)] [MAXIMUM(X_MAX)]
                       [{FREQ,PERCENT}]
             /ORDER={ANALYSIS,VARIABLE}


     (These options are not currently implemented.)
             /HBAR=...
             /GROUPED=...

   The 'FREQUENCIES' procedure outputs frequency tables for specified
variables.  'FREQUENCIES' can also calculate and display descriptive
statistics (including median and mode) and percentiles, and various
graphical representations of the frequency distribution.

   The 'VARIABLES' subcommand is the only required subcommand.  Specify
the variables to be analyzed.

   The 'FORMAT' subcommand controls the output format.  It has several
possible settings:

   '' 'TABLE', the default, causes a frequency table to be output for
     every variable specified.  'NOTABLE' prevents them from being
     output.  'LIMIT' with a numeric argument causes them to be output
     except when there are more than the specified number of values in
     the table.

   '' Normally frequency tables are sorted in ascending order by value.
     This is 'AVALUE'.  'DVALUE' tables are sorted in descending order
     by value.  'AFREQ' and 'DFREQ' tables are sorted in ascending and
     descending order, respectively, by frequency count.

   The 'MISSING' subcommand controls the handling of user-missing
values.  When 'EXCLUDE', the default, is set, user-missing values are
not included in frequency tables or statistics.  When 'INCLUDE' is set,
user-missing are included.  System-missing values are never included in
statistics, but are listed in frequency tables.

   The available 'STATISTICS' are the same as available in
'DESCRIPTIVES' (*note DESCRIPTIVES::), with the addition of 'MEDIAN',
the data's median value, and MODE, the mode.  (If there are multiple
modes, the smallest value is reported.)  By default, the mean, standard
deviation of the mean, minimum, and maximum are reported for each
variable.

   'PERCENTILES' causes the specified percentiles to be reported.  The
percentiles should be presented at a list of numbers between 0 and 100
inclusive.  The 'NTILES' subcommand causes the percentiles to be
reported at the boundaries of the data set divided into the specified
number of ranges.  For instance, '/NTILES=4' would cause quartiles to be
reported.

   The 'HISTOGRAM' subcommand causes the output to include a histogram
for each specified numeric variable.  The X axis by default ranges from
the minimum to the maximum value observed in the data, but the 'MINIMUM'
and 'MAXIMUM' keywords can set an explicit range.  (1) Histograms are
not created for string variables.

   Specify 'NORMAL' to superimpose a normal curve on the histogram.

   The 'PIECHART' subcommand adds a pie chart for each variable to the
data.  Each slice represents one value, with the size of the slice
proportional to the value's frequency.  By default, all non-missing
values are given slices.  The 'MINIMUM' and 'MAXIMUM' keywords can be
used to limit the displayed slices to a given range of values.  The
keyword 'NOMISSING' causes missing values to be omitted from the
piechart.  This is the default.  If instead, 'MISSING' is specified,
then a single slice will be included representing all system missing and
user-missing cases.

   The 'BARCHART' subcommand produces a bar chart for each variable.
The 'MINIMUM' and 'MAXIMUM' keywords can be used to omit categories
whose counts which lie outside the specified limits.  The 'FREQ' option
(default) causes the ordinate to display the frequency of each category,
whereas the 'PERCENT' option will display relative percentages.

   The 'FREQ' and 'PERCENT' options on 'HISTOGRAM' and 'PIECHART' are
accepted but not currently honoured.

   The 'ORDER' subcommand is accepted but ignored.

   ---------- Footnotes ----------

   (1) The number of bins is chosen according to the Freedman-Diaconis
rule: 2 \times IQR(x)n^{-1/3}, where IQR(x) is the interquartile range
of x and n is the number of samples.  Note that 'EXAMINE' uses a
different algorithm to determine bin sizes.


File: pspp.info,  Node: EXAMINE,  Next: GRAPH,  Prev: FREQUENCIES,  Up: Statistics

15.3 EXAMINE
============

     EXAMINE
             VARIABLES= VAR1 [VAR2] ... [VARN]
                [BY FACTOR1 [BY SUBFACTOR1]
                  [ FACTOR2 [BY SUBFACTOR2]]
                  ...
                  [ FACTOR3 [BY SUBFACTOR3]]
                 ]
             /STATISTICS={DESCRIPTIVES, EXTREME[(N)], ALL, NONE}
             /PLOT={BOXPLOT, NPPLOT, HISTOGRAM, SPREADLEVEL[(T)], ALL, NONE}
             /CINTERVAL P
             /COMPARE={GROUPS,VARIABLES}
             /ID=IDENTITY_VARIABLE
             /{TOTAL,NOTOTAL}
             /PERCENTILE=[PERCENTILES]={HAVERAGE, WAVERAGE, ROUND, AEMPIRICAL, EMPIRICAL }
             /MISSING={LISTWISE, PAIRWISE} [{EXCLUDE, INCLUDE}]
     		[{NOREPORT,REPORT}]


   The 'EXAMINE' command is used to perform exploratory data analysis.
In particular, it is useful for testing how closely a distribution
follows a normal distribution, and for finding outliers and extreme
values.

   The 'VARIABLES' subcommand is mandatory.  It specifies the dependent
variables and optionally variables to use as factors for the analysis.
Variables listed before the first 'BY' keyword (if any) are the
dependent variables.  The dependent variables may optionally be followed
by a list of factors which tell PSPP how to break down the analysis for
each dependent variable.

   Following the dependent variables, factors may be specified.  The
factors (if desired) should be preceded by a single 'BY' keyword.  The
format for each factor is
     FACTORVAR [BY SUBFACTORVAR].
   Each unique combination of the values of FACTORVAR and SUBFACTORVAR
divide the dataset into "cells".  Statistics will be calculated for each
cell and for the entire dataset (unless 'NOTOTAL' is given).

   The 'STATISTICS' subcommand specifies which statistics to show.
'DESCRIPTIVES' will produce a table showing some parametric and
non-parametrics statistics.  'EXTREME' produces a table showing the
extremities of each cell.  A number in parentheses, N determines how
many upper and lower extremities to show.  The default number is 5.

   The subcommands 'TOTAL' and 'NOTOTAL' are mutually exclusive.  If
'TOTAL' appears, then statistics will be produced for the entire dataset
as well as for each cell.  If 'NOTOTAL' appears, then statistics will be
produced only for the cells (unless no factor variables have been
given).  These subcommands have no effect if there have been no factor
variables specified.

   The 'PLOT' subcommand specifies which plots are to be produced if
any.  Available plots are 'HISTOGRAM', 'NPPLOT', 'BOXPLOT' and
'SPREADLEVEL'.  The first three can be used to visualise how closely
each cell conforms to a normal distribution, whilst the spread vs. level
plot can be useful to visualise how the variance of differs between
factors.  Boxplots will also show you the outliers and extreme values.
(1)

   The 'SPREADLEVEL' plot displays the interquartile range versus the
median.  It takes an optional parameter T, which specifies how the data
should be transformed prior to plotting.  The given value T is a power
to which the data is raised.  For example, if T is given as 2, then the
data will be squared.  Zero, however is a special value.  If T is 0 or
is omitted, then data will be transformed by taking its natural
logarithm instead of raising to the power of T.

   The 'COMPARE' subcommand is only relevant if producing boxplots, and
it is only useful there is more than one dependent variable and at least
one factor.  If '/COMPARE=GROUPS' is specified, then one plot per
dependent variable is produced, each of which contain boxplots for all
the cells.  If '/COMPARE=VARIABLES' is specified, then one plot per cell
is produced, each containing one boxplot per dependent variable.  If the
'/COMPARE' subcommand is omitted, then PSPP behaves as if
'/COMPARE=GROUPS' were given.

   The 'ID' subcommand is relevant only if '/PLOT=BOXPLOT' or
'/STATISTICS=EXTREME' has been given.  If given, it should provide the
name of a variable which is to be used to labels extreme values and
outliers.  Numeric or string variables are permissible.  If the 'ID'
subcommand is not given, then the case number will be used for
labelling.

   The 'CINTERVAL' subcommand specifies the confidence interval to use
in calculation of the descriptives command.  The default is 95%.

   The 'PERCENTILES' subcommand specifies which percentiles are to be
calculated, and which algorithm to use for calculating them.  The
default is to calculate the 5, 10, 25, 50, 75, 90, 95 percentiles using
the 'HAVERAGE' algorithm.

   The 'TOTAL' and 'NOTOTAL' subcommands are mutually exclusive.  If
'NOTOTAL' is given and factors have been specified in the 'VARIABLES'
subcommand, then then statistics for the unfactored dependent variables
are produced in addition to the factored variables.  If there are no
factors specified then 'TOTAL' and 'NOTOTAL' have no effect.

   The following example will generate descriptive statistics and
histograms for two variables SCORE1 and SCORE2.  Two factors are given,
viz: GENDER and GENDER BY CULTURE.  Therefore, the descriptives and
histograms will be generated for each distinct value of GENDER _and_ for
each distinct combination of the values of GENDER and RACE.  Since the
'NOTOTAL' keyword is given, statistics and histograms for SCORE1 and
SCORE2 covering the whole dataset are not produced.
     EXAMINE SCORE1 SCORE2 BY
             GENDER
             GENDER BY CULTURE
             /STATISTICS = DESCRIPTIVES
             /PLOT = HISTOGRAM
             /NOTOTAL.

   Here is a second example showing how the 'examine' command can be
used to find extremities.
     EXAMINE HEIGHT WEIGHT BY
             GENDER
             /STATISTICS = EXTREME (3)
             /PLOT = BOXPLOT
             /COMPARE = GROUPS
             /ID = NAME.
   In this example, we look at the height and weight of a sample of
individuals and how they differ between male and female.  A table
showing the 3 largest and the 3 smallest values of HEIGHT and WEIGHT for
each gender, and for the whole dataset will be shown.  Boxplots will
also be produced.  Because '/COMPARE = GROUPS' was given, boxplots for
male and female will be shown in the same graphic, allowing us to easily
see the difference between the genders.  Since the variable NAME was
specified on the 'ID' subcommand, this will be used to label the extreme
values.

   *Warning!*  If many dependent variables are specified, or if factor
variables are specified for which there are many distinct values, then
'EXAMINE' will produce a very large quantity of output.

   ---------- Footnotes ----------

   (1) 'HISTOGRAM' uses Sturges' rule to determine the number of bins,
as approximately 1 + \log2(n), where n is the number of samples.  Note
that 'FREQUENCIES' uses a different algorithm to find the bin size.


File: pspp.info,  Node: GRAPH,  Next: CORRELATIONS,  Prev: EXAMINE,  Up: Statistics

15.4 GRAPH
==========

     GRAPH
             /HISTOGRAM [(NORMAL)]= VAR
             /SCATTERPLOT [(BIVARIATE)] = VAR1 WITH VAR2 [BY VAR3]
             /BAR = {SUMMARY-FUNCTION(VAR1) | COUNT-FUNCTION} BY VAR2 [BY VAR3]
             [ /MISSING={LISTWISE, VARIABLE} [{EXCLUDE, INCLUDE}] ]
     		[{NOREPORT,REPORT}]


   The 'GRAPH' produces graphical plots of data.  Only one of the
subcommands 'HISTOGRAM' or 'SCATTERPLOT' can be specified, i.e.  only
one plot can be produced per call of 'GRAPH'.  The 'MISSING' is
optional.

* Menu:

* SCATTERPLOT::             Cartesian Plots
* HISTOGRAM::               Histograms
* BAR CHART::               Bar Charts


File: pspp.info,  Node: SCATTERPLOT,  Next: HISTOGRAM,  Up: GRAPH

15.4.1 Scatterplot
------------------

The subcommand 'SCATTERPLOT' produces an xy plot of the data.  The
different values of the optional third variable VAR3 will result in
different colours and/or markers for the plot.  The following is an
example for producing a scatterplot.

     GRAPH
             /SCATTERPLOT = HEIGHT WITH WEIGHT BY GENDER.

   This example will produce a scatterplot where HEIGHT is plotted
versus WEIGHT.  Depending on the value of the GENDER variable, the
colour of the datapoint is different.  With this plot it is possible to
analyze gender differences for HEIGHT vs. WEIGHT relation.


File: pspp.info,  Node: HISTOGRAM,  Next: BAR CHART,  Prev: SCATTERPLOT,  Up: GRAPH

15.4.2 Histogram
----------------

The subcommand 'HISTOGRAM' produces a histogram.  Only one variable is
allowed for the histogram plot.  The keyword 'NORMAL' may be specified
in parentheses, to indicate that the ideal normal curve should be
superimposed over the histogram.  For an alternative method to produce
histograms *note EXAMINE::.  The following example produces a histogram
plot for the variable WEIGHT.

     GRAPH
             /HISTOGRAM = WEIGHT.


File: pspp.info,  Node: BAR CHART,  Prev: HISTOGRAM,  Up: GRAPH

15.4.3 Bar Chart
----------------

The subcommand 'BAR' produces a bar chart.  This subcommand requires
that a COUNT-FUNCTION be specified (with no arguments) or a
SUMMARY-FUNCTION with a variable VAR1 in parentheses.  Following the
summary or count function, the keyword 'BY' should be specified and then
a catagorical variable, VAR2.  The values of the variable VAR2 determine
the labels of the bars to be plotted.  Optionally a second categorical
variable VAR3 may be specified in which case a clustered (grouped) bar
chart is produced.

   Valid count functions are
'COUNT'
     The weighted counts of the cases in each category.
'PCT'
     The weighted counts of the cases in each category expressed as a
     percentage of the total weights of the cases.
'CUFREQ'
     The cumulative weighted counts of the cases in each category.
'CUPCT'
     The cumulative weighted counts of the cases in each category
     expressed as a percentage of the total weights of the cases.

   The summary function is applied to VAR1 across all cases in each
category.  The recognised summary functions are:
'SUM'
     The sum.
'MEAN'
     The arithmetic mean.
'MAXIMUM'
     The maximum value.
'MINIMUM'
     The minimum value.

   The following examples assume a dataset which is the results of a
survey.  Each respondent has indicated annual income, their sex and city
of residence.  One could create a bar chart showing how the mean income
varies between of residents of different cities, thus:
     GRAPH  /BAR  = MEAN(INCOME) BY CITY.

   This can be extended to also indicate how income in each city differs
between the sexes.
     GRAPH  /BAR  = MEAN(INCOME) BY CITY BY SEX.

   One might also want to see how many respondents there are from each
city.  This can be achieved as follows:
     GRAPH  /BAR  = COUNT BY CITY.

   Bar charts can also be produced using the *note FREQUENCIES:: and
*note CROSSTABS:: commands.


File: pspp.info,  Node: CORRELATIONS,  Next: CROSSTABS,  Prev: GRAPH,  Up: Statistics

15.5 CORRELATIONS
=================

     CORRELATIONS
          /VARIABLES = VAR_LIST [ WITH VAR_LIST ]
          [
           .
           .
           .
           /VARIABLES = VAR_LIST [ WITH VAR_LIST ]
           /VARIABLES = VAR_LIST [ WITH VAR_LIST ]
          ]

          [ /PRINT={TWOTAIL, ONETAIL} {SIG, NOSIG} ]
          [ /STATISTICS=DESCRIPTIVES XPROD ALL]
          [ /MISSING={PAIRWISE, LISTWISE} {INCLUDE, EXCLUDE} ]

   The 'CORRELATIONS' procedure produces tables of the Pearson
correlation coefficient for a set of variables.  The significance of the
coefficients are also given.

   At least one 'VARIABLES' subcommand is required.  If the 'WITH'
keyword is used, then a non-square correlation table will be produced.
The variables preceding 'WITH', will be used as the rows of the table,
and the variables following will be the columns of the table.  If no
'WITH' subcommand is given, then a square, symmetrical table using all
variables is produced.

   The 'MISSING' subcommand determines the handling of missing
variables.  If 'INCLUDE' is set, then user-missing values are included
in the calculations, but system-missing values are not.  If 'EXCLUDE' is
set, which is the default, user-missing values are excluded as well as
system-missing values.

   If 'LISTWISE' is set, then the entire case is excluded from analysis
whenever any variable specified in any '/VARIABLES' subcommand contains
a missing value.  If 'PAIRWISE' is set, then a case is considered
missing only if either of the values for the particular coefficient are
missing.  The default is 'PAIRWISE'.

   The 'PRINT' subcommand is used to control how the reported
significance values are printed.  If the 'TWOTAIL' option is used, then
a two-tailed test of significance is printed.  If the 'ONETAIL' option
is given, then a one-tailed test is used.  The default is 'TWOTAIL'.

   If the 'NOSIG' option is specified, then correlation coefficients
with significance less than 0.05 are highlighted.  If 'SIG' is
specified, then no highlighting is performed.  This is the default.

   The 'STATISTICS' subcommand requests additional statistics to be
displayed.  The keyword 'DESCRIPTIVES' requests that the mean, number of
non-missing cases, and the non-biased estimator of the standard
deviation are displayed.  These statistics will be displayed in a
separated table, for all the variables listed in any '/VARIABLES'
subcommand.  The 'XPROD' keyword requests cross-product deviations and
covariance estimators to be displayed for each pair of variables.  The
keyword 'ALL' is the union of 'DESCRIPTIVES' and 'XPROD'.


File: pspp.info,  Node: CROSSTABS,  Next: FACTOR,  Prev: CORRELATIONS,  Up: Statistics

15.6 CROSSTABS
==============

     CROSSTABS
             /TABLES=VAR_LIST BY VAR_LIST [BY VAR_LIST]...
             /MISSING={TABLE,INCLUDE,REPORT}
             /WRITE={NONE,CELLS,ALL}
             /FORMAT={TABLES,NOTABLES}
                     {PIVOT,NOPIVOT}
                     {AVALUE,DVALUE}
                     {NOINDEX,INDEX}
                     {BOX,NOBOX}
             /CELLS={COUNT,ROW,COLUMN,TOTAL,EXPECTED,RESIDUAL,SRESIDUAL,
                     ASRESIDUAL,ALL,NONE}
             /COUNT={ASIS,CASE,CELL}
                    {ROUND,TRUNCATE}
             /STATISTICS={CHISQ,PHI,CC,LAMBDA,UC,BTAU,CTAU,RISK,GAMMA,D,
                          KAPPA,ETA,CORR,ALL,NONE}
             /BARCHART

     (Integer mode.)
             /VARIABLES=VAR_LIST (LOW,HIGH)...

   The 'CROSSTABS' procedure displays crosstabulation tables requested
by the user.  It can calculate several statistics for each cell in the
crosstabulation tables.  In addition, a number of statistics can be
calculated for each table itself.

   The 'TABLES' subcommand is used to specify the tables to be reported.
Any number of dimensions is permitted, and any number of variables per
dimension is allowed.  The 'TABLES' subcommand may be repeated as many
times as needed.  This is the only required subcommand in "general
mode".

   Occasionally, one may want to invoke a special mode called "integer
mode".  Normally, in general mode, PSPP automatically determines what
values occur in the data.  In integer mode, the user specifies the range
of values that the data assumes.  To invoke this mode, specify the
'VARIABLES' subcommand, giving a range of data values in parentheses for
each variable to be used on the 'TABLES' subcommand.  Data values inside
the range are truncated to the nearest integer, then assigned to that
value.  If values occur outside this range, they are discarded.  When it
is present, the 'VARIABLES' subcommand must precede the 'TABLES'
subcommand.

   In general mode, numeric and string variables may be specified on
TABLES. In integer mode, only numeric variables are allowed.

   The 'MISSING' subcommand determines the handling of user-missing
values.  When set to 'TABLE', the default, missing values are dropped on
a table by table basis.  When set to 'INCLUDE', user-missing values are
included in tables and statistics.  When set to 'REPORT', which is
allowed only in integer mode, user-missing values are included in tables
but marked with an 'M' (for "missing") and excluded from statistical
calculations.

   Currently the 'WRITE' subcommand is ignored.

   The 'FORMAT' subcommand controls the characteristics of the
crosstabulation tables to be displayed.  It has a number of possible
settings:

     'TABLES', the default, causes crosstabulation tables to be output.
     'NOTABLES' suppresses them.

     'PIVOT', the default, causes each 'TABLES' subcommand to be
     displayed in a pivot table format.  'NOPIVOT' causes the old-style
     crosstabulation format to be used.

     'AVALUE', the default, causes values to be sorted in ascending
     order.  'DVALUE' asserts a descending sort order.

     'INDEX' and 'NOINDEX' are currently ignored.

     'BOX' and 'NOBOX' is currently ignored.

   The 'CELLS' subcommand controls the contents of each cell in the
displayed crosstabulation table.  The possible settings are:

COUNT
     Frequency count.
ROW
     Row percent.
COLUMN
     Column percent.
TOTAL
     Table percent.
EXPECTED
     Expected value.
RESIDUAL
     Residual.
SRESIDUAL
     Standardized residual.
ASRESIDUAL
     Adjusted standardized residual.
ALL
     All of the above.
NONE
     Suppress cells entirely.

   '/CELLS' without any settings specified requests 'COUNT', 'ROW',
'COLUMN', and 'TOTAL'.  If 'CELLS' is not specified at all then only
'COUNT' will be selected.

   By default, crosstabulation and statistics use raw case weights,
without rounding.  Use the '/COUNT' subcommand to perform rounding: CASE
rounds the weights of individual weights as cases are read, CELL rounds
the weights of cells within each crosstabulation table after it has been
constructed, and ASIS explicitly specifies the default non-rounding
behavior.  When rounding is requested, ROUND, the default, rounds to the
nearest integer and TRUNCATE rounds toward zero.

   The 'STATISTICS' subcommand selects statistics for computation:

CHISQ

     Pearson chi-square, likelihood ratio, Fisher's exact test,
     continuity correction, linear-by-linear association.
PHI
     Phi.
CC
     Contingency coefficient.
LAMBDA
     Lambda.
UC
     Uncertainty coefficient.
BTAU
     Tau-b.
CTAU
     Tau-c.
RISK
     Risk estimate.
GAMMA
     Gamma.
D
     Somers' D.
KAPPA
     Cohen's Kappa.
ETA
     Eta.
CORR
     Spearman correlation, Pearson's r.
ALL
     All of the above.
NONE
     No statistics.

   Selected statistics are only calculated when appropriate for the
statistic.  Certain statistics require tables of a particular size, and
some statistics are calculated only in integer mode.

   '/STATISTICS' without any settings selects CHISQ. If the 'STATISTICS'
subcommand is not given, no statistics are calculated.

   The '/BARCHART' subcommand produces a clustered bar chart for the
first two variables on each table.  If a table has more than two
variables, the counts for the third and subsequent levels will be
aggregated and the chart will be produces as if there were only two
variables.

   *Please note:* Currently the implementation of 'CROSSTABS' has the
following limitations:

   * Significance of some symmetric and directional measures is not
     calculated.
   * Asymptotic standard error is not calculated for Goodman and
     Kruskal's tau or symmetric Somers' d.
   * Approximate T is not calculated for symmetric uncertainty
     coefficient.

   Fixes for any of these deficiencies would be welcomed.


File: pspp.info,  Node: FACTOR,  Next: GLM,  Prev: CROSSTABS,  Up: Statistics

15.7 FACTOR
===========

     FACTOR  VARIABLES=VAR_LIST

             [ /METHOD = {CORRELATION, COVARIANCE} ]

             [ /ANALYSIS=VAR_LIST ]

             [ /EXTRACTION={PC, PAF}]

             [ /ROTATION={VARIMAX, EQUAMAX, QUARTIMAX, PROMAX[(K)], NOROTATE}]

             [ /PRINT=[INITIAL] [EXTRACTION] [ROTATION] [UNIVARIATE] [CORRELATION] [COVARIANCE] [DET] [KMO] [SIG] [ALL] [DEFAULT] ]

             [ /PLOT=[EIGEN] ]

             [ /FORMAT=[SORT] [BLANK(N)] [DEFAULT] ]

             [ /CRITERIA=[FACTORS(N)] [MINEIGEN(L)] [ITERATE(M)] [ECONVERGE (DELTA)] [DEFAULT] ]

             [ /MISSING=[{LISTWISE, PAIRWISE}] [{INCLUDE, EXCLUDE}] ]

   The 'FACTOR' command performs Factor Analysis or Principal Axis
Factoring on a dataset.  It may be used to find common factors in the
data or for data reduction purposes.

   The 'VARIABLES' subcommand is required.  It lists the variables which
are to partake in the analysis.  (The 'ANALYSIS' subcommand may
optionally further limit the variables that participate; it is not
useful and implemented only for compatibility.)

   The '/EXTRACTION' subcommand is used to specify the way in which
factors (components) are extracted from the data.  If 'PC' is specified,
then Principal Components Analysis is used.  If 'PAF' is specified, then
Principal Axis Factoring is used.  By default Principal Components
Analysis will be used.

   The '/ROTATION' subcommand is used to specify the method by which the
extracted solution will be rotated.  Three orthogonal rotation methods
are available: 'VARIMAX' (which is the default), 'EQUAMAX', and
'QUARTIMAX'.  There is one oblique rotation method, viz: 'PROMAX'.
Optionally you may enter the power of the promax rotation K, which must
be enclosed in parentheses.  The default value of K is 5.  If you don't
want any rotation to be performed, the word 'NOROTATE' will prevent the
command from performing any rotation on the data.

   The '/METHOD' subcommand should be used to determine whether the
covariance matrix or the correlation matrix of the data is to be
analysed.  By default, the correlation matrix is analysed.

   The '/PRINT' subcommand may be used to select which features of the
analysis are reported:

   * 'UNIVARIATE' A table of mean values, standard deviations and total
     weights are printed.
   * 'INITIAL' Initial communalities and eigenvalues are printed.
   * 'EXTRACTION' Extracted communalities and eigenvalues are printed.
   * 'ROTATION' Rotated communalities and eigenvalues are printed.
   * 'CORRELATION' The correlation matrix is printed.
   * 'COVARIANCE' The covariance matrix is printed.
   * 'DET' The determinant of the correlation or covariance matrix is
     printed.
   * 'KMO' The Kaiser-Meyer-Olkin measure of sampling adequacy and the
     Bartlett test of sphericity is printed.
   * 'SIG' The significance of the elements of correlation matrix is
     printed.
   * 'ALL' All of the above are printed.
   * 'DEFAULT' Identical to 'INITIAL' and 'EXTRACTION'.

   If '/PLOT=EIGEN' is given, then a "Scree" plot of the eigenvalues
will be printed.  This can be useful for visualizing which factors
(components) should be retained.

   The '/FORMAT' subcommand determined how data are to be displayed in
loading matrices.  If 'SORT' is specified, then the variables are sorted
in descending order of significance.  If 'BLANK(N)' is specified, then
coefficients whose absolute value is less than N will not be printed.
If the keyword 'DEFAULT' is given, or if no '/FORMAT' subcommand is
given, then no sorting is performed, and all coefficients will be
printed.

   The '/CRITERIA' subcommand is used to specify how the number of
extracted factors (components) are chosen.  If 'FACTORS(N)' is
specified, where N is an integer, then N factors will be extracted.
Otherwise, the 'MINEIGEN' setting will be used.  'MINEIGEN(L)' requests
that all factors whose eigenvalues are greater than or equal to L are
extracted.  The default value of L is 1.  The 'ECONVERGE' setting has
effect only when iterative algorithms for factor extraction (such as
Principal Axis Factoring) are used.  'ECONVERGE(DELTA)' specifies that
iteration should cease when the maximum absolute value of the
communality estimate between one iteration and the previous is less than
DELTA.  The default value of DELTA is 0.001.  The 'ITERATE(M)' may
appear any number of times and is used for two different purposes.  It
is used to set the maximum number of iterations (M) for convergence and
also to set the maximum number of iterations for rotation.  Whether it
affects convergence or rotation depends upon which subcommand follows
the 'ITERATE' subcommand.  If 'EXTRACTION' follows, it affects
convergence.  If 'ROTATION' follows, it affects rotation.  If neither
'ROTATION' nor 'EXTRACTION' follow a 'ITERATE' subcommand it will be
ignored.  The default value of M is 25.

   The 'MISSING' subcommand determines the handling of missing
variables.  If 'INCLUDE' is set, then user-missing values are included
in the calculations, but system-missing values are not.  If 'EXCLUDE' is
set, which is the default, user-missing values are excluded as well as
system-missing values.  This is the default.  If 'LISTWISE' is set, then
the entire case is excluded from analysis whenever any variable
specified in the 'VARIABLES' subcommand contains a missing value.  If
'PAIRWISE' is set, then a case is considered missing only if either of
the values for the particular coefficient are missing.  The default is
'LISTWISE'.


File: pspp.info,  Node: GLM,  Next: LOGISTIC REGRESSION,  Prev: FACTOR,  Up: Statistics

15.8 GLM
========

     GLM DEPENDENT_VARS BY FIXED_FACTORS
          [/METHOD = SSTYPE(TYPE)]
          [/DESIGN = INTERACTION_0 [INTERACTION_1 [... INTERACTION_N]]]
          [/INTERCEPT = {INCLUDE|EXCLUDE}]
          [/MISSING = {INCLUDE|EXCLUDE}]

   The 'GLM' procedure can be used for fixed effects factorial Anova.

   The DEPENDENT_VARS are the variables to be analysed.  You may analyse
several variables in the same command in which case they should all
appear before the 'BY' keyword.

   The FIXED_FACTORS list must be one or more categorical variables.
Normally it will not make sense to enter a scalar variable in the
FIXED_FACTORS and doing so may cause PSPP to do a lot of unnecessary
processing.

   The 'METHOD' subcommand is used to change the method for producing
the sums of squares.  Available values of TYPE are 1, 2 and 3.  The
default is type 3.

   You may specify a custom design using the 'DESIGN' subcommand.  The
design comprises a list of interactions where each interaction is a list
of variables separated by a '*'.  For example the command
     GLM subject BY sex age_group race
         /DESIGN = age_group sex group age_group*sex age_group*race
specifies the model subject = age_group + sex + race + age_group*sex +
age_group*race.  If no 'DESIGN' subcommand is specified, then the
default is all possible combinations of the fixed factors.  That is to
say
     GLM subject BY sex age_group race
   implies the model subject = age_group + sex + race + age_group*sex +
age_group*race + sex*race + age_group*sex*race.

   The 'MISSING' subcommand determines the handling of missing
variables.  If 'INCLUDE' is set then, for the purposes of GLM analysis,
only system-missing values are considered to be missing; user-missing
values are not regarded as missing.  If 'EXCLUDE' is set, which is the
default, then user-missing values are considered to be missing as well
as system-missing values.  A case for which any dependent variable or
any factor variable has a missing value is excluded from the analysis.


File: pspp.info,  Node: LOGISTIC REGRESSION,  Next: MEANS,  Prev: GLM,  Up: Statistics

15.9 LOGISTIC REGRESSION
========================

     LOGISTIC REGRESSION [VARIABLES =] DEPENDENT_VAR WITH PREDICTORS

          [/CATEGORICAL = CATEGORICAL_PREDICTORS]

          [{/NOCONST | /ORIGIN | /NOORIGIN }]

          [/PRINT = [SUMMARY] [DEFAULT] [CI(CONFIDENCE)] [ALL]]

          [/CRITERIA = [BCON(MIN_DELTA)] [ITERATE(MAX_INTERATIONS)]
                       [LCON(MIN_LIKELIHOOD_DELTA)] [EPS(MIN_EPSILON)]
                       [CUT(CUT_POINT)]]

          [/MISSING = {INCLUDE|EXCLUDE}]

   Bivariate Logistic Regression is used when you want to explain a
dichotomous dependent variable in terms of one or more predictor
variables.

   The minimum command is
     LOGISTIC REGRESSION Y WITH X1 X2 ... XN.
   Here, Y is the dependent variable, which must be dichotomous and X1
... XN are the predictor variables whose coefficients the procedure
estimates.

   By default, a constant term is included in the model.  Hence, the
full model is {\bf y} = b_0 + b_1 {\bf x_1} + b_2 {\bf x_2} + \dots +
b_n {\bf x_n}

   Predictor variables which are categorical in nature should be listed
on the '/CATEGORICAL' subcommand.  Simple variables as well as
interactions between variables may be listed here.

   If you want a model without the constant term b_0, use the keyword
'/ORIGIN'.  '/NOCONST' is a synonym for '/ORIGIN'.

   An iterative Newton-Raphson procedure is used to fit the model.  The
'/CRITERIA' subcommand is used to specify the stopping criteria of the
procedure, and other parameters.  The value of CUT_POINT is used in the
classification table.  It is the threshold above which predicted values
are considered to be 1.  Values of CUT_POINT must lie in the range
[0,1].  During iterations, if any one of the stopping criteria are
satisfied, the procedure is considered complete.  The stopping criteria
are:
   * The number of iterations exceeds MAX_ITERATIONS. The default value
     of MAX_ITERATIONS is 20.
   * The change in the all coefficient estimates are less than
     MIN_DELTA.  The default value of MIN_DELTA is 0.001.
   * The magnitude of change in the likelihood estimate is less than
     MIN_LIKELIHOOD_DELTA.  The default value of MIN_DELTA is zero.
     This means that this criterion is disabled.
   * The differential of the estimated probability for all cases is less
     than MIN_EPSILON.  In other words, the probabilities are close to
     zero or one.  The default value of MIN_EPSILON is 0.00000001.

   The 'PRINT' subcommand controls the display of optional statistics.
Currently there is one such option, 'CI', which indicates that the
confidence interval of the odds ratio should be displayed as well as its
value.  'CI' should be followed by an integer in parentheses, to
indicate the confidence level of the desired confidence interval.

   The 'MISSING' subcommand determines the handling of missing
variables.  If 'INCLUDE' is set, then user-missing values are included
in the calculations, but system-missing values are not.  If 'EXCLUDE' is
set, which is the default, user-missing values are excluded as well as
system-missing values.  This is the default.


File: pspp.info,  Node: MEANS,  Next: NPAR TESTS,  Prev: LOGISTIC REGRESSION,  Up: Statistics

15.10 MEANS
===========

     MEANS [TABLES =]
           {VAR_LIST}
             [ BY {VAR_LIST} [BY {VAR_LIST} [BY {VAR_LIST} ... ]]]

           [ /{VAR_LIST}
              [ BY {VAR_LIST} [BY {VAR_LIST} [BY {VAR_LIST} ... ]]] ]

           [/CELLS = [MEAN] [COUNT] [STDDEV] [SEMEAN] [SUM] [MIN] [MAX] [RANGE]
             [VARIANCE] [KURT] [SEKURT]
             [SKEW] [SESKEW] [FIRST] [LAST]
             [HARMONIC] [GEOMETRIC]
             [DEFAULT]
             [ALL]
             [NONE] ]

           [/MISSING = [TABLE] [INCLUDE] [DEPENDENT]]

   You can use the 'MEANS' command to calculate the arithmetic mean and
similar statistics, either for the dataset as a whole or for categories
of data.

   The simplest form of the command is
     MEANS V.
which calculates the mean, count and standard deviation for V.  If you
specify a grouping variable, for example
     MEANS V BY G.
then the means, counts and standard deviations for V after having been
grouped by G will be calculated.  Instead of the mean, count and
standard deviation, you could specify the statistics in which you are
interested:
     MEANS X Y BY G
           /CELLS = HARMONIC SUM MIN.
   This example calculates the harmonic mean, the sum and the minimum
values of X and Y grouped by G.

   The 'CELLS' subcommand specifies which statistics to calculate.  The
available statistics are:
   * 'MEAN' The arithmetic mean.
   * 'COUNT' The count of the values.
   * 'STDDEV' The standard deviation.
   * 'SEMEAN' The standard error of the mean.
   * 'SUM' The sum of the values.
   * 'MIN' The minimum value.
   * 'MAX' The maximum value.
   * 'RANGE' The difference between the maximum and minimum values.
   * 'VARIANCE' The variance.
   * 'FIRST' The first value in the category.
   * 'LAST' The last value in the category.
   * 'SKEW' The skewness.
   * 'SESKEW' The standard error of the skewness.
   * 'KURT' The kurtosis
   * 'SEKURT' The standard error of the kurtosis.
   * 'HARMONIC' The harmonic mean.
   * 'GEOMETRIC' The geometric mean.

   In addition, three special keywords are recognized:
   * 'DEFAULT' This is the same as 'MEAN' 'COUNT' 'STDDEV'.
   * 'ALL' All of the above statistics will be calculated.
   * 'NONE' No statistics will be calculated (only a summary will be
     shown).

   More than one "table" can be specified in a single command.  Each
table is separated by a '/'.  For example
     MEANS TABLES =
           C D E BY X
           /A B BY X Y
           /F BY Y BY Z.
   has three tables (the 'TABLE =' is optional).  The first table has
three dependent variables C, D and E and a single categorical variable
X.  The second table has two dependent variables A and B, and two
categorical variables X and Y.  The third table has a single dependent
variables F and a categorical variable formed by the combination of Y
and Z.

   By default values are omitted from the analysis only if missing
values (either system missing or user missing) for any of the variables
directly involved in their calculation are encountered.  This behaviour
can be modified with the '/MISSING' subcommand.  Three options are
possible: 'TABLE', 'INCLUDE' and 'DEPENDENT'.

   '/MISSING = TABLE' causes cases to be dropped if any variable is
missing in the table specification currently being processed, regardless
of whether it is needed to calculate the statistic.

   '/MISSING = INCLUDE' says that user missing values, either in the
dependent variables or in the categorical variables should be taken at
their face value, and not excluded.

   '/MISSING = DEPENDENT' says that user missing values, in the
dependent variables should be taken at their face value, however cases
which have user missing values for the categorical variables should be
omitted from the calculation.


File: pspp.info,  Node: NPAR TESTS,  Next: T-TEST,  Prev: MEANS,  Up: Statistics

15.11 NPAR TESTS
================

     NPAR TESTS

          nonparametric test subcommands
          .
          .
          .

          [ /STATISTICS={DESCRIPTIVES} ]

          [ /MISSING={ANALYSIS, LISTWISE} {INCLUDE, EXCLUDE} ]

          [ /METHOD=EXACT [ TIMER [(N)] ] ]

   'NPAR TESTS' performs nonparametric tests.  Non parametric tests make
very few assumptions about the distribution of the data.  One or more
tests may be specified by using the corresponding subcommand.  If the
'/STATISTICS' subcommand is also specified, then summary statistics are
produces for each variable that is the subject of any test.

   Certain tests may take a long time to execute, if an exact figure is
required.  Therefore, by default asymptotic approximations are used
unless the subcommand '/METHOD=EXACT' is specified.  Exact tests give
more accurate results, but may take an unacceptably long time to
perform.  If the 'TIMER' keyword is used, it sets a maximum time, after
which the test will be abandoned, and a warning message printed.  The
time, in minutes, should be specified in parentheses after the 'TIMER'
keyword.  If the 'TIMER' keyword is given without this figure, then a
default value of 5 minutes is used.

* Menu:

* BINOMIAL::                Binomial Test
* CHISQUARE::               Chisquare Test
* COCHRAN::                 Cochran Q Test
* FRIEDMAN::                Friedman Test
* KENDALL::                 Kendall's W Test
* KOLMOGOROV-SMIRNOV::      Kolmogorov Smirnov Test
* KRUSKAL-WALLIS::          Kruskal-Wallis Test
* MANN-WHITNEY::            Mann Whitney U Test
* MCNEMAR::                 McNemar Test
* MEDIAN::                  Median Test
* RUNS::                    Runs Test
* SIGN::                    The Sign Test
* WILCOXON::                Wilcoxon Signed Ranks Test


File: pspp.info,  Node: BINOMIAL,  Next: CHISQUARE,  Up: NPAR TESTS

15.11.1 Binomial test
---------------------

          [ /BINOMIAL[(P)]=VAR_LIST[(VALUE1[, VALUE2)] ] ]

   The '/BINOMIAL' subcommand compares the observed distribution of a
dichotomous variable with that of a binomial distribution.  The variable
P specifies the test proportion of the binomial distribution.  The
default value of 0.5 is assumed if P is omitted.

   If a single value appears after the variable list, then that value is
used as the threshold to partition the observed values.  Values less
than or equal to the threshold value form the first category.  Values
greater than the threshold form the second category.

   If two values appear after the variable list, then they will be used
as the values which a variable must take to be in the respective
category.  Cases for which a variable takes a value equal to neither of
the specified values, take no part in the test for that variable.

   If no values appear, then the variable must assume dichotomous
values.  If more than two distinct, non-missing values for a variable
under test are encountered then an error occurs.

   If the test proportion is equal to 0.5, then a two tailed test is
reported.  For any other test proportion, a one tailed test is reported.
For one tailed tests, if the test proportion is less than or equal to
the observed proportion, then the significance of observing the observed
proportion or more is reported.  If the test proportion is more than the
observed proportion, then the significance of observing the observed
proportion or less is reported.  That is to say, the test is always
performed in the observed direction.

   PSPP uses a very precise approximation to the gamma function to
compute the binomial significance.  Thus, exact results are reported
even for very large sample sizes.


File: pspp.info,  Node: CHISQUARE,  Next: COCHRAN,  Prev: BINOMIAL,  Up: NPAR TESTS

15.11.2 Chisquare Test
----------------------

          [ /CHISQUARE=VAR_LIST[(LO,HI)] [/EXPECTED={EQUAL|F1, F2 ... FN}] ]

   The '/CHISQUARE' subcommand produces a chi-square statistic for the
differences between the expected and observed frequencies of the
categories of a variable.  Optionally, a range of values may appear
after the variable list.  If a range is given, then non integer values
are truncated, and values outside the specified range are excluded from
the analysis.

   The '/EXPECTED' subcommand specifies the expected values of each
category.  There must be exactly one non-zero expected value, for each
observed category, or the 'EQUAL' keyword must be specified.  You may
use the notation 'N*F' to specify N consecutive expected categories all
taking a frequency of F.  The frequencies given are proportions, not
absolute frequencies.  The sum of the frequencies need not be 1.  If no
'/EXPECTED' subcommand is given, then then equal frequencies are
expected.


File: pspp.info,  Node: COCHRAN,  Next: FRIEDMAN,  Prev: CHISQUARE,  Up: NPAR TESTS

15.11.3 Cochran Q Test
----------------------

          [ /COCHRAN = VAR_LIST ]

   The Cochran Q test is used to test for differences between three or
more groups.  The data for VAR_LIST in all cases must assume exactly two
distinct values (other than missing values).

   The value of Q will be displayed and its Asymptotic significance
based on a chi-square distribution.


File: pspp.info,  Node: FRIEDMAN,  Next: KENDALL,  Prev: COCHRAN,  Up: NPAR TESTS

15.11.4 Friedman Test
---------------------

          [ /FRIEDMAN = VAR_LIST ]

   The Friedman test is used to test for differences between repeated
measures when there is no indication that the distributions are normally
distributed.

   A list of variables which contain the measured data must be given.
The procedure prints the sum of ranks for each variable, the test
statistic and its significance.


File: pspp.info,  Node: KENDALL,  Next: KOLMOGOROV-SMIRNOV,  Prev: FRIEDMAN,  Up: NPAR TESTS

15.11.5 Kendall's W Test
------------------------

          [ /KENDALL = VAR_LIST ]

   The Kendall test investigates whether an arbitrary number of related
samples come from the same population.  It is identical to the Friedman
test except that the additional statistic W, Kendall's Coefficient of
Concordance is printed.  It has the range [0,1] -- a value of zero
indicates no agreement between the samples whereas a value of unity
indicates complete agreement.


File: pspp.info,  Node: KOLMOGOROV-SMIRNOV,  Next: KRUSKAL-WALLIS,  Prev: KENDALL,  Up: NPAR TESTS

15.11.6 Kolmogorov-Smirnov Test
-------------------------------

          [ /KOLMOGOROV-SMIRNOV ({NORMAL [MU, SIGMA], UNIFORM [MIN, MAX], POISSON [LAMBDA], EXPONENTIAL [SCALE] }) = VAR_LIST ]

   The one sample Kolmogorov-Smirnov subcommand is used to test whether
or not a dataset is drawn from a particular distribution.  Four
distributions are supported, viz: Normal, Uniform, Poisson and
Exponential.

   Ideally you should provide the parameters of the distribution against
which you wish to test the data.  For example, with the normal
distribution the mean (MU)and standard deviation (SIGMA) should be
given; with the uniform distribution, the minimum (MIN)and maximum (MAX)
value should be provided.  However, if the parameters are omitted they
will be imputed from the data.  Imputing the parameters reduces the
power of the test so should be avoided if possible.

   In the following example, two variables SCORE and AGE are tested to
see if they follow a normal distribution with a mean of 3.5 and a
standard deviation of 2.0.
       NPAR TESTS
             /KOLMOGOROV-SMIRNOV (normal 3.5 2.0) = SCORE AGE.
   If the variables need to be tested against different distributions,
then a separate subcommand must be used.  For example the following
syntax tests SCORE against a normal distribution with mean of 3.5 and
standard deviation of 2.0 whilst AGE is tested against a normal
distribution of mean 40 and standard deviation 1.5.
       NPAR TESTS
             /KOLMOGOROV-SMIRNOV (normal 3.5 2.0) = SCORE
             /KOLMOGOROV-SMIRNOV (normal 40 1.5) =  AGE.

   The abbreviated subcommand 'K-S' may be used in place of
'KOLMOGOROV-SMIRNOV'.


File: pspp.info,  Node: KRUSKAL-WALLIS,  Next: MANN-WHITNEY,  Prev: KOLMOGOROV-SMIRNOV,  Up: NPAR TESTS

15.11.7 Kruskal-Wallis Test
---------------------------

          [ /KRUSKAL-WALLIS = VAR_LIST BY var (LOWER, UPPER) ]

   The Kruskal-Wallis test is used to compare data from an arbitrary
number of populations.  It does not assume normality.  The data to be
compared are specified by VAR_LIST.  The categorical variable
determining the groups to which the data belongs is given by VAR.  The
limits LOWER and UPPER specify the valid range of VAR.  Any cases for
which VAR falls outside [LOWER, UPPER] will be ignored.

   The mean rank of each group as well as the chi-squared value and
significance of the test will be printed.  The abbreviated subcommand
'K-W' may be used in place of 'KRUSKAL-WALLIS'.


File: pspp.info,  Node: MANN-WHITNEY,  Next: MCNEMAR,  Prev: KRUSKAL-WALLIS,  Up: NPAR TESTS

15.11.8 Mann-Whitney U Test
---------------------------

          [ /MANN-WHITNEY = VAR_LIST BY var (GROUP1, GROUP2) ]

   The Mann-Whitney subcommand is used to test whether two groups of
data come from different populations.  The variables to be tested should
be specified in VAR_LIST and the grouping variable, that determines to
which group the test variables belong, in VAR.  VAR may be either a
string or an alpha variable.  GROUP1 and GROUP2 specify the two values
of VAR which determine the groups of the test data.  Cases for which the
VAR value is neither GROUP1 or GROUP2 will be ignored.

   The value of the Mann-Whitney U statistic, the Wilcoxon W, and the
significance will be printed.  The abbreviated subcommand 'M-W' may be
used in place of 'MANN-WHITNEY'.


File: pspp.info,  Node: MCNEMAR,  Next: MEDIAN,  Prev: MANN-WHITNEY,  Up: NPAR TESTS

15.11.9 McNemar Test
--------------------

          [ /MCNEMAR VAR_LIST [ WITH VAR_LIST [ (PAIRED) ]]]

   Use McNemar's test to analyse the significance of the difference
between pairs of correlated proportions.

   If the 'WITH' keyword is omitted, then tests for all combinations of
the listed variables are performed.  If the 'WITH' keyword is given, and
the '(PAIRED)' keyword is also given, then the number of variables
preceding 'WITH' must be the same as the number following it.  In this
case, tests for each respective pair of variables are performed.  If the
'WITH' keyword is given, but the '(PAIRED)' keyword is omitted, then
tests for each combination of variable preceding 'WITH' against variable
following 'WITH' are performed.

   The data in each variable must be dichotomous.  If there are more
than two distinct variables an error will occur and the test will not be
run.


File: pspp.info,  Node: MEDIAN,  Next: RUNS,  Prev: MCNEMAR,  Up: NPAR TESTS

15.11.10 Median Test
--------------------

          [ /MEDIAN [(VALUE)] = VAR_LIST BY VARIABLE (VALUE1, VALUE2) ]

   The median test is used to test whether independent samples come from
populations with a common median.  The median of the populations against
which the samples are to be tested may be given in parentheses
immediately after the '/MEDIAN' subcommand.  If it is not given, the
median will be imputed from the union of all the samples.

   The variables of the samples to be tested should immediately follow
the '=' sign.  The keyword 'BY' must come next, and then the grouping
variable.  Two values in parentheses should follow.  If the first value
is greater than the second, then a 2 sample test is performed using
these two values to determine the groups.  If however, the first
variable is less than the second, then a k sample test is conducted and
the group values used are all values encountered which lie in the range
[VALUE1,VALUE2].


File: pspp.info,  Node: RUNS,  Next: SIGN,  Prev: MEDIAN,  Up: NPAR TESTS

15.11.11 Runs Test
------------------

          [ /RUNS ({MEAN, MEDIAN, MODE, VALUE})  = VAR_LIST ]

   The '/RUNS' subcommand tests whether a data sequence is randomly
ordered.

   It works by examining the number of times a variable's value crosses
a given threshold.  The desired threshold must be specified within
parentheses.  It may either be specified as a number or as one of
'MEAN', 'MEDIAN' or 'MODE'.  Following the threshold specification comes
the list of variables whose values are to be tested.

   The subcommand shows the number of runs, the asymptotic significance
based on the length of the data.


File: pspp.info,  Node: SIGN,  Next: WILCOXON,  Prev: RUNS,  Up: NPAR TESTS

15.11.12 Sign Test
------------------

          [ /SIGN VAR_LIST [ WITH VAR_LIST [ (PAIRED) ]]]

   The '/SIGN' subcommand tests for differences between medians of the
variables listed.  The test does not make any assumptions about the
distribution of the data.

   If the 'WITH' keyword is omitted, then tests for all combinations of
the listed variables are performed.  If the 'WITH' keyword is given, and
the '(PAIRED)' keyword is also given, then the number of variables
preceding 'WITH' must be the same as the number following it.  In this
case, tests for each respective pair of variables are performed.  If the
'WITH' keyword is given, but the '(PAIRED)' keyword is omitted, then
tests for each combination of variable preceding 'WITH' against variable
following 'WITH' are performed.


File: pspp.info,  Node: WILCOXON,  Prev: SIGN,  Up: NPAR TESTS

15.11.13 Wilcoxon Matched Pairs Signed Ranks Test
-------------------------------------------------

          [ /WILCOXON VAR_LIST [ WITH VAR_LIST [ (PAIRED) ]]]

   The '/WILCOXON' subcommand tests for differences between medians of
the variables listed.  The test does not make any assumptions about the
variances of the samples.  It does however assume that the distribution
is symmetrical.

   If the 'WITH' keyword is omitted, then tests for all combinations of
the listed variables are performed.  If the 'WITH' keyword is given, and
the '(PAIRED)' keyword is also given, then the number of variables
preceding 'WITH' must be the same as the number following it.  In this
case, tests for each respective pair of variables are performed.  If the
'WITH' keyword is given, but the '(PAIRED)' keyword is omitted, then
tests for each combination of variable preceding 'WITH' against variable
following 'WITH' are performed.


File: pspp.info,  Node: T-TEST,  Next: ONEWAY,  Prev: NPAR TESTS,  Up: Statistics

15.12 T-TEST
============

     T-TEST
             /MISSING={ANALYSIS,LISTWISE} {EXCLUDE,INCLUDE}
             /CRITERIA=CI(CONFIDENCE)


     (One Sample mode.)
             TESTVAL=TEST_VALUE
             /VARIABLES=VAR_LIST


     (Independent Samples mode.)
             GROUPS=var(VALUE1 [, VALUE2])
             /VARIABLES=VAR_LIST


     (Paired Samples mode.)
             PAIRS=VAR_LIST [WITH VAR_LIST [(PAIRED)] ]


   The 'T-TEST' procedure outputs tables used in testing hypotheses
about means.  It operates in one of three modes:
   * One Sample mode.
   * Independent Groups mode.
   * Paired mode.

Each of these modes are described in more detail below.  There are two
optional subcommands which are common to all modes.

   The '/CRITERIA' subcommand tells PSPP the confidence interval used in
the tests.  The default value is 0.95.

   The 'MISSING' subcommand determines the handling of missing
variables.  If 'INCLUDE' is set, then user-missing values are included
in the calculations, but system-missing values are not.  If 'EXCLUDE' is
set, which is the default, user-missing values are excluded as well as
system-missing values.  This is the default.

   If 'LISTWISE' is set, then the entire case is excluded from analysis
whenever any variable specified in the '/VARIABLES', '/PAIRS' or
'/GROUPS' subcommands contains a missing value.  If 'ANALYSIS' is set,
then missing values are excluded only in the analysis for which they
would be needed.  This is the default.

* Menu:

* One Sample Mode::             Testing against a hypothesized mean
* Independent Samples Mode::    Testing two independent groups for equal mean
* Paired Samples Mode::         Testing two interdependent groups for equal mean


File: pspp.info,  Node: One Sample Mode,  Next: Independent Samples Mode,  Up: T-TEST

15.12.1 One Sample Mode
-----------------------

The 'TESTVAL' subcommand invokes the One Sample mode.  This mode is used
to test a population mean against a hypothesized mean.  The value given
to the 'TESTVAL' subcommand is the value against which you wish to test.
In this mode, you must also use the '/VARIABLES' subcommand to tell PSPP
which variables you wish to test.


File: pspp.info,  Node: Independent Samples Mode,  Next: Paired Samples Mode,  Prev: One Sample Mode,  Up: T-TEST

15.12.2 Independent Samples Mode
--------------------------------

The 'GROUPS' subcommand invokes Independent Samples mode or 'Groups'
mode.  This mode is used to test whether two groups of values have the
same population mean.  In this mode, you must also use the '/VARIABLES'
subcommand to tell PSPP the dependent variables you wish to test.

   The variable given in the 'GROUPS' subcommand is the independent
variable which determines to which group the samples belong.  The values
in parentheses are the specific values of the independent variable for
each group.  If the parentheses are omitted and no values are given, the
default values of 1.0 and 2.0 are assumed.

   If the independent variable is numeric, it is acceptable to specify
only one value inside the parentheses.  If you do this, cases where the
independent variable is greater than or equal to this value belong to
the first group, and cases less than this value belong to the second
group.  When using this form of the 'GROUPS' subcommand, missing values
in the independent variable are excluded on a listwise basis, regardless
of whether '/MISSING=LISTWISE' was specified.


File: pspp.info,  Node: Paired Samples Mode,  Prev: Independent Samples Mode,  Up: T-TEST

15.12.3 Paired Samples Mode
---------------------------

The 'PAIRS' subcommand introduces Paired Samples mode.  Use this mode
when repeated measures have been taken from the same samples.  If the
'WITH' keyword is omitted, then tables for all combinations of variables
given in the 'PAIRS' subcommand are generated.  If the 'WITH' keyword is
given, and the '(PAIRED)' keyword is also given, then the number of
variables preceding 'WITH' must be the same as the number following it.
In this case, tables for each respective pair of variables are
generated.  In the event that the 'WITH' keyword is given, but the
'(PAIRED)' keyword is omitted, then tables for each combination of
variable preceding 'WITH' against variable following 'WITH' are
generated.


File: pspp.info,  Node: ONEWAY,  Next: QUICK CLUSTER,  Prev: T-TEST,  Up: Statistics

15.13 ONEWAY
============

     ONEWAY
             [/VARIABLES = ] VAR_LIST BY VAR
             /MISSING={ANALYSIS,LISTWISE} {EXCLUDE,INCLUDE}
             /CONTRAST= VALUE1 [, VALUE2] ... [,VALUEN]
             /STATISTICS={DESCRIPTIVES,HOMOGENEITY}
             /POSTHOC={BONFERRONI, GH, LSD, SCHEFFE, SIDAK, TUKEY, ALPHA ([VALUE])}

   The 'ONEWAY' procedure performs a one-way analysis of variance of
variables factored by a single independent variable.  It is used to
compare the means of a population divided into more than two groups.

   The dependent variables to be analysed should be given in the
'VARIABLES' subcommand.  The list of variables must be followed by the
'BY' keyword and the name of the independent (or factor) variable.

   You can use the 'STATISTICS' subcommand to tell PSPP to display
ancillary information.  The options accepted are:
   * DESCRIPTIVES Displays descriptive statistics about the groups
     factored by the independent variable.
   * HOMOGENEITY Displays the Levene test of Homogeneity of Variance for
     the variables and their groups.

   The 'CONTRAST' subcommand is used when you anticipate certain
differences between the groups.  The subcommand must be followed by a
list of numerals which are the coefficients of the groups to be tested.
The number of coefficients must correspond to the number of distinct
groups (or values of the independent variable).  If the total sum of the
coefficients are not zero, then PSPP will display a warning, but will
proceed with the analysis.  The 'CONTRAST' subcommand may be given up to
10 times in order to specify different contrast tests.  The 'MISSING'
subcommand defines how missing values are handled.  If 'LISTWISE' is
specified then cases which have missing values for the independent
variable or any dependent variable will be ignored.  If 'ANALYSIS' is
specified, then cases will be ignored if the independent variable is
missing or if the dependent variable currently being analysed is
missing.  The default is 'ANALYSIS'.  A setting of 'EXCLUDE' means that
variables whose values are user-missing are to be excluded from the
analysis.  A setting of 'INCLUDE' means they are to be included.  The
default is 'EXCLUDE'.

   Using the 'POSTHOC' subcommand you can perform multiple pairwise
comparisons on the data.  The following comparison methods are
available:
   * 'LSD' Least Significant Difference.
   * 'TUKEY' Tukey Honestly Significant Difference.
   * 'BONFERRONI' Bonferroni test.
   * 'SCHEFFE' Scheffe''s test.
   * 'SIDAK' Sidak test.
   * 'GH' The Games-Howell test.

The optional syntax 'ALPHA(VALUE)' is used to indicate that VALUE should
be used as the confidence level for which the posthoc tests will be
performed.  The default is 0.05.


File: pspp.info,  Node: QUICK CLUSTER,  Next: RANK,  Prev: ONEWAY,  Up: Statistics

15.14 QUICK CLUSTER
===================

     QUICK CLUSTER VAR_LIST
           [/CRITERIA=CLUSTERS(K) [MXITER(MAX_ITER)] CONVERGE(EPSILON) [NOINITIAL]]
           [/MISSING={EXCLUDE,INCLUDE} {LISTWISE, PAIRWISE}]
           [/PRINT={INITIAL} {CLUSTER}]

   The 'QUICK CLUSTER' command performs k-means clustering on the
dataset.  This is useful when you wish to allocate cases into clusters
of similar values and you already know the number of clusters.

   The minimum specification is 'QUICK CLUSTER' followed by the names of
the variables which contain the cluster data.  Normally you will also
want to specify '/CRITERIA=CLUSTERS(K)' where K is the number of
clusters.  If this is not specified, then K defaults to 2.

   If you use '/CRITERIA=NOINITIAL' then a naive algorithm to select the
initial clusters is used.  This will provide for faster execution but
less well separated initial clusters and hence possibly an inferior
final result.

   'QUICK CLUSTER' uses an iterative algorithm to select the clusters
centers.  The subcommand '/CRITERIA=MXITER(MAX_ITER)' sets the maximum
number of iterations.  During classification, PSPP will continue
iterating until until MAX_ITER iterations have been done or the
convergence criterion (see below) is fulfilled.  The default value of
MAX_ITER is 2.

   If however, you specify '/CRITERIA=NOUPDATE' then after selecting the
initial centers, no further update to the cluster centers is done.  In
this case, MAX_ITER, if specified.  is ignored.

   The subcommand '/CRITERIA=CONVERGE(EPSILON)' is used to set the
convergence criterion.  The value of convergence criterion is EPSILON
times the minimum distance between the _initial_ cluster centers.
Iteration stops when the mean cluster distance between one iteration and
the next is less than the convergence criterion.  The default value of
EPSILON is zero.

   The 'MISSING' subcommand determines the handling of missing
variables.  If 'INCLUDE' is set, then user-missing values are considered
at their face value and not as missing values.  If 'EXCLUDE' is set,
which is the default, user-missing values are excluded as well as
system-missing values.

   If 'LISTWISE' is set, then the entire case is excluded from the
analysis whenever any of the clustering variables contains a missing
value.  If 'PAIRWISE' is set, then a case is considered missing only if
all the clustering variables contain missing values.  Otherwise it is
clustered on the basis of the non-missing values.  The default is
'LISTWISE'.

   The 'PRINT' subcommand requests additional output to be printed.  If
'INITIAL' is set, then the initial cluster memberships will be printed.
If 'CLUSTER' is set, the cluster memberships of the individual cases
will be displayed (potentially generating lengthy output).


File: pspp.info,  Node: RANK,  Next: REGRESSION,  Prev: QUICK CLUSTER,  Up: Statistics

15.15 RANK
==========

     RANK
             [VARIABLES=] VAR_LIST [{A,D}] [BY VAR_LIST]
             /TIES={MEAN,LOW,HIGH,CONDENSE}
             /FRACTION={BLOM,TUKEY,VW,RANKIT}
             /PRINT[={YES,NO}
             /MISSING={EXCLUDE,INCLUDE}

             /RANK [INTO VAR_LIST]
             /NTILES(k) [INTO VAR_LIST]
             /NORMAL [INTO VAR_LIST]
             /PERCENT [INTO VAR_LIST]
             /RFRACTION [INTO VAR_LIST]
             /PROPORTION [INTO VAR_LIST]
             /N [INTO VAR_LIST]
             /SAVAGE [INTO VAR_LIST]

   The 'RANK' command ranks variables and stores the results into new
variables.

   The 'VARIABLES' subcommand, which is mandatory, specifies one or more
variables whose values are to be ranked.  After each variable, 'A' or
'D' may appear, indicating that the variable is to be ranked in
ascending or descending order.  Ascending is the default.  If a 'BY'
keyword appears, it should be followed by a list of variables which are
to serve as group variables.  In this case, the cases are gathered into
groups, and ranks calculated for each group.

   The 'TIES' subcommand specifies how tied values are to be treated.
The default is to take the mean value of all the tied cases.

   The 'FRACTION' subcommand specifies how proportional ranks are to be
calculated.  This only has any effect if 'NORMAL' or 'PROPORTIONAL' rank
functions are requested.

   The 'PRINT' subcommand may be used to specify that a summary of the
rank variables created should appear in the output.

   The function subcommands are 'RANK', 'NTILES', 'NORMAL', 'PERCENT',
'RFRACTION', 'PROPORTION' and 'SAVAGE'.  Any number of function
subcommands may appear.  If none are given, then the default is RANK.
The 'NTILES' subcommand must take an integer specifying the number of
partitions into which values should be ranked.  Each subcommand may be
followed by the 'INTO' keyword and a list of variables which are the
variables to be created and receive the rank scores.  There may be as
many variables specified as there are variables named on the 'VARIABLES'
subcommand.  If fewer are specified, then the variable names are
automatically created.

   The 'MISSING' subcommand determines how user missing values are to be
treated.  A setting of 'EXCLUDE' means that variables whose values are
user-missing are to be excluded from the rank scores.  A setting of
'INCLUDE' means they are to be included.  The default is 'EXCLUDE'.


File: pspp.info,  Node: REGRESSION,  Next: RELIABILITY,  Prev: RANK,  Up: Statistics

15.16 REGRESSION
================

The 'REGRESSION' procedure fits linear models to data via least-squares
estimation.  The procedure is appropriate for data which satisfy those
assumptions typical in linear regression:

   * The data set contains n observations of a dependent variable, say
     Y_1,...,Y_n, and n observations of one or more explanatory
     variables.  Let X_{11}, X_{12}, ..., X_{1n} denote the n
     observations of the first explanatory variable; X_{21},...,X_{2n}
     denote the n observations of the second explanatory variable;
     X_{k1},...,X_{kn} denote the n observations of the kth explanatory
     variable.

   * The dependent variable Y has the following relationship to the
     explanatory variables: Y_i = b_0 + b_1 X_{1i} + ... + b_k X_{ki} +
     Z_i where b_0, b_1, ..., b_k are unknown coefficients, and
     Z_1,...,Z_n are independent, normally distributed "noise" terms
     with mean zero and common variance.  The noise, or "error" terms
     are unobserved.  This relationship is called the "linear model".

   The 'REGRESSION' procedure estimates the coefficients b_0,...,b_k and
produces output relevant to inferences for the linear model.

* Menu:

* Syntax::                      Syntax definition.
* Examples::                    Using the REGRESSION procedure.


File: pspp.info,  Node: Syntax,  Next: Examples,  Up: REGRESSION

15.16.1 Syntax
--------------

     REGRESSION
             /VARIABLES=VAR_LIST
             /DEPENDENT=VAR_LIST
             /STATISTICS={ALL, DEFAULTS, R, COEFF, ANOVA, BCOV, CI[CONF]}
             /SAVE={PRED, RESID}

   The 'REGRESSION' procedure reads the active dataset and outputs
statistics relevant to the linear model specified by the user.

   The 'VARIABLES' subcommand, which is required, specifies the list of
variables to be analyzed.  Keyword 'VARIABLES' is required.  The
'DEPENDENT' subcommand specifies the dependent variable of the linear
model.  The 'DEPENDENT' subcommand is required.  All variables listed in
the 'VARIABLES' subcommand, but not listed in the 'DEPENDENT'
subcommand, are treated as explanatory variables in the linear model.

   All other subcommands are optional:

   The 'STATISTICS' subcommand specifies which statistics are to be
displayed.  The following keywords are accepted:

'ALL'
     All of the statistics below.
'R'
     The ratio of the sums of squares due to the model to the total sums
     of squares for the dependent variable.
'COEFF'
     A table containing the estimated model coefficients and their
     standard errors.
'CI (CONF)'
     This item is only relevant if COEFF has also been selected.  It
     specifies that the confidence interval for the coefficients should
     be printed.  The optional value CONF, which must be in parentheses,
     is the desired confidence level expressed as a percentage.
'ANOVA'
     Analysis of variance table for the model.
'BCOV'
     The covariance matrix for the estimated model coefficients.
'DEFAULT'
     The same as if R, COEFF, and ANOVA had been selected.  This is what
     you get if the /STATISTICS command is not specified, or if it is
     specified without any parameters.

   The 'SAVE' subcommand causes PSPP to save the residuals or predicted
values from the fitted model to the active dataset.  PSPP will store the
residuals in a variable called 'RES1' if no such variable exists, 'RES2'
if 'RES1' already exists, 'RES3' if 'RES1' and 'RES2' already exist,
etc.  It will choose the name of the variable for the predicted values
similarly, but with 'PRED' as a prefix.  When 'SAVE' is used, PSPP
ignores 'TEMPORARY', treating temporary transformations as permanent.


File: pspp.info,  Node: Examples,  Prev: Syntax,  Up: REGRESSION

15.16.2 Examples
----------------

The following PSPP syntax will generate the default output and save the
predicted values and residuals to the active dataset.

     title 'Demonstrate REGRESSION procedure'.
     data list / v0 1-2 (A) v1 v2 3-22 (10).
     begin data.
     b  7.735648 -23.97588
     b  6.142625 -19.63854
     a  7.651430 -25.26557
     c  6.125125 -16.57090
     a  8.245789 -25.80001
     c  6.031540 -17.56743
     a  9.832291 -28.35977
     c  5.343832 -16.79548
     a  8.838262 -29.25689
     b  6.200189 -18.58219
     end data.
     list.
     regression /variables=v0 v1 v2 /statistics defaults /dependent=v2
                /save pred resid /method=enter.


File: pspp.info,  Node: RELIABILITY,  Next: ROC,  Prev: REGRESSION,  Up: Statistics

15.17 RELIABILITY
=================

     RELIABILITY
             /VARIABLES=VAR_LIST
             /SCALE (NAME) = {VAR_LIST, ALL}
             /MODEL={ALPHA, SPLIT[(N)]}
             /SUMMARY={TOTAL,ALL}
             /MISSING={EXCLUDE,INCLUDE}

   The 'RELIABILITY' command performs reliability analysis on the data.

   The 'VARIABLES' subcommand is required.  It determines the set of
variables upon which analysis is to be performed.

   The 'SCALE' subcommand determines which variables reliability is to
be calculated for.  If it is omitted, then analysis for all variables
named in the 'VARIABLES' subcommand will be used.  Optionally, the NAME
parameter may be specified to set a string name for the scale.

   The 'MODEL' subcommand determines the type of analysis.  If 'ALPHA'
is specified, then Cronbach's Alpha is calculated for the scale.  If the
model is 'SPLIT', then the variables are divided into 2 subsets.  An
optional parameter N may be given, to specify how many variables to be
in the first subset.  If N is omitted, then it defaults to one half of
the variables in the scale, or one half minus one if there are an odd
number of variables.  The default model is 'ALPHA'.

   By default, any cases with user missing, or system missing values for
any variables given in the 'VARIABLES' subcommand will be omitted from
analysis.  The 'MISSING' subcommand determines whether user missing
values are to be included or excluded in the analysis.

   The 'SUMMARY' subcommand determines the type of summary analysis to
be performed.  Currently there is only one type: 'SUMMARY=TOTAL', which
displays per-item analysis tested against the totals.


File: pspp.info,  Node: ROC,  Prev: RELIABILITY,  Up: Statistics

15.18 ROC
=========

     ROC     VAR_LIST BY STATE_VAR (STATE_VALUE)
             /PLOT = { CURVE [(REFERENCE)], NONE }
             /PRINT = [ SE ] [ COORDINATES ]
             /CRITERIA = [ CUTOFF({INCLUDE,EXCLUDE}) ]
               [ TESTPOS ({LARGE,SMALL}) ]
               [ CI (CONFIDENCE) ]
               [ DISTRIBUTION ({FREE, NEGEXPO }) ]
             /MISSING={EXCLUDE,INCLUDE}

   The 'ROC' command is used to plot the receiver operating
characteristic curve of a dataset, and to estimate the area under the
curve.  This is useful for analysing the efficacy of a variable as a
predictor of a state of nature.

   The mandatory VAR_LIST is the list of predictor variables.  The
variable STATE_VAR is the variable whose values represent the actual
states, and STATE_VALUE is the value of this variable which represents
the positive state.

   The optional subcommand 'PLOT' is used to determine if and how the
'ROC' curve is drawn.  The keyword 'CURVE' means that the 'ROC' curve
should be drawn, and the optional keyword 'REFERENCE', which should be
enclosed in parentheses, says that the diagonal reference line should be
drawn.  If the keyword 'NONE' is given, then no 'ROC' curve is drawn.
By default, the curve is drawn with no reference line.

   The optional subcommand 'PRINT' determines which additional tables
should be printed.  Two additional tables are available.  The 'SE'
keyword says that standard error of the area under the curve should be
printed as well as the area itself.  In addition, a p-value under the
null hypothesis that the area under the curve equals 0.5 will be
printed.  The 'COORDINATES' keyword says that a table of coordinates of
the 'ROC' curve should be printed.

   The 'CRITERIA' subcommand has four optional parameters:
   * The 'TESTPOS' parameter may be 'LARGE' or 'SMALL'.  'LARGE' is the
     default, and says that larger values in the predictor variables are
     to be considered positive.  'SMALL' indicates that smaller values
     should be considered positive.

   * The 'CI' parameter specifies the confidence interval that should be
     printed.  It has no effect if the 'SE' keyword in the 'PRINT'
     subcommand has not been given.

   * The 'DISTRIBUTION' parameter determines the method to be used when
     estimating the area under the curve.  There are two possibilities,
     viz: 'FREE' and 'NEGEXPO'.  The 'FREE' method uses a non-parametric
     estimate, and the 'NEGEXPO' method a bi-negative exponential
     distribution estimate.  The 'NEGEXPO' method should only be used
     when the number of positive actual states is equal to the number of
     negative actual states.  The default is 'FREE'.

   * The 'CUTOFF' parameter is for compatibility and is ignored.

   The 'MISSING' subcommand determines whether user missing values are
to be included or excluded in the analysis.  The default behaviour is to
exclude them.  Cases are excluded on a listwise basis; if any of the
variables in VAR_LIST or if the variable STATE_VAR is missing, then the
entire case will be excluded.


File: pspp.info,  Node: Utilities,  Next: Invoking pspp-convert,  Prev: Statistics,  Up: Top

16 Utilities
************

Commands that don't fit any other category are placed here.

   Most of these commands are not affected by commands like 'IF' and
'LOOP': they take effect only once, unconditionally, at the time that
they are encountered in the input.

* Menu:

* ADD DOCUMENT::                Add documentary text to the active dataset.
* CACHE::                       Ignored for compatibility.
* CD::                          Change the current directory.
* COMMENT::                     Document your syntax file.
* DOCUMENT::                    Document the active dataset.
* DISPLAY DOCUMENTS::           Display active dataset documents.
* DISPLAY FILE LABEL::          Display the active dataset label.
* DROP DOCUMENTS::              Remove documents from the active dataset.
* ECHO::                        Write a string to the output stream.
* ERASE::                       Erase a file.
* EXECUTE::                     Execute pending transformations.
* FILE LABEL::                  Set the active dataset's label.
* FINISH::                      Terminate the PSPP session.
* HOST::                        Temporarily return to the operating system.
* INCLUDE::                     Include a file within the current one.
* INSERT::                      Insert a file within the current one.
* OUTPUT::                      Modify the appearance of the output.
* PERMISSIONS::                 Change permissions on a file.
* PRESERVE and RESTORE::        Saving settings and restoring them later.
* SET::                         Adjust PSPP runtime parameters.
* SHOW::                        Display runtime parameters.
* SUBTITLE::                    Provide a document subtitle.
* TITLE::                       Provide a document title.


File: pspp.info,  Node: ADD DOCUMENT,  Next: CACHE,  Up: Utilities

16.1 ADD DOCUMENT
=================

     ADD DOCUMENT
         'line one' 'line two' ... 'last line' .

   'ADD DOCUMENT' adds one or more lines of descriptive commentary to
the active dataset.  Documents added in this way are saved to system
files.  They can be viewed using 'SYSFILE INFO' or 'DISPLAY DOCUMENTS'.
They can be removed from the active dataset with 'DROP DOCUMENTS'.

   Each line of documentary text must be enclosed in quotation marks,
and may not be more than 80 bytes long.  *Note DOCUMENT::.


File: pspp.info,  Node: CACHE,  Next: CD,  Prev: ADD DOCUMENT,  Up: Utilities

16.2 CACHE
==========

     CACHE.

   This command is accepted, for compatibility, but it has no effect.


File: pspp.info,  Node: CD,  Next: COMMENT,  Prev: CACHE,  Up: Utilities

16.3 CD
=======

     CD 'new directory' .

   'CD' changes the current directory.  The new directory will become
that specified by the command.


File: pspp.info,  Node: COMMENT,  Next: DOCUMENT,  Prev: CD,  Up: Utilities

16.4 COMMENT
============

     Two possibles syntaxes:
             COMMENT comment text ... .
             *comment text ... .

   'COMMENT' is ignored.  It is used to provide information to the
author and other readers of the PSPP syntax file.

   'COMMENT' can extend over any number of lines.  Don't forget to
terminate it with a dot or a blank line.


File: pspp.info,  Node: DOCUMENT,  Next: DISPLAY DOCUMENTS,  Prev: COMMENT,  Up: Utilities

16.5 DOCUMENT
=============

     DOCUMENT DOCUMENTARY_TEXT.

   'DOCUMENT' adds one or more lines of descriptive commentary to the
active dataset.  Documents added in this way are saved to system files.
They can be viewed using 'SYSFILE INFO' or 'DISPLAY DOCUMENTS'.  They
can be removed from the active dataset with 'DROP DOCUMENTS'.

   Specify the DOCUMENTARY TEXT following the 'DOCUMENT' keyword.  It is
interpreted literally -- any quotes or other punctuation marks will be
included in the file.  You can extend the documentary text over as many
lines as necessary.  Lines are truncated at 80 bytes.  Don't forget to
terminate the command with a dot or a blank line.  *Note ADD DOCUMENT::.


File: pspp.info,  Node: DISPLAY DOCUMENTS,  Next: DISPLAY FILE LABEL,  Prev: DOCUMENT,  Up: Utilities

16.6 DISPLAY DOCUMENTS
======================

     DISPLAY DOCUMENTS.

   'DISPLAY DOCUMENTS' displays the documents in the active dataset.
Each document is preceded by a line giving the time and date that it was
added.  *Note DOCUMENT::.


File: pspp.info,  Node: DISPLAY FILE LABEL,  Next: DROP DOCUMENTS,  Prev: DISPLAY DOCUMENTS,  Up: Utilities

16.7 DISPLAY FILE LABEL
=======================

     DISPLAY FILE LABEL.

   'DISPLAY FILE LABEL' displays the file label contained in the active
dataset, if any.  *Note FILE LABEL::.

   This command is a PSPP extension.


File: pspp.info,  Node: DROP DOCUMENTS,  Next: ECHO,  Prev: DISPLAY FILE LABEL,  Up: Utilities

16.8 DROP DOCUMENTS
===================

     DROP DOCUMENTS.

   'DROP DOCUMENTS' removes all documents from the active dataset.  New
documents can be added with 'DOCUMENT' (*note DOCUMENT::).

   'DROP DOCUMENTS' changes only the active dataset.  It does not modify
any system files stored on disk.


File: pspp.info,  Node: ECHO,  Next: ERASE,  Prev: DROP DOCUMENTS,  Up: Utilities

16.9 ECHO
=========

     ECHO 'arbitrary text' .

   Use 'ECHO' to write arbitrary text to the output stream.  The text
should be enclosed in quotation marks following the normal rules for
string tokens (*note Tokens::).


File: pspp.info,  Node: ERASE,  Next: EXECUTE,  Prev: ECHO,  Up: Utilities

16.10 ERASE
===========

     ERASE FILE FILE_NAME.

   'ERASE FILE' deletes a file from the local filesystem.  FILE_NAME
must be quoted.  This command cannot be used if the SAFER (*note SET::)
setting is active.


File: pspp.info,  Node: EXECUTE,  Next: FILE LABEL,  Prev: ERASE,  Up: Utilities

16.11 EXECUTE
=============

     EXECUTE.

   'EXECUTE' causes the active dataset to be read and all pending
transformations to be executed.


File: pspp.info,  Node: FILE LABEL,  Next: FINISH,  Prev: EXECUTE,  Up: Utilities

16.12 FILE LABEL
================

     FILE LABEL FILE_LABEL.

   'FILE LABEL' provides a title for the active dataset.  This title
will be saved into system files and portable files that are created
during this PSPP run.

   FILE_LABEL should not be quoted.  If quotes are included, they are
literally interpreted and become part of the file label.


File: pspp.info,  Node: FINISH,  Next: HOST,  Prev: FILE LABEL,  Up: Utilities

16.13 FINISH
============

     FINISH.

   'FINISH' terminates the current PSPP session and returns control to
the operating system.


File: pspp.info,  Node: HOST,  Next: INCLUDE,  Prev: FINISH,  Up: Utilities

16.14 HOST
==========

     HOST.
     HOST COMMAND=['COMMAND'...].

   'HOST' suspends the current PSPP session and temporarily returns
control to the operating system.  This command cannot be used if the
SAFER (*note SET::) setting is active.

   If the 'COMMAND' subcommand is specified, as a sequence of shell
commands as quoted strings within square brackets, then PSPP executes
them together in a single subshell.

   If no subcommands are specified, then PSPP invokes an interactive
subshell.


File: pspp.info,  Node: INCLUDE,  Next: INSERT,  Prev: HOST,  Up: Utilities

16.15 INCLUDE
=============

             INCLUDE [FILE=]'FILE_NAME' [ENCODING='ENCODING'].

   'INCLUDE' causes the PSPP command processor to read an additional
command file as if it were included bodily in the current command file.
If errors are encountered in the included file, then command processing
will stop and no more commands will be processed.  Include files may be
nested to any depth, up to the limit of available memory.

   The 'INSERT' command (*note INSERT::) is a more flexible alternative
to 'INCLUDE'.  An 'INCLUDE' command acts the same as 'INSERT' with
'ERROR=STOP CD=NO SYNTAX=BATCH' specified.

   The optional 'ENCODING' subcommand has the same meaning as with
'INSERT'.


File: pspp.info,  Node: INSERT,  Next: OUTPUT,  Prev: INCLUDE,  Up: Utilities

16.16 INSERT
============

          INSERT [FILE=]'FILE_NAME'
             [CD={NO,YES}]
             [ERROR={CONTINUE,STOP}]
             [SYNTAX={BATCH,INTERACTIVE}]
             [ENCODING={LOCALE, 'CHARSET_NAME'}].

   'INSERT' is similar to 'INCLUDE' (*note INCLUDE::) but somewhat more
flexible.  It causes the command processor to read a file as if it were
embedded in the current command file.

   If 'CD=YES' is specified, then before including the file, the current
directory will be changed to the directory of the included file.  The
default setting is 'CD=NO'.  Note that this directory will remain
current until it is changed explicitly (with the 'CD' command, or a
subsequent 'INSERT' command with the 'CD=YES' option).  It will not
revert to its original setting even after the included file is finished
processing.

   If 'ERROR=STOP' is specified, errors encountered in the inserted file
will cause processing to immediately cease.  Otherwise processing will
continue at the next command.  The default setting is 'ERROR=CONTINUE'.

   If 'SYNTAX=INTERACTIVE' is specified then the syntax contained in the
included file must conform to interactive syntax conventions.  *Note
Syntax Variants::.  The default setting is 'SYNTAX=BATCH'.

   'ENCODING' optionally specifies the character set used by the
included file.  Its argument, which is not case-sensitive, must be in
one of the following forms:

'LOCALE'
     The encoding used by the system locale, or as overridden by the
     'SET' command (*note SET::).  On GNU/Linux and other Unix-like
     systems, environment variables, e.g. 'LANG' or 'LC_ALL', determine
     the system locale.

CHARSET_NAME
     One of the character set names listed by IANA at
     <http://www.iana.org/assignments/character-sets>.  Some examples
     are 'ASCII' (United States), 'ISO-8859-1' (western Europe),
     'EUC-JP' (Japan), and 'windows-1252' (Windows).  Not all systems
     support all character sets.

'Auto,ENCODING'
     Automatically detects whether a syntax file is encoded in an
     Unicode encoding such as UTF-8, UTF-16, or UTF-32.  If it is not,
     then PSPP generally assumes that the file is encoded in ENCODING
     (an IANA character set name).  However, if ENCODING is UTF-8, and
     the syntax file is not valid UTF-8, PSPP instead assumes that the
     file is encoded in 'windows-1252'.

     For best results, ENCODING should be an ASCII-compatible encoding
     (the most common locale encodings are all ASCII-compatible),
     because encodings that are not ASCII compatible cannot be
     automatically distinguished from UTF-8.

'Auto'
'Auto,Locale'
     Automatic detection, as above, with the default encoding taken from
     the system locale or the setting on 'SET LOCALE'.

   When ENCODING is not specified, the default is taken from the
'--syntax-encoding' command option, if it was specified, and otherwise
it is 'Auto'.


File: pspp.info,  Node: OUTPUT,  Next: PERMISSIONS,  Prev: INSERT,  Up: Utilities

16.17 OUTPUT
============

     OUTPUT MODIFY
            /SELECT TABLES
            /TABLECELLS SELECT = [ {SIGNIFICANCE, COUNT} ]
                        FORMAT = FMT_SPEC.
     *Please note:* In the above synopsis the characters '[' and ']' are
     literals.  They must appear in the syntax to be interpreted.

   'OUTPUT' changes the appearance of the tables in which results are
printed.  In particular, it can be used to set the format and precision
to which results are displayed.

   After running this command, the default table appearance parameters
will have been modified and each new output table generated will use the
new parameters.

   Following '/TABLECELLS SELECT =' a list of cell classes must appear,
enclosed in square brackets.  This list determines the classes of values
should be selected for modification.  Each class can be:

SIGNIFICANCE
     Significance of tests (p-values).

COUNT
     Counts or sums of weights.

   The value of FMT_SPEC must be a valid output format (*note Input and
Output Formats::).  Note that not all possible formats are meaningful
for all classes.


File: pspp.info,  Node: PERMISSIONS,  Next: PRESERVE and RESTORE,  Prev: OUTPUT,  Up: Utilities

16.18 PERMISSIONS
=================

     PERMISSIONS
             FILE='FILE_NAME'
             /PERMISSIONS = {READONLY,WRITEABLE}.

   'PERMISSIONS' changes the permissions of a file.  There is one
mandatory subcommand which specifies the permissions to which the file
should be changed.  If you set a file's permission to 'READONLY', then
the file will become unwritable either by you or anyone else on the
system.  If you set the permission to 'WRITEABLE', then the file will
become writeable by you; the permissions afforded to others will be
unchanged.  This command cannot be used if the 'SAFER' (*note SET::)
setting is active.


File: pspp.info,  Node: PRESERVE and RESTORE,  Next: SET,  Prev: PERMISSIONS,  Up: Utilities

16.19 PRESERVE and RESTORE
==========================

     PRESERVE.
     ...
     RESTORE.

   'PRESERVE' saves all of the settings that 'SET' (*note SET::) can
adjust.  A later 'RESTORE' command restores those settings.

   'PRESERVE' can be nested up to five levels deep.


File: pspp.info,  Node: SET,  Next: SHOW,  Prev: PRESERVE and RESTORE,  Up: Utilities

16.20 SET
=========

     SET

     (data input)
             /BLANKS={SYSMIS,'.',number}
             /DECIMAL={DOT,COMMA}
             /FORMAT=FMT_SPEC
             /EPOCH={AUTOMATIC,YEAR}
             /RIB={NATIVE,MSBFIRST,LSBFIRST,VAX}
             /RRB={NATIVE,ISL,ISB,IDL,IDB,VF,VD,VG,ZS,ZL}

     (interaction)
             /MXERRS=MAX_ERRS
             /MXWARNS=MAX_WARNINGS
             /WORKSPACE=WORKSPACE_SIZE

     (syntax execution)
             /LOCALE='LOCALE'
             /MEXPAND={ON,OFF}
             /MITERATE=MAX_ITERATIONS
             /MNEST=MAX_NEST
             /MPRINT={ON,OFF}
             /MXLOOPS=MAX_LOOPS
             /SEED={RANDOM,SEED_VALUE}
             /UNDEFINED={WARN,NOWARN}
             /FUZZBITS=FUZZBITS

     (data output)
             /CC{A,B,C,D,E}={'NPRE,PRE,SUF,NSUF','NPRE.PRE.SUF.NSUF'}
             /DECIMAL={DOT,COMMA}
             /FORMAT=FMT_SPEC
             /WIB={NATIVE,MSBFIRST,LSBFIRST,VAX}
             /WRB={NATIVE,ISL,ISB,IDL,IDB,VF,VD,VG,ZS,ZL}

     (output routing)
             /ERRORS={ON,OFF,TERMINAL,LISTING,BOTH,NONE}
             /MESSAGES={ON,OFF,TERMINAL,LISTING,BOTH,NONE}
             /PRINTBACK={ON,OFF,TERMINAL,LISTING,BOTH,NONE}
             /RESULTS={ON,OFF,TERMINAL,LISTING,BOTH,NONE}

     (output driver options)
             /HEADERS={NO,YES,BLANK}
             /LENGTH={NONE,N_LINES}
             /MORE={ON,OFF}
             /WIDTH={NARROW,WIDTH,N_CHARACTERS}
             /TNUMBERS={VALUES,LABELS,BOTH}
             /TVARS={NAMES,LABELS,BOTH}

     (logging)
             /JOURNAL={ON,OFF} ['FILE_NAME']

     (system files)
             /COMPRESSION={ON,OFF}
             /SCOMPRESSION={ON,OFF}

     (miscellaneous)
             /SAFER=ON
             /LOCALE='STRING'


     (obsolete settings accepted for compatibility, but ignored)
             /BOXSTRING={'XXX','XXXXXXXXXXX'}
             /CASE={UPPER,UPLOW}
             /CPI=cpi_value
             /HIGHRES={ON,OFF}
             /HISTOGRAM='C'
             /LOWRES={AUTO,ON,OFF}
             /LPI=LPI_VALUE
             /MENUS={STANDARD,EXTENDED}
             /MXMEMORY=MAX_MEMORY
             /SCRIPTTAB='c'
             /TB1={'XXX','XXXXXXXXXXX'}
             /TBFONTS='STRING'
             /XSORT={YES,NO}

   'SET' allows the user to adjust several parameters relating to PSPP's
execution.  Since there are many subcommands to this command, its
subcommands will be examined in groups.

   For subcommands that take boolean values, 'ON' and 'YES' are
synonymous, as are 'OFF' and 'NO', when used as subcommand values.

   The data input subcommands affect the way that data is read from data
files.  The data input subcommands are

BLANKS
     This is the value assigned to an item data item that is empty or
     contains only white space.  An argument of SYSMIS or '.'  will
     cause the system-missing value to be assigned to null items.  This
     is the default.  Any real value may be assigned.

DECIMAL
     This value may be set to 'DOT' or 'COMMA'.  Setting it to 'DOT'
     causes the decimal point character to be '.' and the grouping
     character to be ','.  Setting it to 'COMMA' causes the decimal
     point character to be ',' and the grouping character to be '.'.  If
     the setting is 'COMMA', then ',' will not be treated as a field
     separator in the 'DATA LIST' command (*note DATA LIST::).  The
     default value is determined from the system locale.

FORMAT
     Allows the default numeric input/output format to be specified.
     The default is F8.2.  *Note Input and Output Formats::.

EPOCH
     Specifies the range of years used when a 2-digit year is read from
     a data file or used in a date construction expression (*note Date
     Construction::).  If a 4-digit year is specified for the epoch,
     then 2-digit years are interpreted starting from that year, known
     as the epoch.  If 'AUTOMATIC' (the default) is specified, then the
     epoch begins 69 years before the current date.

RIB

     PSPP extension to set the byte ordering (endianness) used for
     reading data in IB or PIB format (*note Binary and Hexadecimal
     Numeric Formats::).  In 'MSBFIRST' ordering, the most-significant
     byte appears at the left end of a IB or PIB field.  In 'LSBFIRST'
     ordering, the least-significant byte appears at the left end.
     'VAX' ordering is like 'MSBFIRST', except that each pair of bytes
     is in reverse order.  'NATIVE', the default, is equivalent to
     'MSBFIRST' or 'LSBFIRST' depending on the native format of the
     machine running PSPP.

RRB

     PSPP extension to set the floating-point format used for reading
     data in RB format (*note Binary and Hexadecimal Numeric Formats::).
     The possibilities are:

     NATIVE
          The native format of the machine running PSPP.  Equivalent to
          either IDL or IDB.

     ISL
          32-bit IEEE 754 single-precision floating point, in
          little-endian byte order.

     ISB
          32-bit IEEE 754 single-precision floating point, in big-endian
          byte order.

     IDL
          64-bit IEEE 754 double-precision floating point, in
          little-endian byte order.

     IDB
          64-bit IEEE 754 double-precision floating point, in big-endian
          byte order.

     VF
          32-bit VAX F format, in VAX-endian byte order.

     VD
          64-bit VAX D format, in VAX-endian byte order.

     VG
          64-bit VAX G format, in VAX-endian byte order.

     ZS
          32-bit IBM Z architecture short format hexadecimal floating
          point, in big-endian byte order.

     ZL
          64-bit IBM Z architecture long format hexadecimal floating
          point, in big-endian byte order.

          Z architecture also supports IEEE 754 floating point.  The ZS
          and ZL formats are only for use with very old input files.
     The default is NATIVE.

   Interaction subcommands affect the way that PSPP interacts with an
online user.  The interaction subcommands are

MXERRS
     The maximum number of errors before PSPP halts processing of the
     current command file.  The default is 50.

MXWARNS
     The maximum number of warnings + errors before PSPP halts
     processing the current command file.  The special value of zero
     means that all warning situations should be ignored.  No warnings
     will be issued, except a single initial warning advising the user
     that warnings will not be given.  The default value is 100.

   Syntax execution subcommands control the way that PSPP commands
execute.  The syntax execution subcommands are

LOCALE
     Overrides the system locale for the purpose of reading and writing
     syntax and data files.  The argument should be a locale name in the
     general form 'LANGUAGE_COUNTRY.ENCODING', where LANGUAGE and
     COUNTRY are 2-character language and country abbreviations,
     respectively, and ENCODING is an IANA character set name.  Example
     locales are 'en_US.UTF-8' (UTF-8 encoded English as spoken in the
     United States) and 'ja_JP.EUC-JP' (EUC-JP encoded Japanese as
     spoken in Japan).

MEXPAND
MITERATE
MNEST
MPRINT
     Currently not used.

MXLOOPS
     The maximum number of iterations for an uncontrolled loop (*note
     LOOP::).  The default MAX_LOOPS is 40.

SEED
     The initial pseudo-random number seed.  Set to a real number or to
     RANDOM, which will obtain an initial seed from the current time of
     day.

UNDEFINED
     Currently not used.

FUZZBITS
     The maximum number of bits of errors in the least-significant
     places to accept for rounding up a value that is almost halfway
     between two possibilities for rounding with the RND operator (*note
     Miscellaneous Mathematics::).  The default FUZZBITS is 6.

WORKSPACE
     The maximum amount of memory (in kilobytes) that PSPP will use to
     store data being processed.  If memory in excess of the workspace
     size is required, then PSPP will start to use temporary files to
     store the data.  Setting a higher value will, in general, mean
     procedures will run faster, but may cause other applications to run
     slower.  On platforms without virtual memory management, setting a
     very large workspace may cause PSPP to abort.

   Data output subcommands affect the format of output data.  These
subcommands are

CCA
CCB
CCC
CCD
CCE

     Set up custom currency formats.  *Note Custom Currency Formats::,
     for details.

DECIMAL
     The default 'DOT' setting causes the decimal point character to be
     '.'.  A setting of 'COMMA' causes the decimal point character to be
     ','.

FORMAT
     Allows the default numeric input/output format to be specified.
     The default is F8.2.  *Note Input and Output Formats::.

WIB

     PSPP extension to set the byte ordering (endianness) used for
     writing data in IB or PIB format (*note Binary and Hexadecimal
     Numeric Formats::).  In 'MSBFIRST' ordering, the most-significant
     byte appears at the left end of a IB or PIB field.  In 'LSBFIRST'
     ordering, the least-significant byte appears at the left end.
     'VAX' ordering is like 'MSBFIRST', except that each pair of bytes
     is in reverse order.  'NATIVE', the default, is equivalent to
     'MSBFIRST' or 'LSBFIRST' depending on the native format of the
     machine running PSPP.

WRB

     PSPP extension to set the floating-point format used for writing
     data in RB format (*note Binary and Hexadecimal Numeric Formats::).
     The choices are the same as 'SET RIB'.  The default is 'NATIVE'.

   In the PSPP text-based interface, the output routing subcommands
affect where output is sent.  The following values are allowed for each
of these subcommands:

OFF
NONE
     Discard this kind of output.

TERMINAL
     Write this output to the terminal, but not to listing files and
     other output devices.

LISTING
     Write this output to listing files and other output devices, but
     not to the terminal.

ON
BOTH
     Write this type of output to all output devices.

   These output routing subcommands are:

ERRORS
     Applies to error and warning messages.  The default is 'BOTH'.

MESSAGES
     Applies to notes.  The default is 'BOTH'.

PRINTBACK
     Determines whether the syntax used for input is printed back as
     part of the output.  The default is 'NONE'.

RESULTS
     Applies to everything not in one of the above categories, such as
     the results of statistical procedures.  The default is 'BOTH'.

   These subcommands have no effect on output in the PSPP GUI
environment.

   Output driver option subcommands affect output drivers' settings.
These subcommands are

HEADERS
LENGTH
MORE
WIDTH
TNUMBERS
     The 'TNUMBERS' option sets the way in which values are displayed in
     output tables.  The valid settings are 'VALUES', 'LABELS' and
     'BOTH'.  If 'TNUMBERS' is set to 'VALUES', then all values are
     displayed with their literal value (which for a numeric value is a
     number and for a string value an alphanumeric string).  If
     'TNUMBERS' is set to 'LABELS', then values are displayed using
     their assigned labels if any.  (*Note VALUE LABELS::.)  If the a
     value has no label, then it will be displayed using its literal
     value.  If 'TNUMBERS' is set to 'BOTH', then values will be
     displayed with both their label (if any) and their literal value in
     parentheses.
TVARS
     The 'TVARS' option sets the way in which variables are displayed in
     output tables.  The valid settings are 'NAMES', 'LABELS' and
     'BOTH'.  If 'TVARS' is set to 'NAMES', then all variables are
     displayed using their names.  If 'TVARS' is set to 'LABELS', then
     variables are displayed using their label if one has been set.  If
     no label has been set, then the name will be used.  (*Note VARIABLE
     LABELS::.)  If 'TVARS' is set to 'BOTH', then variables will be
     displayed with both their label (if any) and their name in
     parentheses.

   Logging subcommands affect logging of commands executed to external
files.  These subcommands are

JOURNAL
LOG
     These subcommands, which are synonyms, control the journal.  The
     default is 'ON', which causes commands entered interactively to be
     written to the journal file.  Commands included from syntax files
     that are included interactively and error messages printed by PSPP
     are also written to the journal file, prefixed by '>'.  'OFF'
     disables use of the journal.

     The journal is named 'pspp.jnl' by default.  A different name may
     be specified.

   System file subcommands affect the default format of system files
produced by PSPP.  These subcommands are

COMPRESSION
     Not currently used.

SCOMPRESSION
     Whether system files created by 'SAVE' or 'XSAVE' are compressed by
     default.  The default is 'ON'.

   Security subcommands affect the operations that commands are allowed
to perform.  The security subcommands are

SAFER
     Setting this option disables the following operations:

        * The 'ERASE' command.
        * The 'HOST' command.
        * The 'PERMISSIONS' command.
        * Pipes (file names beginning or ending with '|').

     Be aware that this setting does not guarantee safety (commands can
     still overwrite files, for instance) but it is an improvement.
     When set, this setting cannot be reset during the same session, for
     obvious security reasons.

LOCALE
     This item is used to set the default character encoding.  The
     encoding may be specified either as an encoding name or alias (see
     <http://www.iana.org/assignments/character-sets>), or as a locale
     name.  If given as a locale name, only the character encoding of
     the locale is relevant.

     System files written by PSPP will use this encoding.  System files
     read by PSPP, for which the encoding is unknown, will be
     interpreted using this encoding.

     The full list of valid encodings and locale names/alias are
     operating system dependent.  The following are all examples of
     acceptable syntax on common GNU/Linux systems.
          SET LOCALE='iso-8859-1'.

          SET LOCALE='ru_RU.cp1251'.

          SET LOCALE='japanese'.

     Contrary to intuition, this command does not affect any aspect of
     the system's locale.


File: pspp.info,  Node: SHOW,  Next: SUBTITLE,  Prev: SET,  Up: Utilities

16.21 SHOW
==========

     SHOW
             [ALL]
             [BLANKS]
             [CC]
             [CCA]
             [CCB]
             [CCC]
             [CCD]
             [CCE]
             [COPYING]
             [DECIMALS]
             [DIRECTORY]
             [ENVIRONMENT]
             [FORMAT]
             [FUZZBITS]
             [LENGTH]
             [MXERRS]
             [MXLOOPS]
             [MXWARNS]
             [N]
             [SCOMPRESSION]
             [TEMPDIR]
             [UNDEFINED]
             [VERSION]
             [WARRANTY]
             [WEIGHT]
             [WIDTH]

   'SHOW' can be used to display the current state of PSPP's execution
parameters.  Parameters that can be changed using 'SET' (*note SET::),
can be examined using 'SHOW' using the subcommand with the same name.
'SHOW' supports the following additional subcommands:

'ALL'
     Show all settings.
'CC'
     Show all custom currency settings ('CCA' through 'CCE').
'DIRECTORY'
     Shows the current working directory.
'ENVIRONMENT'
     Shows the operating system details.
'N'
     Reports the number of cases in the active dataset.  The reported
     number is not weighted.  If no dataset is defined, then 'Unknown'
     will be reported.
'TEMPDIR'
     Shows the path of the directory where temporary files will be
     stored.
'VERSION'
     Shows the version of this installation of PSPP.
'WARRANTY'
     Show details of the lack of warranty for PSPP.
'COPYING' / 'LICENSE'
     Display the terms of PSPP's copyright licence (*note License::).

   Specifying 'SHOW' without any subcommands is equivalent to 'SHOW
ALL'.


File: pspp.info,  Node: SUBTITLE,  Next: TITLE,  Prev: SHOW,  Up: Utilities

16.22 SUBTITLE
==============

     SUBTITLE 'SUBTITLE_STRING'.
       or
     SUBTITLE SUBTITLE_STRING.

   'SUBTITLE' provides a subtitle to a particular PSPP run.  This
subtitle appears at the top of each output page below the title, if
headers are enabled on the output device.

   Specify a subtitle as a string in quotes.  The alternate syntax that
did not require quotes is now obsolete.  If it is used then the subtitle
is converted to all uppercase.


File: pspp.info,  Node: TITLE,  Prev: SUBTITLE,  Up: Utilities

16.23 TITLE
===========

     TITLE 'TITLE_STRING'.
       or
     TITLE TITLE_STRING.

   'TITLE' provides a title to a particular PSPP run.  This title
appears at the top of each output page, if headers are enabled on the
output device.

   Specify a title as a string in quotes.  The alternate syntax that did
not require quotes is now obsolete.  If it is used then the title is
converted to all uppercase.


File: pspp.info,  Node: Invoking pspp-convert,  Next: Invoking pspp-dump-sav,  Prev: Utilities,  Up: Top

17 Invoking 'pspp-convert'
**************************

'pspp-convert' is a command-line utility accompanying PSPP.  It reads an
SPSS or SPSS/PC+ system file or SPSS portable file or encrypted SPSS
syntax file INPUT and writes a copy of it to another OUTPUT in a
different format.  Synopsis:

     pspp-convert [OPTIONS] INPUT OUTPUT

     pspp-convert --help

     pspp-convert --version

   The format of INPUT is automatically detected, when possible.  The
character encoding of old SPSS system files cannot always be guessed
correctly, and SPSS/PC+ system files do not include any indication of
their encoding.  Use '-e ENCODING' to specify the encoding in this case.

   By default, the intended format for OUTPUT is inferred based on its
extension:

'csv'
'txt'
     Comma-separated value.  Each value is formatted according to its
     variable's print format.  The first line in the file contains
     variable names.

'sav'
'sys'
     SPSS system file.

'por'
     SPSS portable file.

'sps'
     SPSS syntax file.  (Only encrypted syntax files may be converted to
     this format.)

   'pspp-convert' can convert most input formats to most output formats.
Encrypted system file and syntax files are exceptions: if the input file
is in an encrypted format, then the output file must be the same format
(decrypted).  To decrypt such a file, specify the encrypted file as
INPUT.  The output will be the equivalent plaintext file.  You will be
prompted for the password (or use '-p', documented below).

   Use '-O EXTENSION' to override the inferred format or to specify the
format for unrecognized extensions.

   The following options are accepted:

'-O FORMAT'
'--output-format=FORMAT'
     Specifies the desired output format.  FORMAT must be one of the
     extensions listed above, e.g.  '-O csv' requests comma-separated
     value output.

'-c MAXCASES'
'--cases=MAXCASES'
     By default, all cases are copied from INPUT to OUTPUT.  Specifying
     this option to limit the number of cases written to OUTPUT to
     MAXCASES.

'-e CHARSET'
'--encoding=CHARSET'
     Overrides the encoding in which character strings in INPUT are
     interpreted.  This option is necessary because old SPSS system
     files, and SPSS/PC+ system files, do not self-identify their
     encoding.

'-p PASSWORD'
'--password=PASSWORD'
     Specifies the password to use to decrypt an encrypted SPSS system
     file or syntax file.  If this option is not specified,
     'pspp-convert' will prompt interactively for the password as
     necessary.

     Be aware that command-line options, including passwords, may be
     visible to other users on multiuser systems.

'-h'
'--help'
     Prints a usage message on stdout and exits.

'-v'
'--version'
     Prints version information on stdout and exits.


File: pspp.info,  Node: Invoking pspp-dump-sav,  Next: Not Implemented,  Prev: Invoking pspp-convert,  Up: Top

18 Invoking 'pspp-dump-sav'
***************************

'pspp-dump-sav' is a command-line utility accompanying PSPP.  It reads
one or more SPSS system files and prints their contents.  The output
format is useful for debugging system file readers and writers and for
discovering how to interpret unknown or poorly understood records.  End
users may find the output useful for providing the PSPP developers
information about system files that PSPP does not accurately read.

   Synopsis:

     pspp-dump-sav [-d[MAXCASES] | --data[=MAXCASES]] FILE...

     pspp-dump-sav --help | -h

     pspp-dump-sav --version | -v

   The following options are accepted:

-d[MAXCASES]
--data[=MAXCASES]
     By default, 'pspp-dump-sav' does not print any of the data in a
     system file, only the file headers.  Specify this option to print
     the data as well.  If MAXCASES is specified, then it limits the
     number of cases printed.

-h
--help
     Prints a usage message on stdout and exits.

-v
--version
     Prints version information on stdout and exits.

   Some errors that prevent files from being interpreted successfully
cause 'pspp-dump-sav' to exit without reading any additional files given
on the command line.


File: pspp.info,  Node: Not Implemented,  Next: Bugs,  Prev: Invoking pspp-dump-sav,  Up: Top

19 Not Implemented
******************

This chapter lists parts of the PSPP language that are not yet
implemented.

'2SLS'
     Two stage least squares regression

'ACF'
     Autocorrelation function

'ALSCAL'
     Multidimensional scaling

'ANACOR'
     Correspondence analysis

'ANOVA'
     Factorial analysis of variance

'CASEPLOT'
     Plot time series

'CASESTOVARS'
     Restructure complex data

'CATPCA'
     Categorical principle components analysis

'CATREG'
     Categorical regression

'CCF'
     Time series cross correlation

'CLEAR TRANSFORMATIONS'
     Clears transformations from active dataset

'CLUSTER'
     Hierarchical clustering

'CONJOINT'
     Analyse full concept data

'CORRESPONDENCE'
     Show correspondence

'COXREG'
     Cox proportional hazards regression

'CREATE'
     Create time series data

'CSDESCRIPTIVES'
     Complex samples descriptives

'CSGLM'
     Complex samples GLM

'CSLOGISTIC'
     Complex samples logistic regression

'CSPLAN'
     Complex samples design

'CSSELECT'
     Select complex samples

'CSTABULATE'
     Tabulate complex samples

'CTABLES'
     Display complex samples

'CURVEFIT'
     Fit curve to line plot

'DATE'
     Create time series data

'DEFINE'
     Syntax macros

'DETECTANOMALY'
     Find unusual cases

'DISCRIMINANT'
     Linear discriminant analysis

'EDIT'
     obsolete

'END FILE TYPE'
     Ends complex data input

'FILE TYPE'
     Complex data input

'FIT'
     Goodness of Fit

'GENLOG'
     Categorical model fitting

'GET TRANSLATE'
     Read other file formats

'GGRAPH'
     Custom defined graphs

'HILOGLINEAR'
     Hierarchical loglinear models

'HOMALS'
     Homogeneity analysis

'IGRAPH'
     Interactive graphs

'INFO'
     Local Documentation

'KEYED DATA LIST'
     Read nonsequential data

'KM'
     Kaplan-Meier

'LOGLINEAR'
     General model fitting

'MANOVA'
     Multivariate analysis of variance

'MAPS'
     Geographical display

'MATRIX'
     Matrix processing

'MATRIX DATA'
     Matrix data input

'MCONVERT'
     Convert covariance/correlation matrices

'MIXED'
     Mixed linear models

'MODEL CLOSE'
     Close server connection

'MODEL HANDLE'
     Define server connection

'MODEL LIST'
     Show existing models

'MODEL NAME'
     Specify model label

'MULTIPLE CORRESPONDENCE'
     Multiple correspondence analysis

'MULT RESPONSE'
     Multiple response analysis

'MVA'
     Missing value analysis

'NAIVEBAYES'
     Small sample bayesian prediction

'NLR'
     Non Linear Regression

'NOMREG'
     Multinomial logistic regression

'NONPAR CORR'
     Nonparametric correlation

'NUMBERED'

'OLAP CUBES'
     On-line analytical processing

'OMS'
     Output management

'ORTHOPLAN'
     Orthogonal effects design

'OVERALS'
     Nonlinear canonical correlation

'PACF'
     Partial autocorrelation

'PARTIAL CORR'
     Partial correlation

'PLANCARDS'
     Conjoint analysis planning

'PLUM'
     Estimate ordinal regression models

'POINT'
     Marker in keyed file

'PPLOT'
     Plot time series variables

'PREDICT'
     Specify forecast period

'PREFSCAL'
     Multidimensional unfolding

'PRINCALS'
     PCA by alternating least squares

'PROBIT'
     Probit analysis

'PROCEDURE OUTPUT'
     Specify output file

'PROXIMITIES'
     Pairwise similarity

'PROXSCAL'
     Multidimensional scaling of proximity data

'RATIO STATISTICS'
     Descriptives of ratios

'READ MODEL'
     Read new model

'RECORD TYPE'
     Defines a type of record within FILE TYPE

'REFORMAT'
     Read obsolete files

'REPEATING DATA'
     Specify multiple cases per input record

'REPORT'
     Pretty print working file

'RMV'
     Replace missing values

'SCRIPT'
     Run script file

'SEASON'
     Estimate seasonal factors

'SELECTPRED'
     Select predictor variables

'SPCHART'
     Plot control charts

'SPECTRA'
     Plot spectral density

'STEMLEAF'
     Plot stem-and-leaf display

'SUMMARIZE'
     Univariate statistics

'SURVIVAL'
     Survival analysis

'TDISPLAY'
     Display active models

'TREE'
     Create classification tree

'TSAPPLY'
     Apply time series model

'TSET'
     Set time sequence variables

'TSHOW'
     Show time sequence variables

'TSMODEL'
     Estimate time series model

'TSPLOT'
     Plot time sequence variables

'TWOSTEP CLUSTER'
     Cluster observations

'UNIANOVA'
     Univariate analysis

'UNNUMBERED'
     obsolete

'VALIDATEDATA'
     Identify suspicious cases

'VARCOMP'
     Estimate variance

'VARSTOCASES'
     Restructure complex data

'VERIFY'
     Report time series

'WLS'
     Weighted least squares regression

'XGRAPH'
     High resolution charts


File: pspp.info,  Node: Bugs,  Next: Function Index,  Prev: Not Implemented,  Up: Top

20 Bugs
*******

Occasionally you may encounter a bug in PSPP.

20.1 When to report bugs
========================

If you discover a bug, please first:
   * Make sure that it really is a bug.  Sometimes, what may appear to
     be a bug, turns out to be a misunderstanding of how to use the
     program.  If you are unsure, ask for advice on the pspp-users
     mailing list.  Information about the mailing list is at
     <http://lists.gnu.org/mailman/listinfo/pspp-users>.
   * Try an up to date version of PSPP; the problem may have been
     recently fixed.
   * If the problem persists in the up to date version, check to see if
     it has already been reported.  Reported issues are listed at
     <http://savannah.gnu.org/bugs/?group=pspp>.  For known issues in
     individual language features, see the relevant section in *note
     Language::.
   * If the problem exists in a recent version and it has not already
     been reported, then please report it.

20.2 How to report bugs
=======================

The best way to send a bug report is using the web page at
<http://savannah.gnu.org/bugs/?group=pspp>.  Alternatively, bug reports
may be sent by email to <bug-gnu-pspp@gnu.org>.

   In your bug report please include:
   * The version of PSPP in which you encountered the problem.  That
     means the precise version number.  Do not simply say "the latest
     version" -- releases happen quickly, and bug reports are archived
     indefinitely.
   * The operating system and type of computer on which it is running.
     On a GNU or other unix-like system, the output from the 'uname'
     command is helpful.
   * A sample of the syntax which causes the problem or, if it is a user
     interface problem, the sequence of steps required to reproduce it.
     Screen shots are not usually helpful unless you are reporting a bug
     in the graphical user interface itself.
   * A description of what you think is wrong: What happened that you
     didn't expect, and what did you expect to happen?

   The following is an example of a useful bug report:
     When I run PSPP 0.8.4 on the system:
     "Linux knut 3.5.3-gnu #1 PREEMPT Tue Aug 28 10:49:41 UTC 2012 mips64 GNU/Linux"
     Executing the following syntax:

      DATA LIST FREE /x *.
      BEGIN DATA.
      1 2 3
      END DATA.
      LIST.

     results in:

      4
      5
      6

     I think the output should be:

      1
      2
      3
Here, the developers have the necessary information to reproduce the
circumstances of the bug report, and they understand what the reporter
expected.

   Conversely, the following is a useless bug report:

     I downloaded the latest version of PSPP and entered a sequence of numbers,
     but when I analyse them it gives the wrong output.
In that example, it is impossible to reproduce, and there is no
indication of why the reporter thought what he saw was wrong.

   Note that the purpose of bug reports is to help improve the quality
of PSPP for the benefit of all users.  It is not a consultancy or
support service.  If that is what you want, you are welcome to make
private arrangements.  Since PSPP is free software, consultants have
access to the information they need to provide such support.  The PSPP
developers appreciate all users' feedback, but cannot promise an
immediate response.

   Please do not use the bug reporting address for general enquiries or
to seek help in using, installing or running the program.  For that, use
the pspp-users mailing list mentioned above.


File: pspp.info,  Node: Function Index,  Next: Command Index,  Prev: Bugs,  Up: Top

21 Function Index
*****************

 [index ]
* Menu:

* (:                                     Miscellaneous Functions.
                                                              (line  41)
* ABS:                                   Miscellaneous Mathematics.
                                                              (line   9)
* ACOS:                                  Trigonometry.        (line  10)
* ANY:                                   Set Membership.      (line  13)
* ARCOS:                                 Trigonometry.        (line   9)
* ARSIN:                                 Trigonometry.        (line  15)
* ARTAN:                                 Trigonometry.        (line  20)
* ASIN:                                  Trigonometry.        (line  16)
* ATAN:                                  Trigonometry.        (line  21)
* CDF.BERNOULLI:                         Discrete Distributions.
                                                              (line   9)
* CDF.BETA:                              Continuous Distributions.
                                                              (line   9)
* CDF.BINOM:                             Discrete Distributions.
                                                              (line  15)
* CDF.CAUCHY:                            Continuous Distributions.
                                                              (line  25)
* CDF.CHISQ:                             Continuous Distributions.
                                                              (line  31)
* CDF.EXP:                               Continuous Distributions.
                                                              (line  41)
* CDF.F:                                 Continuous Distributions.
                                                              (line  55)
* CDF.GAMMA:                             Continuous Distributions.
                                                              (line  65)
* CDF.GEOM:                              Discrete Distributions.
                                                              (line  21)
* CDF.HYPER:                             Discrete Distributions.
                                                              (line  27)
* CDF.LAPLACE:                           Continuous Distributions.
                                                              (line  76)
* CDF.LNORMAL:                           Continuous Distributions.
                                                              (line  99)
* CDF.LOGISTIC:                          Continuous Distributions.
                                                              (line  92)
* CDF.NEGBIN:                            Discrete Distributions.
                                                              (line  39)
* CDF.NORMAL:                            Continuous Distributions.
                                                              (line 106)
* CDF.PARETO:                            Continuous Distributions.
                                                              (line 129)
* CDF.POISSON:                           Discrete Distributions.
                                                              (line  46)
* CDF.RAYLEIGH:                          Continuous Distributions.
                                                              (line 136)
* CDF.T:                                 Continuous Distributions.
                                                              (line 149)
* CDF.T1G:                               Continuous Distributions.
                                                              (line 157)
* CDF.T2G:                               Continuous Distributions.
                                                              (line 163)
* CDF.UNIFORM:                           Continuous Distributions.
                                                              (line 169)
* CDF.VBNOR:                             Continuous Distributions.
                                                              (line  19)
* CDF.WEIBULL:                           Continuous Distributions.
                                                              (line 180)
* CDFNORM:                               Continuous Distributions.
                                                              (line 113)
* CFVAR:                                 Statistical Functions.
                                                              (line  24)
* CONCAT:                                String Functions.    (line   8)
* COS:                                   Trigonometry.        (line  24)
* CTIME.DAYS:                            Time Extraction.     (line   9)
* CTIME.HOURS:                           Time Extraction.     (line  12)
* CTIME.MINUTES:                         Time Extraction.     (line  15)
* CTIME.SECONDS:                         Time Extraction.     (line  18)
* DATE.DMY:                              Date Construction.   (line  39)
* DATE.MDY:                              Date Construction.   (line  40)
* DATE.MOYR:                             Date Construction.   (line  44)
* DATE.QYR:                              Date Construction.   (line  48)
* DATE.WKYR:                             Date Construction.   (line  52)
* DATE.YRDAY:                            Date Construction.   (line  56)
* DATEDIFF:                              Time and Date Arithmetic.
                                                              (line  24)
* DATESUM:                               Time and Date Arithmetic.
                                                              (line  40)
* EXP:                                   Mathematics.         (line   9)
* IDF.BETA:                              Continuous Distributions.
                                                              (line  10)
* IDF.CAUCHY:                            Continuous Distributions.
                                                              (line  26)
* IDF.CHISQ:                             Continuous Distributions.
                                                              (line  33)
* IDF.EXP:                               Continuous Distributions.
                                                              (line  42)
* IDF.F:                                 Continuous Distributions.
                                                              (line  57)
* IDF.GAMMA:                             Continuous Distributions.
                                                              (line  66)
* IDF.LAPLACE:                           Continuous Distributions.
                                                              (line  77)
* IDF.LNORMAL:                           Continuous Distributions.
                                                              (line 100)
* IDF.LOGISTIC:                          Continuous Distributions.
                                                              (line  93)
* IDF.NORMAL:                            Continuous Distributions.
                                                              (line 107)
* IDF.PARETO:                            Continuous Distributions.
                                                              (line 130)
* IDF.RAYLEIGH:                          Continuous Distributions.
                                                              (line 137)
* IDF.T:                                 Continuous Distributions.
                                                              (line 150)
* IDF.T1G:                               Continuous Distributions.
                                                              (line 158)
* IDF.T2G:                               Continuous Distributions.
                                                              (line 164)
* IDF.UNIFORM:                           Continuous Distributions.
                                                              (line 170)
* IDF.WEIBULL:                           Continuous Distributions.
                                                              (line 181)
* INDEX:                                 String Functions.    (line  13)
* INDEX <1>:                             String Functions.    (line  19)
* LAG:                                   Miscellaneous Functions.
                                                              (line   6)
* LENGTH:                                String Functions.    (line  27)
* LG10:                                  Mathematics.         (line  12)
* LN:                                    Mathematics.         (line  16)
* LNGAMMA:                               Mathematics.         (line  20)
* LOWER:                                 String Functions.    (line  30)
* LPAD:                                  String Functions.    (line  35)
* LPAD <1>:                              String Functions.    (line  41)
* LTRIM:                                 String Functions.    (line  48)
* LTRIM <1>:                             String Functions.    (line  53)
* MAX:                                   Statistical Functions.
                                                              (line  29)
* MEAN:                                  Statistical Functions.
                                                              (line  33)
* MEDIAN:                                Statistical Functions.
                                                              (line  36)
* MIN:                                   Statistical Functions.
                                                              (line  41)
* MISSING:                               Missing Value Functions.
                                                              (line  12)
* MOD:                                   Miscellaneous Mathematics.
                                                              (line  12)
* MOD10:                                 Miscellaneous Mathematics.
                                                              (line  18)
* NCDF.BETA:                             Continuous Distributions.
                                                              (line  13)
* NCDF.CHISQ:                            Continuous Distributions.
                                                              (line  35)
* NMISS:                                 Missing Value Functions.
                                                              (line  15)
* NORMAL:                                Continuous Distributions.
                                                              (line 119)
* NPDF.BETA:                             Continuous Distributions.
                                                              (line  12)
* NUMBER:                                String Functions.    (line  58)
* NVALID:                                Missing Value Functions.
                                                              (line  20)
* PDF.BERNOULLI:                         Discrete Distributions.
                                                              (line   8)
* PDF.BETA:                              Continuous Distributions.
                                                              (line   8)
* PDF.BINOM:                             Discrete Distributions.
                                                              (line  14)
* PDF.BVNOR:                             Continuous Distributions.
                                                              (line  18)
* PDF.CAUCHY:                            Continuous Distributions.
                                                              (line  24)
* PDF.EXP:                               Continuous Distributions.
                                                              (line  40)
* PDF.F:                                 Continuous Distributions.
                                                              (line  54)
* PDF.GAMMA:                             Continuous Distributions.
                                                              (line  64)
* PDF.GEOM:                              Discrete Distributions.
                                                              (line  20)
* PDF.HYPER:                             Discrete Distributions.
                                                              (line  26)
* PDF.LANDAU:                            Continuous Distributions.
                                                              (line  71)
* PDF.LAPLACE:                           Continuous Distributions.
                                                              (line  75)
* PDF.LNORMAL:                           Continuous Distributions.
                                                              (line  98)
* PDF.LOG:                               Discrete Distributions.
                                                              (line  33)
* PDF.LOGISTIC:                          Continuous Distributions.
                                                              (line  91)
* PDF.NEGBIN:                            Discrete Distributions.
                                                              (line  38)
* PDF.NORMAL:                            Continuous Distributions.
                                                              (line 105)
* PDF.NTAIL:                             Continuous Distributions.
                                                              (line 122)
* PDF.PARETO:                            Continuous Distributions.
                                                              (line 128)
* PDF.POISSON:                           Discrete Distributions.
                                                              (line  45)
* PDF.RAYLEIGH:                          Continuous Distributions.
                                                              (line 135)
* PDF.RTAIL:                             Continuous Distributions.
                                                              (line 142)
* PDF.T:                                 Continuous Distributions.
                                                              (line 148)
* PDF.T1G:                               Continuous Distributions.
                                                              (line 156)
* PDF.T2G:                               Continuous Distributions.
                                                              (line 162)
* PDF.UNIFORM:                           Continuous Distributions.
                                                              (line 168)
* PDF.WEIBULL:                           Continuous Distributions.
                                                              (line 179)
* PDF.XPOWER:                            Continuous Distributions.
                                                              (line  48)
* PROBIT:                                Continuous Distributions.
                                                              (line 116)
* RANGE:                                 Set Membership.      (line  19)
* REPLACE:                               String Functions.    (line  67)
* RINDEX:                                String Functions.    (line  73)
* RINDEX <1>:                            String Functions.    (line  79)
* RND:                                   Miscellaneous Mathematics.
                                                              (line  22)
* RPAD:                                  String Functions.    (line  87)
* RPAD <1>:                              String Functions.    (line  93)
* RTRIM:                                 String Functions.    (line 100)
* RTRIM <1>:                             String Functions.    (line 104)
* RV.BERNOULLI:                          Discrete Distributions.
                                                              (line  10)
* RV.BETA:                               Continuous Distributions.
                                                              (line  11)
* RV.BINOM:                              Discrete Distributions.
                                                              (line  16)
* RV.CAUCHY:                             Continuous Distributions.
                                                              (line  27)
* RV.CHISQ:                              Continuous Distributions.
                                                              (line  34)
* RV.EXP:                                Continuous Distributions.
                                                              (line  43)
* RV.F:                                  Continuous Distributions.
                                                              (line  58)
* RV.GAMMA:                              Continuous Distributions.
                                                              (line  67)
* RV.GEOM:                               Discrete Distributions.
                                                              (line  22)
* RV.HYPER:                              Discrete Distributions.
                                                              (line  28)
* RV.LANDAU:                             Continuous Distributions.
                                                              (line  72)
* RV.LAPLACE:                            Continuous Distributions.
                                                              (line  78)
* RV.LEVY:                               Continuous Distributions.
                                                              (line  82)
* RV.LNORMAL:                            Continuous Distributions.
                                                              (line 101)
* RV.LOG:                                Discrete Distributions.
                                                              (line  34)
* RV.LOGISTIC:                           Continuous Distributions.
                                                              (line  94)
* RV.LVSKEW:                             Continuous Distributions.
                                                              (line  86)
* RV.NEGBIN:                             Discrete Distributions.
                                                              (line  40)
* RV.NORMAL:                             Continuous Distributions.
                                                              (line 108)
* RV.NTAIL:                              Continuous Distributions.
                                                              (line 123)
* RV.PARETO:                             Continuous Distributions.
                                                              (line 131)
* RV.POISSON:                            Discrete Distributions.
                                                              (line  47)
* RV.RAYLEIGH:                           Continuous Distributions.
                                                              (line 138)
* RV.RTAIL:                              Continuous Distributions.
                                                              (line 143)
* RV.T:                                  Continuous Distributions.
                                                              (line 151)
* RV.UNIFORM:                            Continuous Distributions.
                                                              (line 171)
* RV.WEIBULL:                            Continuous Distributions.
                                                              (line 182)
* RV.XPOWER:                             Continuous Distributions.
                                                              (line  49)
* SD:                                    Statistical Functions.
                                                              (line  45)
* SIG.CHISQ:                             Continuous Distributions.
                                                              (line  32)
* SIG.F:                                 Continuous Distributions.
                                                              (line  56)
* SIN:                                   Trigonometry.        (line  27)
* SQRT:                                  Mathematics.         (line  24)
* STRING:                                String Functions.    (line 109)
* STRUNC:                                String Functions.    (line 114)
* SUBSTR:                                String Functions.    (line 119)
* SUBSTR <1>:                            String Functions.    (line 124)
* SUM:                                   Statistical Functions.
                                                              (line  48)
* SYSMIS:                                Missing Value Functions.
                                                              (line  25)
* TAN:                                   Trigonometry.        (line  30)
* TIME.DAYS:                             Time Construction.   (line   9)
* TIME.HMS:                              Time Construction.   (line  12)
* TRUNC:                                 Miscellaneous Mathematics.
                                                              (line  30)
* UNIFORM:                               Continuous Distributions.
                                                              (line 176)
* UPCASE:                                String Functions.    (line 134)
* VALUE:                                 Missing Value Functions.
                                                              (line  31)
* VARIANCE:                              Statistical Functions.
                                                              (line  51)
* XDATE.DATE:                            Date Extraction.     (line  18)
* XDATE.HOUR:                            Date Extraction.     (line  24)
* XDATE.JDAY:                            Date Extraction.     (line  30)
* XDATE.MDAY:                            Date Extraction.     (line  34)
* XDATE.MINUTE:                          Date Extraction.     (line  38)
* XDATE.MONTH:                           Date Extraction.     (line  42)
* XDATE.QUARTER:                         Date Extraction.     (line  46)
* XDATE.SECOND:                          Date Extraction.     (line  50)
* XDATE.TDAY:                            Date Extraction.     (line  54)
* XDATE.TIME:                            Date Extraction.     (line  57)
* XDATE.WEEK:                            Date Extraction.     (line  62)
* XDATE.WKDAY:                           Date Extraction.     (line  66)
* XDATE.YEAR:                            Date Extraction.     (line  70)
* YRMODA:                                Miscellaneous Functions.
                                                              (line  28)


File: pspp.info,  Node: Command Index,  Next: Concept Index,  Prev: Function Index,  Up: Top

22 Command Index
****************

 [index ]
* Menu:

* *:                                     COMMENT.              (line  6)
* ADD DOCUMENT:                          ADD DOCUMENT.         (line  6)
* ADD FILES:                             ADD FILES.            (line  6)
* ADD VALUE LABELS:                      ADD VALUE LABELS.     (line  6)
* AGGREGATE:                             AGGREGATE.            (line  6)
* APPLY DICTIONARY:                      APPLY DICTIONARY.     (line  6)
* AUTORECODE:                            AUTORECODE.           (line  6)
* BEGIN DATA:                            BEGIN DATA.           (line  6)
* BINOMIAL:                              BINOMIAL.             (line  6)
* BREAK:                                 BREAK.                (line  6)
* CACHE:                                 CACHE.                (line  6)
* CD:                                    CD.                   (line  6)
* CHISQUARE:                             CHISQUARE.            (line  6)
* Cochran:                               COCHRAN.              (line  6)
* COMMENT:                               COMMENT.              (line  6)
* COMPUTE:                               COMPUTE.              (line  6)
* CORRELATIONS:                          CORRELATIONS.         (line  6)
* COUNT:                                 COUNT.                (line  6)
* CROSSTABS:                             CROSSTABS.            (line  6)
* DATA LIST:                             DATA LIST.            (line  6)
* DATA LIST FIXED:                       DATA LIST FIXED.      (line  6)
* DATA LIST FREE:                        DATA LIST FREE.       (line  6)
* DATA LIST LIST:                        DATA LIST LIST.       (line  6)
* DATAFILE ATTRIBUTE:                    DATAFILE ATTRIBUTE.   (line  6)
* DATASET:                               DATASET.              (line  6)
* DATASET ACTIVATE:                      DATASET.              (line 22)
* DATASET CLOSE:                         DATASET.              (line 41)
* DATASET COPY:                          DATASET.              (line 28)
* DATASET DECLARE:                       DATASET.              (line 35)
* DATASET DISPLAY:                       DATASET.              (line 47)
* DATASET NAME:                          DATASET.              (line 18)
* DELETE VARIABLES:                      DELETE VARIABLES.     (line  6)
* DESCRIPTIVES:                          DESCRIPTIVES.         (line  6)
* DISPLAY:                               DISPLAY.              (line  6)
* DISPLAY DOCUMENTS:                     DISPLAY DOCUMENTS.    (line  6)
* DISPLAY FILE LABEL:                    DISPLAY FILE LABEL.   (line  6)
* DO IF:                                 DO IF.                (line  6)
* DO REPEAT:                             DO REPEAT.            (line  6)
* DOCUMENT:                              DOCUMENT.             (line  6)
* DROP DOCUMENTS:                        DROP DOCUMENTS.       (line  6)
* ECHO:                                  ECHO.                 (line  6)
* END CASE:                              END CASE.             (line  6)
* END DATA:                              BEGIN DATA.           (line  6)
* END FILE:                              END FILE.             (line  6)
* ERASE:                                 ERASE.                (line  6)
* EXAMINE:                               EXAMINE.              (line  6)
* EXECUTE:                               EXECUTE.              (line  6)
* EXPORT:                                EXPORT.               (line  6)
* FACTOR:                                FACTOR.               (line  6)
* FILE HANDLE:                           FILE HANDLE.          (line  6)
* FILE LABEL:                            FILE LABEL.           (line  6)
* FILTER:                                FILTER.               (line  6)
* FINISH:                                FINISH.               (line  6)
* FLIP:                                  FLIP.                 (line  6)
* FORMATS:                               FORMATS.              (line  6)
* FREQUENCIES:                           FREQUENCIES.          (line  6)
* FRIEDMAN:                              FRIEDMAN.             (line  6)
* GET:                                   Reading data from a pre-prepared PSPP file.
                                                               (line  6)
* GET <1>:                               GET.                  (line  6)
* GET DATA:                              GET DATA.             (line  6)
* GLM:                                   GLM.                  (line  6)
* GRAPH:                                 GRAPH.                (line  6)
* HOST:                                  HOST.                 (line  6)
* IF:                                    IF.                   (line  6)
* IMPORT:                                IMPORT.               (line  6)
* INCLUDE:                               INCLUDE.              (line  6)
* INPUT PROGRAM:                         INPUT PROGRAM.        (line  6)
* INSERT:                                INSERT.               (line  6)
* K-S:                                   KOLMOGOROV-SMIRNOV.   (line  6)
* K-W:                                   KRUSKAL-WALLIS.       (line  6)
* KENDALL:                               KENDALL.              (line  6)
* KOLMOGOROV-SMIRNOV:                    KOLMOGOROV-SMIRNOV.   (line  6)
* KRUSKAL-WALLIS:                        KRUSKAL-WALLIS.       (line  6)
* LEAVE:                                 LEAVE.                (line  6)
* LIST:                                  Listing the data.     (line  6)
* LIST <1>:                              LIST.                 (line  6)
* LOGISTIC REGRESSION:                   LOGISTIC REGRESSION.  (line  6)
* LOOP:                                  LOOP.                 (line  6)
* M-W:                                   MANN-WHITNEY.         (line  6)
* MANN-WHITNEY:                          MANN-WHITNEY.         (line  6)
* MATCH FILES:                           MATCH FILES.          (line  6)
* MCNEMAR:                               MCNEMAR.              (line  6)
* MEANS:                                 MEANS.                (line  6)
* MEDIAN:                                MEDIAN.               (line  6)
* MISSING VALUES:                        MISSING VALUES.       (line  6)
* MODIFY VARS:                           MODIFY VARS.          (line  6)
* MRSETS:                                MRSETS.               (line  6)
* N OF CASES:                            N OF CASES.           (line  6)
* NEW FILE:                              NEW FILE.             (line  6)
* NPAR TESTS:                            NPAR TESTS.           (line  6)
* NUMERIC:                               NUMERIC.              (line  6)
* ONEWAY:                                ONEWAY.               (line  6)
* OUTPUT:                                OUTPUT.               (line  6)
* PERMISSIONS:                           PERMISSIONS.          (line  6)
* PRESERVE:                              PRESERVE and RESTORE. (line  6)
* PRINT:                                 PRINT.                (line  6)
* PRINT EJECT:                           PRINT EJECT.          (line  6)
* PRINT FORMATS:                         PRINT FORMATS.        (line  6)
* PRINT SPACE:                           PRINT SPACE.          (line  6)
* QUICK CLUSTER:                         QUICK CLUSTER.        (line  6)
* RANK:                                  RANK.                 (line  6)
* RECODE:                                RECODE.               (line  6)
* REGRESSION:                            Linear Regression.    (line  6)
* REGRESSION <1>:                        Syntax.               (line  6)
* RELIABILITY:                           RELIABILITY.          (line  6)
* RENAME VARIABLES:                      RENAME VARIABLES.     (line  6)
* REPEATING DATA:                        REPEATING DATA.       (line  6)
* REREAD:                                REREAD.               (line  6)
* RESTORE:                               PRESERVE and RESTORE. (line  6)
* ROC:                                   ROC.                  (line  6)
* RUNS:                                  RUNS.                 (line  6)
* SAMPLE:                                SAMPLE.               (line  6)
* SAVE:                                  Saving data to a PSPP file..
                                                               (line  6)
* SAVE <1>:                              SAVE.                 (line  6)
* SAVE TRANSLATE:                        SAVE TRANSLATE.       (line  6)
* SELECT IF:                             SELECT IF.            (line  6)
* SET:                                   SET.                  (line  6)
* SHOW:                                  SHOW.                 (line  6)
* SIGN:                                  SIGN.                 (line  6)
* SORT CASES:                            SORT CASES.           (line  6)
* SORT VARIABLES:                        SORT VARIABLES.       (line  6)
* SPLIT FILE:                            SPLIT FILE.           (line  6)
* STRING:                                STRING.               (line  6)
* SUBTITLE:                              SUBTITLE.             (line  6)
* SYSFILE INFO:                          SYSFILE INFO.         (line  6)
* T-TEST:                                Testing for differences of means.
                                                               (line  6)
* T-TEST <1>:                            T-TEST.               (line  6)
* TEMPORARY:                             TEMPORARY.            (line  6)
* TITLE:                                 TITLE.                (line  6)
* UPDATE:                                UPDATE.               (line  6)
* VALUE LABELS:                          VALUE LABELS.         (line  6)
* VARIABLE ALIGNMENT:                    VARIABLE ALIGNMENT.   (line  6)
* VARIABLE ATTRIBUTE:                    VARIABLE ATTRIBUTE.   (line  6)
* VARIABLE LABELS:                       VARIABLE LABELS.      (line  6)
* VARIABLE LEVEL:                        VARIABLE LEVEL.       (line  6)
* VARIABLE ROLE:                         VARIABLE ROLE.        (line  6)
* VARIABLE WIDTH:                        VARIABLE WIDTH.       (line  6)
* VECTOR:                                VECTOR.               (line  6)
* WEIGHT:                                WEIGHT.               (line  6)
* WILCOXON:                              WILCOXON.             (line  6)
* WRITE:                                 WRITE.                (line  6)
* WRITE FORMATS:                         WRITE FORMATS.        (line  6)
* XEXPORT:                               XEXPORT.              (line  6)
* XSAVE:                                 XSAVE.                (line  6)


File: pspp.info,  Node: Concept Index,  Next: GNU Free Documentation License,  Prev: Command Index,  Up: Top

23 Concept Index
****************

 [index ]
* Menu:

* '"':                                   Tokens.              (line  64)
* "is defined as":                       BNF.                 (line  44)
* '$CASENUM':                            System Variables.    (line  11)
* '$DATE':                               System Variables.    (line  15)
* '$JDATE':                              System Variables.    (line  19)
* '$LENGTH':                             System Variables.    (line  23)
* '$SYSMIS':                             System Variables.    (line  26)
* '$TIME':                               System Variables.    (line  29)
* '$WIDTH':                              System Variables.    (line  33)
* '&':                                   Logical Operators.   (line  11)
* ''':                                   Tokens.              (line  64)
* '(':                                   Functions.           (line   6)
* '( )':                                 Grouping Operators.  (line   6)
* ')':                                   Functions.           (line   6)
* '*':                                   Arithmetic Operators.
                                                              (line  15)
* '**':                                  Arithmetic Operators.
                                                              (line  24)
* '+':                                   Arithmetic Operators.
                                                              (line   9)
* '-':                                   Arithmetic Operators.
                                                              (line  12)
* '-' <1>:                               Arithmetic Operators.
                                                              (line  29)
* '.':                                   Attributes.          (line  15)
* '.' <1>:                               BNF.                 (line  29)
* '/':                                   Arithmetic Operators.
                                                              (line  19)
* '<':                                   Relational Operators.
                                                              (line  25)
* '<=':                                  Relational Operators.
                                                              (line  21)
* '<>':                                  Relational Operators.
                                                              (line  37)
* '=':                                   Relational Operators.
                                                              (line  17)
* '>':                                   Relational Operators.
                                                              (line  33)
* '>=':                                  Relational Operators.
                                                              (line  29)
* '_':                                   Attributes.          (line  20)
* '|':                                   Logical Operators.   (line  17)
* '~':                                   Logical Operators.   (line  23)
* '~=':                                  Relational Operators.
                                                              (line  37)
* absolute value:                        Miscellaneous Mathematics.
                                                              (line   9)
* addition:                              Arithmetic Operators.
                                                              (line   9)
* analysis of variance:                  GLM.                 (line   6)
* analysis of variance <1>:              ONEWAY.              (line   6)
* 'AND':                                 Logical Operators.   (line  11)
* ANOVA:                                 GLM.                 (line   6)
* ANOVA <1>:                             ONEWAY.              (line   6)
* arccosine:                             Trigonometry.        (line   9)
* arcsine:                               Trigonometry.        (line  15)
* arctangent:                            Trigonometry.        (line  20)
* Area under curve:                      ROC.                 (line   6)
* arguments, invalid:                    Date Construction.   (line  35)
* arguments, minimum valid:              Statistical Functions.
                                                              (line  15)
* arguments, of date construction functions: Date Construction.
                                                              (line   6)
* arguments, of date extraction functions: Date Extraction.   (line   6)
* arithmetic mean:                       MEANS.               (line  43)
* arithmetic operators:                  Arithmetic Operators.
                                                              (line   6)
* attributes of variables:               Attributes.          (line   6)
* Backus-Naur Form:                      BNF.                 (line   6)
* bar chart:                             FREQUENCIES.         (line  89)
* bar chart <1>:                         BAR CHART.           (line   6)
* bar chart <2>:                         CROSSTABS.           (line 157)
* Batch syntax:                          Syntax Variants.     (line   6)
* binary formats:                        Binary and Hexadecimal Numeric Formats.
                                                              (line   6)
* binomial test:                         BINOMIAL.            (line   6)
* bivariate logistic regression:         LOGISTIC REGRESSION. (line   6)
* BNF:                                   BNF.                 (line   6)
* Boolean:                               Boolean Values.      (line   6)
* Boolean <1>:                           Logical Operators.   (line   6)
* boxplot:                               EXAMINE.             (line  57)
* bugs:                                  Bugs.                (line   6)
* case conversion:                       String Functions.    (line 134)
* case-sensitivity:                      Tokens.              (line  20)
* case-sensitivity <1>:                  Tokens.              (line  64)
* cases:                                 Data Input and Output.
                                                              (line   6)
* changing directory:                    CD.                  (line   6)
* changing file permissions:             PERMISSIONS.         (line   6)
* chi-square:                            CROSSTABS.           (line 118)
* chisquare:                             CROSSTABS.           (line 118)
* chisquare test:                        CHISQUARE.           (line   6)
* clustering:                            QUICK CLUSTER.       (line   6)
* Cochran Q test:                        COCHRAN.             (line   6)
* coefficient of concordance:            KENDALL.             (line   6)
* coefficient of variation:              Statistical Functions.
                                                              (line  24)
* comma separated values:                Reading data from other sources.
                                                              (line   6)
* command file:                          Files.               (line  10)
* command syntax, description of:        BNF.                 (line   6)
* commands, ordering:                    Order of Commands.   (line   6)
* commands, structure:                   Commands.            (line   6)
* commands, unimplemented:               Not Implemented.     (line   9)
* concatenation:                         String Functions.    (line   8)
* conditionals:                          Conditionals and Looping.
                                                              (line   6)
* consistency:                           Testing data consistency.
                                                              (line   6)
* constructing dates:                    Date Construction.   (line   6)
* constructing times:                    Time Construction.   (line   6)
* control flow:                          Conditionals and Looping.
                                                              (line   6)
* convention, 'TO':                      Sets of Variables.   (line   6)
* copyright:                             License.             (line   6)
* correlation:                           CORRELATIONS.        (line  20)
* cosine:                                Trigonometry.        (line  24)
* covariance:                            CORRELATIONS.        (line  52)
* Cronbach's Alpha:                      RELIABILITY.         (line  13)
* cross-case function:                   Miscellaneous Functions.
                                                              (line   6)
* currency formats:                      Custom Currency Formats.
                                                              (line   6)
* custom attributes:                     Attributes.          (line  73)
* data:                                  Data Input and Output.
                                                              (line   6)
* data file:                             Files.               (line  17)
* data files:                            GET DATA /TYPE=TXT.  (line  14)
* data reduction:                        FACTOR.              (line   6)
* Data, embedding in syntax files:       BEGIN DATA.          (line   6)
* data, embedding in syntax files:       DATA LIST.           (line   6)
* data, fixed-format, reading:           DATA LIST FIXED.     (line   6)
* data, reading from a file:             DATA LIST.           (line   6)
* databases:                             Reading data from other sources.
                                                              (line   6)
* databases <1>:                         GET DATA /TYPE=PSQL. (line  13)
* dataset:                               Datasets.            (line   6)
* date examination:                      Date Extraction.     (line   6)
* date formats:                          Time and Date Formats.
                                                              (line   6)
* date, Julian:                          Miscellaneous Functions.
                                                              (line  28)
* dates:                                 Time and Date.       (line   6)
* dates, concepts:                       Time and Date Concepts.
                                                              (line  15)
* dates, constructing:                   Date Construction.   (line   6)
* dates, day of the month:               Date Extraction.     (line  34)
* dates, day of the week:                Date Extraction.     (line  66)
* dates, day of the year:                Date Extraction.     (line  30)
* dates, day-month-year:                 Date Construction.   (line  39)
* dates, in days:                        Date Extraction.     (line  18)
* dates, in hours:                       Date Extraction.     (line  24)
* dates, in minutes:                     Date Extraction.     (line  38)
* dates, in months:                      Date Extraction.     (line  42)
* dates, in quarters:                    Date Extraction.     (line  46)
* dates, in seconds:                     Date Extraction.     (line  50)
* dates, in weekdays:                    Date Extraction.     (line  66)
* dates, in weeks:                       Date Extraction.     (line  62)
* dates, in years:                       Date Extraction.     (line  70)
* dates, mathematical properties of:     Time and Date Arithmetic.
                                                              (line   6)
* dates, month-year:                     Date Construction.   (line  44)
* dates, quarter-year:                   Date Construction.   (line  48)
* dates, time of day:                    Date Extraction.     (line  57)
* dates, valid:                          Time and Date.       (line   6)
* dates, week-year:                      Date Construction.   (line  52)
* dates, year-day:                       Date Construction.   (line  56)
* day of the month:                      Date Extraction.     (line  34)
* day of the week:                       Date Extraction.     (line  66)
* day of the year:                       Date Extraction.     (line  30)
* day-month-year:                        Date Construction.   (line  39)
* days:                                  Time Construction.   (line   9)
* days <1>:                              Time Extraction.     (line   9)
* days <2>:                              Date Extraction.     (line  18)
* days <3>:                              Date Extraction.     (line  54)
* decimal places:                        OUTPUT.              (line   6)
* description of command syntax:         BNF.                 (line   6)
* deviation, standard:                   Statistical Functions.
                                                              (line  45)
* dictionary:                            Datasets.            (line   6)
* directory:                             CD.                  (line   6)
* division:                              Arithmetic Operators.
                                                              (line  19)
* DocBook:                               Introduction.        (line  15)
* Embedding data in syntax files:        BEGIN DATA.          (line   6)
* embedding data in syntax files:        DATA LIST.           (line   6)
* embedding fixed-format data:           DATA LIST FIXED.     (line   6)
* encoding, characters:                  SET.                 (line 386)
* 'EQ':                                  Relational Operators.
                                                              (line  17)
* equality, testing:                     Relational Operators.
                                                              (line  17)
* erroneous data:                        Identifying incorrect data.
                                                              (line   6)
* errors, in data:                       Identifying incorrect data.
                                                              (line   6)
* examination, of times:                 Time Extraction.     (line   6)
* Exploratory data analysis:             EXAMINE.             (line   6)
* Exploratory data analysis <1>:         GRAPH.               (line   6)
* exponentiation:                        Arithmetic Operators.
                                                              (line  24)
* 'expression':                          BNF.                 (line  41)
* expressions, mathematical:             Expressions.         (line   6)
* extraction, of dates:                  Date Extraction.     (line   6)
* extraction, of time:                   Time Extraction.     (line   6)
* factor analysis:                       FACTOR.              (line   6)
* factorial anova:                       GLM.                 (line   6)
* false:                                 Logical Operators.   (line   6)
* file definition commands:              Types of Commands.   (line  14)
* file handles:                          File Handles.        (line   6)
* file mode:                             PERMISSIONS.         (line   6)
* file, command:                         Files.               (line  10)
* file, data:                            Files.               (line  17)
* file, output:                          Files.               (line  21)
* file, portable:                        Files.               (line  31)
* file, syntax file:                     Files.               (line  10)
* file, system:                          Files.               (line  27)
* fixed effects:                         GLM.                 (line   6)
* fixed-format data, reading:            DATA LIST FIXED.     (line   6)
* flow of control:                       Conditionals and Looping.
                                                              (line   6)
* formats:                               Input and Output Formats.
                                                              (line   6)
* Friedman test:                         FRIEDMAN.            (line   6)
* function, cross-case:                  Miscellaneous Functions.
                                                              (line   6)
* functions:                             Functions.           (line   6)
* functions, miscellaneous:              Miscellaneous Functions.
                                                              (line   6)
* functions, missing-value:              Missing Value Functions.
                                                              (line   6)
* functions, statistical:                Statistical Functions.
                                                              (line   6)
* functions, string:                     String Functions.    (line   6)
* functions, time & date:                Time and Date.       (line   6)
* 'GE':                                  Relational Operators.
                                                              (line  29)
* geometric mean:                        MEANS.               (line  59)
* Gnumeric:                              GET DATA /TYPE=GNM/ODS.
                                                              (line  13)
* Graphic user interface:                Invoking PSPPIRE.    (line   9)
* greater than:                          Relational Operators.
                                                              (line  33)
* greater than or equal to:              Relational Operators.
                                                              (line  29)
* grouping operators:                    Grouping Operators.  (line   6)
* 'GT':                                  Relational Operators.
                                                              (line  33)
* harmonic mean:                         MEANS.               (line  58)
* headers:                               SET.                 (line 344)
* hexadecimal formats:                   Binary and Hexadecimal Numeric Formats.
                                                              (line   6)
* histogram:                             FREQUENCIES.         (line  71)
* histogram <1>:                         EXAMINE.             (line  57)
* histogram <2>:                         HISTOGRAM.           (line   6)
* hours:                                 Time Extraction.     (line  12)
* hours <1>:                             Date Extraction.     (line  24)
* hours-minutes-seconds:                 Time Construction.   (line  12)
* HTML:                                  Introduction.        (line  15)
* HTML <1>:                              HTML Output Options. (line   6)
* Hypothesis testing:                    Hypothesis Testing.  (line   6)
* identifiers:                           Tokens.              (line  11)
* identifiers, reserved:                 Tokens.              (line  25)
* inequality, testing:                   Relational Operators.
                                                              (line  37)
* input:                                 Data Input and Output.
                                                              (line   6)
* input program commands:                Types of Commands.   (line  21)
* 'integer':                             BNF.                 (line  17)
* integers:                              Tokens.              (line  44)
* Interactive syntax:                    Syntax Variants.     (line   6)
* intersection, logical:                 Logical Operators.   (line  11)
* introduction:                          Introduction.        (line   6)
* inverse cosine:                        Trigonometry.        (line   9)
* inverse sine:                          Trigonometry.        (line  15)
* inverse tangent:                       Trigonometry.        (line  20)
* inversion, logical:                    Logical Operators.   (line  23)
* Inverting data:                        Inverting negatively coded variables.
                                                              (line   6)
* invocation:                            Invoking PSPP.       (line   6)
* Invocation:                            Invoking pspp-convert.
                                                              (line   6)
* Invocation <1>:                        Invoking pspp-dump-sav.
                                                              (line   6)
* Julian date:                           Miscellaneous Functions.
                                                              (line  28)
* K-means clustering:                    QUICK CLUSTER.       (line   6)
* Kendall's W test:                      KENDALL.             (line   6)
* keywords:                              BNF.                 (line  10)
* Kolmogorov-Smirnov test:               KOLMOGOROV-SMIRNOV.  (line   6)
* Kruskal-Wallis test:                   KRUSKAL-WALLIS.      (line   6)
* labels, value:                         Attributes.          (line  59)
* labels, variable:                      Attributes.          (line  56)
* language, command structure:           Commands.            (line   6)
* language, lexical analysis:            Tokens.              (line   6)
* language, PSPP:                        Introduction.        (line   6)
* language, PSPP <1>:                    Language.            (line   6)
* language, tokens:                      Tokens.              (line   6)
* 'LE':                                  Relational Operators.
                                                              (line  21)
* length:                                SET.                 (line 344)
* less than:                             Relational Operators.
                                                              (line  25)
* less than or equal to:                 Relational Operators.
                                                              (line  21)
* lexical analysis:                      Tokens.              (line   6)
* licence:                               License.             (line   6)
* license:                               License.             (line   6)
* Likert scale:                          Inverting negatively coded variables.
                                                              (line   6)
* linear regression:                     Linear Regression.   (line   6)
* linear regression <1>:                 REGRESSION.          (line   6)
* locale:                                SET.                 (line 386)
* logarithms:                            Mathematics.         (line  12)
* logical intersection:                  Logical Operators.   (line  11)
* logical inversion:                     Logical Operators.   (line  23)
* logical operators:                     Logical Operators.   (line   6)
* logical union:                         Logical Operators.   (line  17)
* logistic regression:                   LOGISTIC REGRESSION. (line   6)
* loops:                                 Conditionals and Looping.
                                                              (line   6)
* 'LT':                                  Relational Operators.
                                                              (line  25)
* Mann-Whitney U test:                   MANN-WHITNEY.        (line   6)
* mathematical expressions:              Expressions.         (line   6)
* mathematics:                           Functions.           (line   6)
* mathematics, advanced:                 Mathematics.         (line   6)
* mathematics, applied to times & dates: Time and Date Arithmetic.
                                                              (line   6)
* mathematics, miscellaneous:            Miscellaneous Mathematics.
                                                              (line   6)
* maximum:                               Statistical Functions.
                                                              (line  29)
* McNemar test:                          MCNEMAR.             (line   6)
* mean:                                  Statistical Functions.
                                                              (line  33)
* means:                                 MEANS.               (line   6)
* median:                                Statistical Functions.
                                                              (line  36)
* Median test:                           MEDIAN.              (line   6)
* membership, of set:                    Set Membership.      (line   6)
* memory, amount used to store cases:    SET.                 (line 234)
* minimum:                               Statistical Functions.
                                                              (line  41)
* minimum valid number of arguments:     Statistical Functions.
                                                              (line  15)
* minutes:                               Time Extraction.     (line  15)
* minutes <1>:                           Date Extraction.     (line  38)
* missing values:                        Missing Observations.
                                                              (line   6)
* missing values <1>:                    Attributes.          (line  46)
* missing values <2>:                    Missing Value Functions.
                                                              (line   6)
* mode:                                  PERMISSIONS.         (line   6)
* modulus:                               Miscellaneous Mathematics.
                                                              (line  12)
* modulus, by 10:                        Miscellaneous Mathematics.
                                                              (line  18)
* month-year:                            Date Construction.   (line  44)
* months:                                Date Extraction.     (line  42)
* more:                                  SET.                 (line 344)
* multiplication:                        Arithmetic Operators.
                                                              (line  15)
* names, of functions:                   Functions.           (line   6)
* 'NE':                                  Relational Operators.
                                                              (line  37)
* negation:                              Arithmetic Operators.
                                                              (line  29)
* nonparametric tests:                   NPAR TESTS.          (line   6)
* nonterminals:                          BNF.                 (line  33)
* normality, testing:                    Testing for normality.
                                                              (line   6)
* normality, testing <1>:                EXAMINE.             (line   6)
* normality, testing <2>:                GRAPH.               (line   6)
* 'NOT':                                 Logical Operators.   (line  23)
* npplot:                                EXAMINE.             (line  57)
* null hypothesis:                       Hypothesis Testing.  (line   6)
* 'number':                              BNF.                 (line  14)
* numbers:                               Tokens.              (line  44)
* numbers, converting from strings:      String Functions.    (line  58)
* numbers, converting to strings:        String Functions.    (line 109)
* numeric formats:                       Basic Numeric Formats.
                                                              (line   6)
* obligations, your:                     License.             (line   6)
* observations:                          Data Input and Output.
                                                              (line   6)
* OpenDocument:                          GET DATA /TYPE=GNM/ODS.
                                                              (line  13)
* operations, order of:                  Order of Operations. (line   6)
* operator precedence:                   Order of Operations. (line   6)
* operators:                             Tokens.              (line  95)
* operators <1>:                         BNF.                 (line  26)
* operators <2>:                         Functions.           (line   6)
* operators, arithmetic:                 Arithmetic Operators.
                                                              (line   6)
* operators, grouping:                   Grouping Operators.  (line   6)
* operators, logical:                    Logical Operators.   (line   6)
* 'OR':                                  Logical Operators.   (line  17)
* order of commands:                     Order of Commands.   (line   6)
* order of operations:                   Order of Operations. (line   6)
* output:                                Data Input and Output.
                                                              (line   6)
* output file:                           Files.               (line  21)
* p-value:                               Hypothesis Testing.  (line   6)
* padding strings:                       String Functions.    (line  87)
* pager:                                 SET.                 (line 344)
* parentheses:                           Grouping Operators.  (line   6)
* parentheses <1>:                       Functions.           (line   6)
* PDF:                                   Introduction.        (line  15)
* PDF <1>:                               PDF PostScript and SVG Output Options.
                                                              (line   6)
* percentiles:                           FREQUENCIES.         (line  64)
* percentiles <1>:                       EXAMINE.             (line  92)
* period:                                Attributes.          (line  15)
* piechart:                              FREQUENCIES.         (line  79)
* portable file:                         Files.               (line  31)
* postgres:                              GET DATA /TYPE=PSQL. (line  13)
* PostScript:                            Introduction.        (line  15)
* Postscript:                            PDF PostScript and SVG Output Options.
                                                              (line   6)
* precedence, operator:                  Order of Operations. (line   6)
* precision, of output:                  OUTPUT.              (line   6)
* principal axis factoring:              FACTOR.              (line   6)
* principal components analysis:         FACTOR.              (line   6)
* print format:                          Attributes.          (line  63)
* procedures:                            Types of Commands.   (line  33)
* productions:                           BNF.                 (line  33)
* productions <1>:                       BNF.                 (line  44)
* PSPP language:                         Introduction.        (line   6)
* PSPP, command structure:               Commands.            (line   6)
* PSPP, invoking:                        Invoking PSPP.       (line   6)
* PSPP, language:                        Language.            (line   6)
* 'pspp-convert':                        Invoking pspp-convert.
                                                              (line   6)
* 'pspp-dump-sav':                       Invoking pspp-dump-sav.
                                                              (line   6)
* PSPPIRE:                               Invoking PSPPIRE.    (line   9)
* punctuators:                           Tokens.              (line  95)
* punctuators <1>:                       BNF.                 (line  26)
* Q, Cochran Q:                          COCHRAN.             (line   6)
* quarter-year:                          Date Construction.   (line  48)
* quarters:                              Date Extraction.     (line  46)
* reading data:                          Reading data from a text file.
                                                              (line   6)
* reading data from a file:              DATA LIST.           (line   6)
* reading fixed-format data:             DATA LIST FIXED.     (line   6)
* reals:                                 Tokens.              (line  44)
* Receiver Operating Characteristic:     ROC.                 (line   6)
* recoding data:                         Dealing with suspicious data.
                                                              (line   6)
* regression:                            REGRESSION.          (line   6)
* reliability:                           Testing data consistency.
                                                              (line   6)
* replacing substrings:                  String Functions.    (line  67)
* reserved identifiers:                  Tokens.              (line  25)
* restricted transformations:            Types of Commands.   (line  29)
* rights, your:                          License.             (line   6)
* rounding:                              Miscellaneous Mathematics.
                                                              (line  22)
* runs test:                             RUNS.                (line   6)
* saving:                                Saving data to a PSPP file..
                                                              (line   6)
* scatterplot:                           SCATTERPLOT.         (line   6)
* scratch variables:                     Scratch Variables.   (line   6)
* screening:                             Data Screening and Transformation.
                                                              (line   6)
* searching strings:                     String Functions.    (line  13)
* seconds:                               Time Extraction.     (line  18)
* seconds <1>:                           Date Extraction.     (line  50)
* set membership:                        Set Membership.      (line   6)
* sign test:                             SIGN.                (line   6)
* sine:                                  Trigonometry.        (line  27)
* spreadlevel plot:                      EXAMINE.             (line  57)
* spreadsheet files:                     GET DATA /TYPE=GNM/ODS.
                                                              (line  13)
* spreadsheets:                          Reading data from other sources.
                                                              (line   6)
* square roots:                          Mathematics.         (line  24)
* standard deviation:                    Statistical Functions.
                                                              (line  45)
* start symbol:                          BNF.                 (line  58)
* statistics:                            Statistical Functions.
                                                              (line   6)
* 'string':                              BNF.                 (line  20)
* string formats:                        String Formats.      (line   6)
* string functions:                      String Functions.    (line   6)
* strings:                               Tokens.              (line  64)
* strings, case of:                      String Functions.    (line  30)
* strings, case of <1>:                  String Functions.    (line 134)
* strings, concatenation of:             String Functions.    (line   8)
* strings, converting from numbers:      String Functions.    (line 109)
* strings, converting to numbers:        String Functions.    (line  58)
* strings, finding length of:            String Functions.    (line  27)
* strings, padding:                      String Functions.    (line  35)
* strings, padding <1>:                  String Functions.    (line  87)
* strings, replacing substrings:         String Functions.    (line  67)
* strings, searching backwards:          String Functions.    (line  73)
* strings, taking substrings of:         String Functions.    (line 119)
* strings, trimming:                     String Functions.    (line  48)
* strings, trimming <1>:                 String Functions.    (line 100)
* strings, trimming <2>:                 String Functions.    (line 114)
* strings, truncating:                   String Functions.    (line 114)
* substrings:                            String Functions.    (line 119)
* subtraction:                           Arithmetic Operators.
                                                              (line  12)
* sum:                                   Statistical Functions.
                                                              (line  48)
* SVG:                                   PDF PostScript and SVG Output Options.
                                                              (line   6)
* symbol, start:                         BNF.                 (line  58)
* syntax file:                           Files.               (line  10)
* SYSMIS:                                Dealing with suspicious data.
                                                              (line   6)
* system file:                           Files.               (line  27)
* system files:                          Reading data from a pre-prepared PSPP file.
                                                              (line   6)
* system variables:                      System Variables.    (line   6)
* system-missing:                        Logical Operators.   (line   6)
* T-test:                                Testing for differences of means.
                                                              (line   6)
* tangent:                               Trigonometry.        (line  30)
* terminals:                             BNF.                 (line  10)
* terminals and nonterminals, differences: BNF.               (line  50)
* testing for equality:                  Relational Operators.
                                                              (line  17)
* testing for inequality:                Relational Operators.
                                                              (line  37)
* text files:                            GET DATA /TYPE=TXT.  (line  14)
* time:                                  Date Extraction.     (line  57)
* time examination:                      Time Extraction.     (line   6)
* time formats:                          Time and Date Formats.
                                                              (line   6)
* time, concepts:                        Time and Date Concepts.
                                                              (line   6)
* time, in days:                         Time Construction.   (line   9)
* time, in days <1>:                     Time Extraction.     (line   9)
* time, in days <2>:                     Date Extraction.     (line  18)
* time, in hours:                        Time Extraction.     (line  12)
* time, in hours <1>:                    Date Extraction.     (line  24)
* time, in hours-minutes-seconds:        Time Construction.   (line  12)
* time, in minutes:                      Time Extraction.     (line  15)
* time, in minutes <1>:                  Date Extraction.     (line  38)
* time, in seconds:                      Time Extraction.     (line  18)
* time, in seconds <1>:                  Date Extraction.     (line  50)
* time, instants of:                     Time and Date Concepts.
                                                              (line  15)
* time, intervals:                       Time and Date Concepts.
                                                              (line   6)
* time, lengths of:                      Time Extraction.     (line   6)
* time, mathematical properties of:      Time and Date Arithmetic.
                                                              (line   6)
* times:                                 Time and Date.       (line   6)
* times, constructing:                   Time Construction.   (line   6)
* times, in days:                        Date Extraction.     (line  54)
* tnumbers:                              SET.                 (line 344)
* 'TO' convention:                       Sets of Variables.   (line   6)
* tokens:                                Tokens.              (line   6)
* transformation:                        Data Screening and Transformation.
                                                              (line   6)
* transformations:                       Types of Commands.   (line  25)
* transformations <1>:                   Data Manipulation.   (line   6)
* trigonometry:                          Trigonometry.        (line   6)
* troubleshooting:                       Bugs.                (line   6)
* true:                                  Logical Operators.   (line   6)
* truncation:                            Miscellaneous Mathematics.
                                                              (line  30)
* type of variables:                     Attributes.          (line  29)
* U, Mann-Whitney U:                     MANN-WHITNEY.        (line   6)
* unimplemented commands:                Not Implemented.     (line   9)
* union, logical:                        Logical Operators.   (line  17)
* univariate analysis of variance:       GLM.                 (line   6)
* utility commands:                      Types of Commands.   (line   9)
* value label:                           Miscellaneous Functions.
                                                              (line  41)
* value labels:                          Attributes.          (line  59)
* values, Boolean:                       Boolean Values.      (line   6)
* values, missing:                       Missing Observations.
                                                              (line   6)
* values, missing <1>:                   Attributes.          (line  46)
* values, missing <2>:                   Missing Value Functions.
                                                              (line   6)
* values, system-missing:                Logical Operators.   (line   6)
* 'var-list':                            BNF.                 (line  38)
* 'var-name':                            BNF.                 (line  23)
* variable:                              Datasets.            (line   6)
* variable labels:                       Attributes.          (line  56)
* variable names, ending with period:    Attributes.          (line  15)
* variable role:                         Attributes.          (line  77)
* variables:                             Defining Variables.  (line   6)
* variables, attributes of:              Attributes.          (line   6)
* variables, system:                     System Variables.    (line   6)
* variables, type:                       Attributes.          (line  29)
* variables, width:                      Attributes.          (line  32)
* variance:                              Statistical Functions.
                                                              (line  51)
* variation, coefficient of:             Statistical Functions.
                                                              (line  24)
* week:                                  Date Extraction.     (line  62)
* week-year:                             Date Construction.   (line  52)
* weekday:                               Date Extraction.     (line  66)
* white space, trimming:                 String Functions.    (line  48)
* white space, trimming <1>:             String Functions.    (line 100)
* white space, trimming <2>:             String Functions.    (line 114)
* width:                                 SET.                 (line 344)
* width of variables:                    Attributes.          (line  32)
* wilcoxon matched pairs signed ranks test: WILCOXON.         (line   6)
* workspace:                             SET.                 (line 234)
* write format:                          Attributes.          (line  69)
* year-day:                              Date Construction.   (line  56)
* years:                                 Date Extraction.     (line  70)
* your rights and obligations:           License.             (line   6)


File: pspp.info,  Node: GNU Free Documentation License,  Prev: Concept Index,  Up: Top

Appendix A GNU Free Documentation License
*****************************************

                     Version 1.3, 3 November 2008

     Copyright (C) 2000, 2001, 2002, 2007, 2008 Free Software Foundation, Inc.
     <http://fsf.org/>

     Everyone is permitted to copy and distribute verbatim copies
     of this license document, but changing it is not allowed.

  0. PREAMBLE

     The purpose of this License is to make a manual, textbook, or other
     functional and useful document "free" in the sense of freedom: to
     assure everyone the effective freedom to copy and redistribute it,
     with or without modifying it, either commercially or
     noncommercially.  Secondarily, this License preserves for the
     author and publisher a way to get credit for their work, while not
     being considered responsible for modifications made by others.

     This License is a kind of "copyleft", which means that derivative
     works of the document must themselves be free in the same sense.
     It complements the GNU General Public License, which is a copyleft
     license designed for free software.

     We have designed this License in order to use it for manuals for
     free software, because free software needs free documentation: a
     free program should come with manuals providing the same freedoms
     that the software does.  But this License is not limited to
     software manuals; it can be used for any textual work, regardless
     of subject matter or whether it is published as a printed book.  We
     recommend this License principally for works whose purpose is
     instruction or reference.

  1. APPLICABILITY AND DEFINITIONS

     This License applies to any manual or other work, in any medium,
     that contains a notice placed by the copyright holder saying it can
     be distributed under the terms of this License.  Such a notice
     grants a world-wide, royalty-free license, unlimited in duration,
     to use that work under the conditions stated herein.  The
     "Document", below, refers to any such manual or work.  Any member
     of the public is a licensee, and is addressed as "you".  You accept
     the license if you copy, modify or distribute the work in a way
     requiring permission under copyright law.

     A "Modified Version" of the Document means any work containing the
     Document or a portion of it, either copied verbatim, or with
     modifications and/or translated into another language.

     A "Secondary Section" is a named appendix or a front-matter section
     of the Document that deals exclusively with the relationship of the
     publishers or authors of the Document to the Document's overall
     subject (or to related matters) and contains nothing that could
     fall directly within that overall subject.  (Thus, if the Document
     is in part a textbook of mathematics, a Secondary Section may not
     explain any mathematics.)  The relationship could be a matter of
     historical connection with the subject or with related matters, or
     of legal, commercial, philosophical, ethical or political position
     regarding them.

     The "Invariant Sections" are certain Secondary Sections whose
     titles are designated, as being those of Invariant Sections, in the
     notice that says that the Document is released under this License.
     If a section does not fit the above definition of Secondary then it
     is not allowed to be designated as Invariant.  The Document may
     contain zero Invariant Sections.  If the Document does not identify
     any Invariant Sections then there are none.

     The "Cover Texts" are certain short passages of text that are
     listed, as Front-Cover Texts or Back-Cover Texts, in the notice
     that says that the Document is released under this License.  A
     Front-Cover Text may be at most 5 words, and a Back-Cover Text may
     be at most 25 words.

     A "Transparent" copy of the Document means a machine-readable copy,
     represented in a format whose specification is available to the
     general public, that is suitable for revising the document
     straightforwardly with generic text editors or (for images composed
     of pixels) generic paint programs or (for drawings) some widely
     available drawing editor, and that is suitable for input to text
     formatters or for automatic translation to a variety of formats
     suitable for input to text formatters.  A copy made in an otherwise
     Transparent file format whose markup, or absence of markup, has
     been arranged to thwart or discourage subsequent modification by
     readers is not Transparent.  An image format is not Transparent if
     used for any substantial amount of text.  A copy that is not
     "Transparent" is called "Opaque".

     Examples of suitable formats for Transparent copies include plain
     ASCII without markup, Texinfo input format, LaTeX input format,
     SGML or XML using a publicly available DTD, and standard-conforming
     simple HTML, PostScript or PDF designed for human modification.
     Examples of transparent image formats include PNG, XCF and JPG.
     Opaque formats include proprietary formats that can be read and
     edited only by proprietary word processors, SGML or XML for which
     the DTD and/or processing tools are not generally available, and
     the machine-generated HTML, PostScript or PDF produced by some word
     processors for output purposes only.

     The "Title Page" means, for a printed book, the title page itself,
     plus such following pages as are needed to hold, legibly, the
     material this License requires to appear in the title page.  For
     works in formats which do not have any title page as such, "Title
     Page" means the text near the most prominent appearance of the
     work's title, preceding the beginning of the body of the text.

     The "publisher" means any person or entity that distributes copies
     of the Document to the public.

     A section "Entitled XYZ" means a named subunit of the Document
     whose title either is precisely XYZ or contains XYZ in parentheses
     following text that translates XYZ in another language.  (Here XYZ
     stands for a specific section name mentioned below, such as
     "Acknowledgements", "Dedications", "Endorsements", or "History".)
     To "Preserve the Title" of such a section when you modify the
     Document means that it remains a section "Entitled XYZ" according
     to this definition.

     The Document may include Warranty Disclaimers next to the notice
     which states that this License applies to the Document.  These
     Warranty Disclaimers are considered to be included by reference in
     this License, but only as regards disclaiming warranties: any other
     implication that these Warranty Disclaimers may have is void and
     has no effect on the meaning of this License.

  2. VERBATIM COPYING

     You may copy and distribute the Document in any medium, either
     commercially or noncommercially, provided that this License, the
     copyright notices, and the license notice saying this License
     applies to the Document are reproduced in all copies, and that you
     add no other conditions whatsoever to those of this License.  You
     may not use technical measures to obstruct or control the reading
     or further copying of the copies you make or distribute.  However,
     you may accept compensation in exchange for copies.  If you
     distribute a large enough number of copies you must also follow the
     conditions in section 3.

     You may also lend copies, under the same conditions stated above,
     and you may publicly display copies.

  3. COPYING IN QUANTITY

     If you publish printed copies (or copies in media that commonly
     have printed covers) of the Document, numbering more than 100, and
     the Document's license notice requires Cover Texts, you must
     enclose the copies in covers that carry, clearly and legibly, all
     these Cover Texts: Front-Cover Texts on the front cover, and
     Back-Cover Texts on the back cover.  Both covers must also clearly
     and legibly identify you as the publisher of these copies.  The
     front cover must present the full title with all words of the title
     equally prominent and visible.  You may add other material on the
     covers in addition.  Copying with changes limited to the covers, as
     long as they preserve the title of the Document and satisfy these
     conditions, can be treated as verbatim copying in other respects.

     If the required texts for either cover are too voluminous to fit
     legibly, you should put the first ones listed (as many as fit
     reasonably) on the actual cover, and continue the rest onto
     adjacent pages.

     If you publish or distribute Opaque copies of the Document
     numbering more than 100, you must either include a machine-readable
     Transparent copy along with each Opaque copy, or state in or with
     each Opaque copy a computer-network location from which the general
     network-using public has access to download using public-standard
     network protocols a complete Transparent copy of the Document, free
     of added material.  If you use the latter option, you must take
     reasonably prudent steps, when you begin distribution of Opaque
     copies in quantity, to ensure that this Transparent copy will
     remain thus accessible at the stated location until at least one
     year after the last time you distribute an Opaque copy (directly or
     through your agents or retailers) of that edition to the public.

     It is requested, but not required, that you contact the authors of
     the Document well before redistributing any large number of copies,
     to give them a chance to provide you with an updated version of the
     Document.

  4. MODIFICATIONS

     You may copy and distribute a Modified Version of the Document
     under the conditions of sections 2 and 3 above, provided that you
     release the Modified Version under precisely this License, with the
     Modified Version filling the role of the Document, thus licensing
     distribution and modification of the Modified Version to whoever
     possesses a copy of it.  In addition, you must do these things in
     the Modified Version:

       A. Use in the Title Page (and on the covers, if any) a title
          distinct from that of the Document, and from those of previous
          versions (which should, if there were any, be listed in the
          History section of the Document).  You may use the same title
          as a previous version if the original publisher of that
          version gives permission.

       B. List on the Title Page, as authors, one or more persons or
          entities responsible for authorship of the modifications in
          the Modified Version, together with at least five of the
          principal authors of the Document (all of its principal
          authors, if it has fewer than five), unless they release you
          from this requirement.

       C. State on the Title page the name of the publisher of the
          Modified Version, as the publisher.

       D. Preserve all the copyright notices of the Document.

       E. Add an appropriate copyright notice for your modifications
          adjacent to the other copyright notices.

       F. Include, immediately after the copyright notices, a license
          notice giving the public permission to use the Modified
          Version under the terms of this License, in the form shown in
          the Addendum below.

       G. Preserve in that license notice the full lists of Invariant
          Sections and required Cover Texts given in the Document's
          license notice.

       H. Include an unaltered copy of this License.

       I. Preserve the section Entitled "History", Preserve its Title,
          and add to it an item stating at least the title, year, new
          authors, and publisher of the Modified Version as given on the
          Title Page.  If there is no section Entitled "History" in the
          Document, create one stating the title, year, authors, and
          publisher of the Document as given on its Title Page, then add
          an item describing the Modified Version as stated in the
          previous sentence.

       J. Preserve the network location, if any, given in the Document
          for public access to a Transparent copy of the Document, and
          likewise the network locations given in the Document for
          previous versions it was based on.  These may be placed in the
          "History" section.  You may omit a network location for a work
          that was published at least four years before the Document
          itself, or if the original publisher of the version it refers
          to gives permission.

       K. For any section Entitled "Acknowledgements" or "Dedications",
          Preserve the Title of the section, and preserve in the section
          all the substance and tone of each of the contributor
          acknowledgements and/or dedications given therein.

       L. Preserve all the Invariant Sections of the Document, unaltered
          in their text and in their titles.  Section numbers or the
          equivalent are not considered part of the section titles.

       M. Delete any section Entitled "Endorsements".  Such a section
          may not be included in the Modified Version.

       N. Do not retitle any existing section to be Entitled
          "Endorsements" or to conflict in title with any Invariant
          Section.

       O. Preserve any Warranty Disclaimers.

     If the Modified Version includes new front-matter sections or
     appendices that qualify as Secondary Sections and contain no
     material copied from the Document, you may at your option designate
     some or all of these sections as invariant.  To do this, add their
     titles to the list of Invariant Sections in the Modified Version's
     license notice.  These titles must be distinct from any other
     section titles.

     You may add a section Entitled "Endorsements", provided it contains
     nothing but endorsements of your Modified Version by various
     parties--for example, statements of peer review or that the text
     has been approved by an organization as the authoritative
     definition of a standard.

     You may add a passage of up to five words as a Front-Cover Text,
     and a passage of up to 25 words as a Back-Cover Text, to the end of
     the list of Cover Texts in the Modified Version.  Only one passage
     of Front-Cover Text and one of Back-Cover Text may be added by (or
     through arrangements made by) any one entity.  If the Document
     already includes a cover text for the same cover, previously added
     by you or by arrangement made by the same entity you are acting on
     behalf of, you may not add another; but you may replace the old
     one, on explicit permission from the previous publisher that added
     the old one.

     The author(s) and publisher(s) of the Document do not by this
     License give permission to use their names for publicity for or to
     assert or imply endorsement of any Modified Version.

  5. COMBINING DOCUMENTS

     You may combine the Document with other documents released under
     this License, under the terms defined in section 4 above for
     modified versions, provided that you include in the combination all
     of the Invariant Sections of all of the original documents,
     unmodified, and list them all as Invariant Sections of your
     combined work in its license notice, and that you preserve all
     their Warranty Disclaimers.

     The combined work need only contain one copy of this License, and
     multiple identical Invariant Sections may be replaced with a single
     copy.  If there are multiple Invariant Sections with the same name
     but different contents, make the title of each such section unique
     by adding at the end of it, in parentheses, the name of the
     original author or publisher of that section if known, or else a
     unique number.  Make the same adjustment to the section titles in
     the list of Invariant Sections in the license notice of the
     combined work.

     In the combination, you must combine any sections Entitled
     "History" in the various original documents, forming one section
     Entitled "History"; likewise combine any sections Entitled
     "Acknowledgements", and any sections Entitled "Dedications".  You
     must delete all sections Entitled "Endorsements."

  6. COLLECTIONS OF DOCUMENTS

     You may make a collection consisting of the Document and other
     documents released under this License, and replace the individual
     copies of this License in the various documents with a single copy
     that is included in the collection, provided that you follow the
     rules of this License for verbatim copying of each of the documents
     in all other respects.

     You may extract a single document from such a collection, and
     distribute it individually under this License, provided you insert
     a copy of this License into the extracted document, and follow this
     License in all other respects regarding verbatim copying of that
     document.

  7. AGGREGATION WITH INDEPENDENT WORKS

     A compilation of the Document or its derivatives with other
     separate and independent documents or works, in or on a volume of a
     storage or distribution medium, is called an "aggregate" if the
     copyright resulting from the compilation is not used to limit the
     legal rights of the compilation's users beyond what the individual
     works permit.  When the Document is included in an aggregate, this
     License does not apply to the other works in the aggregate which
     are not themselves derivative works of the Document.

     If the Cover Text requirement of section 3 is applicable to these
     copies of the Document, then if the Document is less than one half
     of the entire aggregate, the Document's Cover Texts may be placed
     on covers that bracket the Document within the aggregate, or the
     electronic equivalent of covers if the Document is in electronic
     form.  Otherwise they must appear on printed covers that bracket
     the whole aggregate.

  8. TRANSLATION

     Translation is considered a kind of modification, so you may
     distribute translations of the Document under the terms of section
     4.  Replacing Invariant Sections with translations requires special
     permission from their copyright holders, but you may include
     translations of some or all Invariant Sections in addition to the
     original versions of these Invariant Sections.  You may include a
     translation of this License, and all the license notices in the
     Document, and any Warranty Disclaimers, provided that you also
     include the original English version of this License and the
     original versions of those notices and disclaimers.  In case of a
     disagreement between the translation and the original version of
     this License or a notice or disclaimer, the original version will
     prevail.

     If a section in the Document is Entitled "Acknowledgements",
     "Dedications", or "History", the requirement (section 4) to
     Preserve its Title (section 1) will typically require changing the
     actual title.

  9. TERMINATION

     You may not copy, modify, sublicense, or distribute the Document
     except as expressly provided under this License.  Any attempt
     otherwise to copy, modify, sublicense, or distribute it is void,
     and will automatically terminate your rights under this License.

     However, if you cease all violation of this License, then your
     license from a particular copyright holder is reinstated (a)
     provisionally, unless and until the copyright holder explicitly and
     finally terminates your license, and (b) permanently, if the
     copyright holder fails to notify you of the violation by some
     reasonable means prior to 60 days after the cessation.

     Moreover, your license from a particular copyright holder is
     reinstated permanently if the copyright holder notifies you of the
     violation by some reasonable means, this is the first time you have
     received notice of violation of this License (for any work) from
     that copyright holder, and you cure the violation prior to 30 days
     after your receipt of the notice.

     Termination of your rights under this section does not terminate
     the licenses of parties who have received copies or rights from you
     under this License.  If your rights have been terminated and not
     permanently reinstated, receipt of a copy of some or all of the
     same material does not give you any rights to use it.

  10. FUTURE REVISIONS OF THIS LICENSE

     The Free Software Foundation may publish new, revised versions of
     the GNU Free Documentation License from time to time.  Such new
     versions will be similar in spirit to the present version, but may
     differ in detail to address new problems or concerns.  See
     <http://www.gnu.org/copyleft/>.

     Each version of the License is given a distinguishing version
     number.  If the Document specifies that a particular numbered
     version of this License "or any later version" applies to it, you
     have the option of following the terms and conditions either of
     that specified version or of any later version that has been
     published (not as a draft) by the Free Software Foundation.  If the
     Document does not specify a version number of this License, you may
     choose any version ever published (not as a draft) by the Free
     Software Foundation.  If the Document specifies that a proxy can
     decide which future versions of this License can be used, that
     proxy's public statement of acceptance of a version permanently
     authorizes you to choose that version for the Document.

  11. RELICENSING

     "Massive Multiauthor Collaboration Site" (or "MMC Site") means any
     World Wide Web server that publishes copyrightable works and also
     provides prominent facilities for anybody to edit those works.  A
     public wiki that anybody can edit is an example of such a server.
     A "Massive Multiauthor Collaboration" (or "MMC") contained in the
     site means any set of copyrightable works thus published on the MMC
     site.

     "CC-BY-SA" means the Creative Commons Attribution-Share Alike 3.0
     license published by Creative Commons Corporation, a not-for-profit
     corporation with a principal place of business in San Francisco,
     California, as well as future copyleft versions of that license
     published by that same organization.

     "Incorporate" means to publish or republish a Document, in whole or
     in part, as part of another Document.

     An MMC is "eligible for relicensing" if it is licensed under this
     License, and if all works that were first published under this
     License somewhere other than this MMC, and subsequently
     incorporated in whole or in part into the MMC, (1) had no cover
     texts or invariant sections, and (2) were thus incorporated prior
     to November 1, 2008.

     The operator of an MMC Site may republish an MMC contained in the
     site under CC-BY-SA on the same site at any time before August 1,
     2009, provided the MMC is eligible for relicensing.

ADDENDUM: How to use this License for your documents
====================================================

To use this License in a document you have written, include a copy of
the License in the document and put the following copyright and license
notices just after the title page:

       Copyright (C)  YEAR  YOUR NAME.
       Permission is granted to copy, distribute and/or modify this document
       under the terms of the GNU Free Documentation License, Version 1.3
       or any later version published by the Free Software Foundation;
       with no Invariant Sections, no Front-Cover Texts, and no Back-Cover
       Texts.  A copy of the license is included in the section entitled ``GNU
       Free Documentation License''.

   If you have Invariant Sections, Front-Cover Texts and Back-Cover
Texts, replace the "with...Texts."  line with this:

         with the Invariant Sections being LIST THEIR TITLES, with
         the Front-Cover Texts being LIST, and with the Back-Cover Texts
         being LIST.

   If you have Invariant Sections without Cover Texts, or some other
combination of the three, merge those two alternatives to suit the
situation.

   If your document contains nontrivial examples of program code, we
recommend releasing these examples in parallel under your choice of free
software license, such as the GNU General Public License, to permit
their use in free software.

